{"problem_id": "sqlfluff__sqlfluff-1625", "repo_owner": "sqlfluff", "repo_name": "sqlfluff", "repo_url": "https://github.com/sqlfluff/sqlfluff", "base_commit": "14e1a23a3166b9a645a16de96f694c77a5d4abb7", "problem": "TSQL - L031 incorrectly triggers \"Avoid using aliases in join condition\" when no join present\n## Expected Behaviour\r\n\r\nBoth of these queries should pass, the only difference is the addition of a table alias 'a':\r\n\r\n1/ no alias\r\n\r\n```\r\nSELECT [hello]\r\nFROM\r\n    mytable\r\n```\r\n\r\n2/ same query with alias\r\n\r\n```\r\nSELECT a.[hello]\r\nFROM\r\n    mytable AS a\r\n```\r\n\r\n## Observed Behaviour\r\n\r\n1/ passes\r\n2/ fails with: L031: Avoid using aliases in join condition.\r\n\r\nBut there is no join condition :-)\r\n\r\n## Steps to Reproduce\r\n\r\nLint queries above\r\n\r\n## Dialect\r\n\r\nTSQL\r\n\r\n## Version\r\n\r\nsqlfluff 0.6.9\r\nPython 3.6.9\r\n\r\n## Configuration\r\n\r\nN/A\n", "issue_title": "Fix issue in sqlfluff/sqlfluff", "issue_body": "TSQL - L031 incorrectly triggers \"Avoid using aliases in join condition\" when no join present\n## Expected Behaviour\r\n\r\nBoth of these queries should pass, the only difference is the addition of a table alias 'a':\r\n\r\n1/ no alias\r\n\r\n```\r\nSELECT [hello]\r\nFROM\r\n    mytable\r\n```\r\n\r\n2/ same query with alias\r\n\r\n```\r\nSELECT a.[hello]\r\nFROM\r\n    mytable AS a\r\n```\r\n\r\n## Observed Behaviour\r\n\r\n1/ passes\r\n2/ fails with: L031: Avoid using aliases in join condition.\r\n\r\nBut there is no join condition :-)\r\n\r\n## Steps to Reproduce\r\n\r\nLint queries above\r\n\r\n## Dialect\r\n\r\nTSQL\r\n\r\n## Version\r\n\r\nsqlfluff 0.6.9\r\nPython 3.6.9\r\n\r\n## Configuration\r\n\r\nN/A\n", "pr_diff": "diff --git a/src/sqlfluff/rules/L031.py b/src/sqlfluff/rules/L031.py\n--- a/src/sqlfluff/rules/L031.py\n+++ b/src/sqlfluff/rules/L031.py\n@@ -211,7 +211,7 @@ def _lint_aliases_in_join(\n             violation_buff.append(\n                 LintResult(\n                     anchor=alias_info.alias_identifier_ref,\n-                    description=\"Avoid using aliases in join condition\",\n+                    description=\"Avoid aliases in from clauses and join conditions.\",\n                     fixes=fixes,\n                 )\n             )\n", "solution": "diff --git a/src/sqlfluff/rules/L031.py b/src/sqlfluff/rules/L031.py\n--- a/src/sqlfluff/rules/L031.py\n+++ b/src/sqlfluff/rules/L031.py\n@@ -211,7 +211,7 @@ def _lint_aliases_in_join(\n             violation_buff.append(\n                 LintResult(\n                     anchor=alias_info.alias_identifier_ref,\n-                    description=\"Avoid using aliases in join condition\",\n+                    description=\"Avoid aliases in from clauses and join conditions.\",\n                     fixes=fixes,\n                 )\n             )\n", "test_command": "[\"test/cli/commands_test.py::test__cli__command_directed\"]", "test_commands": ["[\"test/cli/commands_test.py::test__cli__command_directed\"]", "[\"test/cli/commands_test.py::test__cli__command_dialect\", \"test/cli/commands_test.py::test__cli__command_dialect_legacy\", \"test/cli/commands_test.py::test__cli__command_lint_stdin[command0]\", \"test/cli/commands_test.py::test__cli__command_lint_stdin[command1]\", \"test/cli/commands_test.py::test__cli__command_lint_stdin[command2]\", \"test/cli/commands_test.py::test__cli__command_lint_stdin[command3]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command0]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command1]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command2]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command3]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command4]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command5]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command6]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command7]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command8]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command9]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command10]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command11]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command12]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command13]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command14]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command15]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command16]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command17]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command18]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command19]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command20]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command21]\", \"test/cli/commands_test.py::test__cli__command_lint_parse_with_retcode[command0-1]\", \"test/cli/commands_test.py::test__cli__command_lint_parse_with_retcode[command1-1]\", \"test/cli/commands_test.py::test__cli__command_lint_parse_with_retcode[command2-1]\", \"test/cli/commands_test.py::test__cli__command_lint_warning_explicit_file_ignored\", \"test/cli/commands_test.py::test__cli__command_lint_skip_ignore_files\", \"test/cli/commands_test.py::test__cli__command_versioning\", \"test/cli/commands_test.py::test__cli__command_version\", \"test/cli/commands_test.py::test__cli__command_rules\", \"test/cli/commands_test.py::test__cli__command_dialects\", \"test/cli/commands_test.py::test__cli__command__fix[L001-test/fixtures/linter/indentation_errors.sql]\", \"test/cli/commands_test.py::test__cli__command__fix[L008-test/fixtures/linter/whitespace_errors.sql]\", \"test/cli/commands_test.py::test__cli__command__fix[L008-test/fixtures/linter/indentation_errors.sql]\", \"test/cli/commands_test.py::test__cli__command__fix[L003-test/fixtures/linter/indentation_error_hard.sql]\", \"test/cli/commands_test.py::test__cli__command_fix_stdin[select\", \"test/cli/commands_test.py::test__cli__command_fix_stdin[\", \"test/cli/commands_test.py::test__cli__command_fix_stdin[SELECT\", \"test/cli/commands_test.py::test__cli__command_fix_stdin_logging_to_stderr\", \"test/cli/commands_test.py::test__cli__command_fix_stdin_safety\", \"test/cli/commands_test.py::test__cli__command_fix_stdin_error_exit_code[create\", \"test/cli/commands_test.py::test__cli__command_fix_stdin_error_exit_code[select\", \"test/cli/commands_test.py::test__cli__command__fix_no_force[L001-test/fixtures/linter/indentation_errors.sql-y-0-0]\", \"test/cli/commands_test.py::test__cli__command__fix_no_force[L001-test/fixtures/linter/indentation_errors.sql-n-65-1]\", \"test/cli/commands_test.py::test__cli__command_parse_serialize_from_stdin[yaml]\", \"test/cli/commands_test.py::test__cli__command_parse_serialize_from_stdin[json]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_from_stdin[select\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_from_stdin[SElect\", \"test/cli/commands_test.py::test__cli__command_fail_nice_not_found[command0]\", \"test/cli/commands_test.py::test__cli__command_fail_nice_not_found[command1]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[yaml]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[json]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[github-annotation]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_github_annotation\", \"test/cli/commands_test.py::test___main___help\", \"test/cli/commands_test.py::test_encoding[utf-8-ascii]\", \"test/cli/commands_test.py::test_encoding[utf-8-sig-UTF-8-SIG]\", \"test/cli/commands_test.py::test_encoding[utf-32-UTF-32]\"]"], "files_to_edit": ["src/sqlfluff/rules/L031.py"], "metadata": {"hints_text": "Actually, re-reading the docs I think this is the intended behaviour... closing", "created_at": "2021-10-13T11:35:29Z", "version": "0.6", "test_patch": "diff --git a/test/cli/commands_test.py b/test/cli/commands_test.py\n--- a/test/cli/commands_test.py\n+++ b/test/cli/commands_test.py\n@@ -49,7 +49,7 @@ def invoke_assert_code(\n expected_output = \"\"\"== [test/fixtures/linter/indentation_error_simple.sql] FAIL\n L:   2 | P:   4 | L003 | Indentation not hanging or a multiple of 4 spaces\n L:   5 | P:  10 | L010 | Keywords must be consistently upper case.\n-L:   5 | P:  13 | L031 | Avoid using aliases in join condition\n+L:   5 | P:  13 | L031 | Avoid aliases in from clauses and join conditions.\n \"\"\"\n \n \n", "environment_setup_commit": "67023b85c41d23d6c6d69812a41b207c4f8a9331"}}
{"problem_id": "sqlfluff__sqlfluff-2419", "repo_owner": "sqlfluff", "repo_name": "sqlfluff", "repo_url": "https://github.com/sqlfluff/sqlfluff", "base_commit": "f1dba0e1dd764ae72d67c3d5e1471cf14d3db030", "problem": "Rule L060 could give a specific error message\nAt the moment rule L060 flags something like this:\r\n\r\n```\r\nL:  21 | P:   9 | L060 | Use 'COALESCE' instead of 'IFNULL' or 'NVL'.\r\n```\r\n\r\nSince we likely know the wrong word, it might be nice to actually flag that instead of both `IFNULL` and `NVL` - like most of the other rules do.\r\n\r\nThat is it should flag this:\r\n\r\n```\r\nL:  21 | P:   9 | L060 | Use 'COALESCE' instead of 'IFNULL'.\r\n```\r\n Or this:\r\n\r\n```\r\nL:  21 | P:   9 | L060 | Use 'COALESCE' instead of 'NVL'.\r\n```\r\n\r\nAs appropriate.\r\n\r\nWhat do you think @jpy-git ?\r\n\n", "issue_title": "Fix issue in sqlfluff/sqlfluff", "issue_body": "Rule L060 could give a specific error message\nAt the moment rule L060 flags something like this:\r\n\r\n```\r\nL:  21 | P:   9 | L060 | Use 'COALESCE' instead of 'IFNULL' or 'NVL'.\r\n```\r\n\r\nSince we likely know the wrong word, it might be nice to actually flag that instead of both `IFNULL` and `NVL` - like most of the other rules do.\r\n\r\nThat is it should flag this:\r\n\r\n```\r\nL:  21 | P:   9 | L060 | Use 'COALESCE' instead of 'IFNULL'.\r\n```\r\n Or this:\r\n\r\n```\r\nL:  21 | P:   9 | L060 | Use 'COALESCE' instead of 'NVL'.\r\n```\r\n\r\nAs appropriate.\r\n\r\nWhat do you think @jpy-git ?\r\n\n", "pr_diff": "diff --git a/src/sqlfluff/rules/L060.py b/src/sqlfluff/rules/L060.py\n--- a/src/sqlfluff/rules/L060.py\n+++ b/src/sqlfluff/rules/L060.py\n@@ -59,4 +59,8 @@ def _eval(self, context: RuleContext) -> Optional[LintResult]:\n             ],\n         )\n \n-        return LintResult(context.segment, [fix])\n+        return LintResult(\n+            anchor=context.segment,\n+            fixes=[fix],\n+            description=f\"Use 'COALESCE' instead of '{context.segment.raw_upper}'.\",\n+        )\n", "solution": "diff --git a/src/sqlfluff/rules/L060.py b/src/sqlfluff/rules/L060.py\n--- a/src/sqlfluff/rules/L060.py\n+++ b/src/sqlfluff/rules/L060.py\n@@ -59,4 +59,8 @@ def _eval(self, context: RuleContext) -> Optional[LintResult]:\n             ],\n         )\n \n-        return LintResult(context.segment, [fix])\n+        return LintResult(\n+            anchor=context.segment,\n+            fixes=[fix],\n+            description=f\"Use 'COALESCE' instead of '{context.segment.raw_upper}'.\",\n+        )\n", "test_command": "[\"test/rules/std_L060_test.py::test__rules__std_L060_raised\"]", "test_commands": ["[\"test/rules/std_L060_test.py::test__rules__std_L060_raised\"]", "[]"], "files_to_edit": ["src/sqlfluff/rules/L060.py"], "metadata": {"hints_text": "@tunetheweb Yeah definitely, should be a pretty quick change \ud83d\ude0a", "created_at": "2022-01-22T12:21:52Z", "version": "0.8", "test_patch": "diff --git a/test/rules/std_L060_test.py b/test/rules/std_L060_test.py\nnew file mode 100644\n--- /dev/null\n+++ b/test/rules/std_L060_test.py\n@@ -0,0 +1,12 @@\n+\"\"\"Tests the python routines within L060.\"\"\"\n+import sqlfluff\n+\n+\n+def test__rules__std_L060_raised() -> None:\n+    \"\"\"L060 is raised for use of ``IFNULL`` or ``NVL``.\"\"\"\n+    sql = \"SELECT\\n\\tIFNULL(NULL, 100),\\n\\tNVL(NULL,100);\"\n+    result = sqlfluff.lint(sql, rules=[\"L060\"])\n+\n+    assert len(result) == 2\n+    assert result[0][\"description\"] == \"Use 'COALESCE' instead of 'IFNULL'.\"\n+    assert result[1][\"description\"] == \"Use 'COALESCE' instead of 'NVL'.\"\n", "environment_setup_commit": "a5c4eae4e3e419fe95460c9afd9cf39a35a470c4"}}
{"problem_id": "sqlfluff__sqlfluff-1733", "repo_owner": "sqlfluff", "repo_name": "sqlfluff", "repo_url": "https://github.com/sqlfluff/sqlfluff", "base_commit": "a1579a16b1d8913d9d7c7d12add374a290bcc78c", "problem": "Extra space when first field moved to new line in a WITH statement\nNote, the query below uses a `WITH` statement. If I just try to fix the SQL within the CTE, this works fine.\r\n\r\nGiven the following SQL:\r\n\r\n```sql\r\nWITH example AS (\r\n    SELECT my_id,\r\n        other_thing,\r\n        one_more\r\n    FROM\r\n        my_table\r\n)\r\n\r\nSELECT *\r\nFROM example\r\n```\r\n\r\n## Expected Behaviour\r\n\r\nafter running `sqlfluff fix` I'd expect (`my_id` gets moved down and indented properly):\r\n\r\n```sql\r\nWITH example AS (\r\n    SELECT\r\n        my_id,\r\n        other_thing,\r\n        one_more\r\n    FROM\r\n        my_table\r\n)\r\n\r\nSELECT *\r\nFROM example\r\n```\r\n\r\n## Observed Behaviour\r\n\r\nafter running `sqlfluff fix` we get (notice that `my_id` is indented one extra space)\r\n\r\n```sql\r\nWITH example AS (\r\n    SELECT\r\n         my_id,\r\n        other_thing,\r\n        one_more\r\n    FROM\r\n        my_table\r\n)\r\n\r\nSELECT *\r\nFROM example\r\n```\r\n\r\n## Steps to Reproduce\r\n\r\nNoted above. Create a file with the initial SQL and fun `sqfluff fix` on it.\r\n\r\n## Dialect\r\n\r\nRunning with default config.\r\n\r\n## Version\r\nInclude the output of `sqlfluff --version` along with your Python version\r\n\r\nsqlfluff, version 0.7.0\r\nPython 3.7.5\r\n\r\n## Configuration\r\n\r\nDefault config.\r\n\n", "issue_title": "Fix issue in sqlfluff/sqlfluff", "issue_body": "Extra space when first field moved to new line in a WITH statement\nNote, the query below uses a `WITH` statement. If I just try to fix the SQL within the CTE, this works fine.\r\n\r\nGiven the following SQL:\r\n\r\n```sql\r\nWITH example AS (\r\n    SELECT my_id,\r\n        other_thing,\r\n        one_more\r\n    FROM\r\n        my_table\r\n)\r\n\r\nSELECT *\r\nFROM example\r\n```\r\n\r\n## Expected Behaviour\r\n\r\nafter running `sqlfluff fix` I'd expect (`my_id` gets moved down and indented properly):\r\n\r\n```sql\r\nWITH example AS (\r\n    SELECT\r\n        my_id,\r\n        other_thing,\r\n        one_more\r\n    FROM\r\n        my_table\r\n)\r\n\r\nSELECT *\r\nFROM example\r\n```\r\n\r\n## Observed Behaviour\r\n\r\nafter running `sqlfluff fix` we get (notice that `my_id` is indented one extra space)\r\n\r\n```sql\r\nWITH example AS (\r\n    SELECT\r\n         my_id,\r\n        other_thing,\r\n        one_more\r\n    FROM\r\n        my_table\r\n)\r\n\r\nSELECT *\r\nFROM example\r\n```\r\n\r\n## Steps to Reproduce\r\n\r\nNoted above. Create a file with the initial SQL and fun `sqfluff fix` on it.\r\n\r\n## Dialect\r\n\r\nRunning with default config.\r\n\r\n## Version\r\nInclude the output of `sqlfluff --version` along with your Python version\r\n\r\nsqlfluff, version 0.7.0\r\nPython 3.7.5\r\n\r\n## Configuration\r\n\r\nDefault config.\r\n\n", "pr_diff": "diff --git a/src/sqlfluff/rules/L039.py b/src/sqlfluff/rules/L039.py\n--- a/src/sqlfluff/rules/L039.py\n+++ b/src/sqlfluff/rules/L039.py\n@@ -44,7 +44,9 @@ def _eval(self, context: RuleContext) -> Optional[List[LintResult]]:\n                 # This is to avoid indents\n                 if not prev_newline:\n                     prev_whitespace = seg\n-                prev_newline = False\n+                # We won't set prev_newline to False, just for whitespace\n+                # in case there's multiple indents, inserted by other rule\n+                # fixes (see #1713)\n             elif seg.is_type(\"comment\"):\n                 prev_newline = False\n                 prev_whitespace = None\n", "solution": "diff --git a/src/sqlfluff/rules/L039.py b/src/sqlfluff/rules/L039.py\n--- a/src/sqlfluff/rules/L039.py\n+++ b/src/sqlfluff/rules/L039.py\n@@ -44,7 +44,9 @@ def _eval(self, context: RuleContext) -> Optional[List[LintResult]]:\n                 # This is to avoid indents\n                 if not prev_newline:\n                     prev_whitespace = seg\n-                prev_newline = False\n+                # We won't set prev_newline to False, just for whitespace\n+                # in case there's multiple indents, inserted by other rule\n+                # fixes (see #1713)\n             elif seg.is_type(\"comment\"):\n                 prev_newline = False\n                 prev_whitespace = None\n", "test_command": "[\"test/rules/std_L003_L036_L039_combo_test.py::test__rules__std_L003_L036_L039\"]", "test_commands": ["[\"test/rules/std_L003_L036_L039_combo_test.py::test__rules__std_L003_L036_L039\"]", "[\"test/rules/std_L016_L36_combo_test.py::test__rules__std_L016_L036_long_line_lint\", \"test/rules/std_L016_L36_combo_test.py::test__rules__std_L016_L036_long_line_fix\", \"test/rules/std_L016_L36_combo_test.py::test__rules__std_L016_L036_long_line_fix2\"]"], "files_to_edit": ["src/sqlfluff/rules/L039.py"], "metadata": {"hints_text": "Does running `sqlfluff fix` again correct the SQL?\n@tunetheweb yes, yes it does. Is that something that the user is supposed to do (run it multiple times) or is this indeed a bug?\nIdeally not, but there are some circumstances where it\u2019s understandable that would happen. This however seems an easy enough example where it should not happen.\nThis appears to be a combination of rules L036, L003, and L039 not playing nicely together.\r\n\r\nThe original error is rule L036 and it produces this:\r\n\r\n```sql\r\nWITH example AS (\r\n    SELECT\r\nmy_id,\r\n        other_thing,\r\n        one_more\r\n    FROM\r\n        my_table\r\n)\r\n\r\nSELECT *\r\nFROM example\r\n```\r\n\r\nThat is, it moves the `my_id` down to the newline but does not even try to fix the indentation.\r\n\r\nThen we have another run through and L003 spots the lack of indentation and fixes it by adding the first set of whitespace:\r\n\r\n```sql\r\nWITH example AS (\r\n    SELECT\r\n    my_id,\r\n        other_thing,\r\n        one_more\r\n    FROM\r\n        my_table\r\n)\r\n\r\nSELECT *\r\nFROM example\r\n```\r\n\r\nThen we have another run through and L003 spots that there still isn't enough indentation and fixes it by adding the second set of whitespace:\r\n\r\n```sql\r\nWITH example AS (\r\n    SELECT\r\n        my_id,\r\n        other_thing,\r\n        one_more\r\n    FROM\r\n        my_table\r\n)\r\n\r\nSELECT *\r\nFROM example\r\n```\r\n\r\nAt this point we're all good.\r\n\r\nHowever then L039 has a look. It never expects two sets of whitespace following a new line and is specifically coded to only assume one set of spaces (which it normally would be if the other rules hadn't interfered as it would be parsed as one big space), so it think's the second set is too much indentation, so it replaces it with a single space.\r\n\r\nThen another run and L003 and the whitespace back in so we end up with two indents, and a single space.\r\n\r\nLuckily the fix is easier than that explanation. PR coming up...\r\n\r\n", "created_at": "2021-10-22T18:23:33Z", "version": "0.6", "test_patch": "diff --git a/test/rules/std_L003_L036_L039_combo_test.py b/test/rules/std_L003_L036_L039_combo_test.py\nnew file mode 100644\n--- /dev/null\n+++ b/test/rules/std_L003_L036_L039_combo_test.py\n@@ -0,0 +1,36 @@\n+\"\"\"Tests issue #1373 doesn't reoccur.\n+\n+The combination of L003 (incorrect indentation), L036 (select targets),\n+and L039 (unnecessary white space) can result in incorrect indentation.\n+\"\"\"\n+\n+import sqlfluff\n+\n+\n+def test__rules__std_L003_L036_L039():\n+    \"\"\"Verify that double indents don't flag L039.\"\"\"\n+    sql = \"\"\"\n+    WITH example AS (\n+        SELECT my_id,\n+            other_thing,\n+            one_more\n+        FROM\n+            my_table\n+    )\n+\n+    SELECT *\n+    FROM example\\n\"\"\"\n+    fixed_sql = \"\"\"\n+    WITH example AS (\n+        SELECT\n+            my_id,\n+            other_thing,\n+            one_more\n+        FROM\n+            my_table\n+    )\n+\n+    SELECT *\n+    FROM example\\n\"\"\"\n+    result = sqlfluff.fix(sql)\n+    assert result == fixed_sql\ndiff --git a/test/rules/std_L016_L36_combo.py b/test/rules/std_L016_L36_combo_test.py\nsimilarity index 100%\nrename from test/rules/std_L016_L36_combo.py\nrename to test/rules/std_L016_L36_combo_test.py\n", "environment_setup_commit": "67023b85c41d23d6c6d69812a41b207c4f8a9331"}}
{"problem_id": "sqlfluff__sqlfluff-1517", "repo_owner": "sqlfluff", "repo_name": "sqlfluff", "repo_url": "https://github.com/sqlfluff/sqlfluff", "base_commit": "304a197829f98e7425a46d872ada73176137e5ae", "problem": "\"Dropped elements in sequence matching\" when doubled semicolon\n## Expected Behaviour\r\nFrankly, I'm not sure whether it (doubled `;`) should be just ignored or rather some specific rule should be triggered.\r\n## Observed Behaviour\r\n```console\r\n(.venv) ?master ~/prod/_inne/sqlfluff> echo \"select id from tbl;;\" | sqlfluff lint -\r\nTraceback (most recent call last):\r\n  File \"/home/adam/prod/_inne/sqlfluff/.venv/bin/sqlfluff\", line 11, in <module>\r\n    load_entry_point('sqlfluff', 'console_scripts', 'sqlfluff')()\r\n  File \"/home/adam/prod/_inne/sqlfluff/.venv/lib/python3.9/site-packages/click/core.py\", line 1137, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"/home/adam/prod/_inne/sqlfluff/.venv/lib/python3.9/site-packages/click/core.py\", line 1062, in main\r\n    rv = self.invoke(ctx)\r\n  File \"/home/adam/prod/_inne/sqlfluff/.venv/lib/python3.9/site-packages/click/core.py\", line 1668, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"/home/adam/prod/_inne/sqlfluff/.venv/lib/python3.9/site-packages/click/core.py\", line 1404, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"/home/adam/prod/_inne/sqlfluff/.venv/lib/python3.9/site-packages/click/core.py\", line 763, in invoke\r\n    return __callback(*args, **kwargs)\r\n  File \"/home/adam/prod/_inne/sqlfluff/src/sqlfluff/cli/commands.py\", line 347, in lint\r\n    result = lnt.lint_string_wrapped(sys.stdin.read(), fname=\"stdin\")\r\n  File \"/home/adam/prod/_inne/sqlfluff/src/sqlfluff/core/linter/linter.py\", line 789, in lint_string_wrapped\r\n    linted_path.add(self.lint_string(string, fname=fname, fix=fix))\r\n  File \"/home/adam/prod/_inne/sqlfluff/src/sqlfluff/core/linter/linter.py\", line 668, in lint_string\r\n    parsed = self.parse_string(in_str=in_str, fname=fname, config=config)\r\n  File \"/home/adam/prod/_inne/sqlfluff/src/sqlfluff/core/linter/linter.py\", line 607, in parse_string\r\n    return self.parse_rendered(rendered, recurse=recurse)\r\n  File \"/home/adam/prod/_inne/sqlfluff/src/sqlfluff/core/linter/linter.py\", line 313, in parse_rendered\r\n    parsed, pvs = cls._parse_tokens(\r\n  File \"/home/adam/prod/_inne/sqlfluff/src/sqlfluff/core/linter/linter.py\", line 190, in _parse_tokens\r\n    parsed: Optional[BaseSegment] = parser.parse(\r\n  File \"/home/adam/prod/_inne/sqlfluff/src/sqlfluff/core/parser/parser.py\", line 32, in parse\r\n    parsed = root_segment.parse(parse_context=ctx)\r\n  File \"/home/adam/prod/_inne/sqlfluff/src/sqlfluff/core/parser/segments/base.py\", line 821, in parse\r\n    check_still_complete(segments, m.matched_segments, m.unmatched_segments)\r\n  File \"/home/adam/prod/_inne/sqlfluff/src/sqlfluff/core/parser/helpers.py\", line 30, in check_still_complete\r\n    raise RuntimeError(\r\nRuntimeError: Dropped elements in sequence matching! 'select id from tbl;;' != ';'\r\n\r\n```\r\n## Steps to Reproduce\r\nRun \r\n```console\r\necho \"select id from tbl;;\" | sqlfluff lint -\r\n```\r\n## Dialect\r\ndefault (ansi)\r\n## Version\r\n```\r\nsqlfluff, version 0.6.6\r\nPython 3.9.5\r\n```\r\n## Configuration\r\nNone\r\n\n", "issue_title": "Fix issue in sqlfluff/sqlfluff", "issue_body": "\"Dropped elements in sequence matching\" when doubled semicolon\n## Expected Behaviour\r\nFrankly, I'm not sure whether it (doubled `;`) should be just ignored or rather some specific rule should be triggered.\r\n## Observed Behaviour\r\n```console\r\n(.venv) ?master ~/prod/_inne/sqlfluff> echo \"select id from tbl;;\" | sqlfluff lint -\r\nTraceback (most recent call last):\r\n  File \"/home/adam/prod/_inne/sqlfluff/.venv/bin/sqlfluff\", line 11, in <module>\r\n    load_entry_point('sqlfluff', 'console_scripts', 'sqlfluff')()\r\n  File \"/home/adam/prod/_inne/sqlfluff/.venv/lib/python3.9/site-packages/click/core.py\", line 1137, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"/home/adam/prod/_inne/sqlfluff/.venv/lib/python3.9/site-packages/click/core.py\", line 1062, in main\r\n    rv = self.invoke(ctx)\r\n  File \"/home/adam/prod/_inne/sqlfluff/.venv/lib/python3.9/site-packages/click/core.py\", line 1668, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"/home/adam/prod/_inne/sqlfluff/.venv/lib/python3.9/site-packages/click/core.py\", line 1404, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"/home/adam/prod/_inne/sqlfluff/.venv/lib/python3.9/site-packages/click/core.py\", line 763, in invoke\r\n    return __callback(*args, **kwargs)\r\n  File \"/home/adam/prod/_inne/sqlfluff/src/sqlfluff/cli/commands.py\", line 347, in lint\r\n    result = lnt.lint_string_wrapped(sys.stdin.read(), fname=\"stdin\")\r\n  File \"/home/adam/prod/_inne/sqlfluff/src/sqlfluff/core/linter/linter.py\", line 789, in lint_string_wrapped\r\n    linted_path.add(self.lint_string(string, fname=fname, fix=fix))\r\n  File \"/home/adam/prod/_inne/sqlfluff/src/sqlfluff/core/linter/linter.py\", line 668, in lint_string\r\n    parsed = self.parse_string(in_str=in_str, fname=fname, config=config)\r\n  File \"/home/adam/prod/_inne/sqlfluff/src/sqlfluff/core/linter/linter.py\", line 607, in parse_string\r\n    return self.parse_rendered(rendered, recurse=recurse)\r\n  File \"/home/adam/prod/_inne/sqlfluff/src/sqlfluff/core/linter/linter.py\", line 313, in parse_rendered\r\n    parsed, pvs = cls._parse_tokens(\r\n  File \"/home/adam/prod/_inne/sqlfluff/src/sqlfluff/core/linter/linter.py\", line 190, in _parse_tokens\r\n    parsed: Optional[BaseSegment] = parser.parse(\r\n  File \"/home/adam/prod/_inne/sqlfluff/src/sqlfluff/core/parser/parser.py\", line 32, in parse\r\n    parsed = root_segment.parse(parse_context=ctx)\r\n  File \"/home/adam/prod/_inne/sqlfluff/src/sqlfluff/core/parser/segments/base.py\", line 821, in parse\r\n    check_still_complete(segments, m.matched_segments, m.unmatched_segments)\r\n  File \"/home/adam/prod/_inne/sqlfluff/src/sqlfluff/core/parser/helpers.py\", line 30, in check_still_complete\r\n    raise RuntimeError(\r\nRuntimeError: Dropped elements in sequence matching! 'select id from tbl;;' != ';'\r\n\r\n```\r\n## Steps to Reproduce\r\nRun \r\n```console\r\necho \"select id from tbl;;\" | sqlfluff lint -\r\n```\r\n## Dialect\r\ndefault (ansi)\r\n## Version\r\n```\r\nsqlfluff, version 0.6.6\r\nPython 3.9.5\r\n```\r\n## Configuration\r\nNone\r\n\n", "pr_diff": "diff --git a/src/sqlfluff/core/parser/helpers.py b/src/sqlfluff/core/parser/helpers.py\n--- a/src/sqlfluff/core/parser/helpers.py\n+++ b/src/sqlfluff/core/parser/helpers.py\n@@ -2,6 +2,7 @@\n \n from typing import Tuple, List, Any, Iterator, TYPE_CHECKING\n \n+from sqlfluff.core.errors import SQLParseError\n from sqlfluff.core.string_helpers import curtail_string\n \n if TYPE_CHECKING:\n@@ -26,11 +27,11 @@ def check_still_complete(\n     \"\"\"Check that the segments in are the same as the segments out.\"\"\"\n     initial_str = join_segments_raw(segments_in)\n     current_str = join_segments_raw(matched_segments + unmatched_segments)\n-    if initial_str != current_str:  # pragma: no cover\n-        raise RuntimeError(\n-            \"Dropped elements in sequence matching! {!r} != {!r}\".format(\n-                initial_str, current_str\n-            )\n+\n+    if initial_str != current_str:\n+        raise SQLParseError(\n+            f\"Could not parse: {current_str}\",\n+            segment=unmatched_segments[0],\n         )\n     return True\n \n", "solution": "diff --git a/src/sqlfluff/core/parser/helpers.py b/src/sqlfluff/core/parser/helpers.py\n--- a/src/sqlfluff/core/parser/helpers.py\n+++ b/src/sqlfluff/core/parser/helpers.py\n@@ -2,6 +2,7 @@\n \n from typing import Tuple, List, Any, Iterator, TYPE_CHECKING\n \n+from sqlfluff.core.errors import SQLParseError\n from sqlfluff.core.string_helpers import curtail_string\n \n if TYPE_CHECKING:\n@@ -26,11 +27,11 @@ def check_still_complete(\n     \"\"\"Check that the segments in are the same as the segments out.\"\"\"\n     initial_str = join_segments_raw(segments_in)\n     current_str = join_segments_raw(matched_segments + unmatched_segments)\n-    if initial_str != current_str:  # pragma: no cover\n-        raise RuntimeError(\n-            \"Dropped elements in sequence matching! {!r} != {!r}\".format(\n-                initial_str, current_str\n-            )\n+\n+    if initial_str != current_str:\n+        raise SQLParseError(\n+            f\"Could not parse: {current_str}\",\n+            segment=unmatched_segments[0],\n         )\n     return True\n \n", "test_command": "[\"test/dialects/ansi_test.py::test__dialect__ansi_multiple_semicolons[select\"]", "test_commands": ["[\"test/dialects/ansi_test.py::test__dialect__ansi_multiple_semicolons[select\"]", "[\"test/dialects/ansi_test.py::test__dialect__ansi__file_lex[a\", \"test/dialects/ansi_test.py::test__dialect__ansi__file_lex[b.c-res1]\", \"test/dialects/ansi_test.py::test__dialect__ansi__file_lex[abc\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[SelectKeywordSegment-select]\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[NakedIdentifierSegment-online_sales]\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[BareFunctionSegment-current_timestamp]\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[FunctionSegment-current_timestamp()]\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[NumericLiteralSegment-1000.0]\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[ExpressionSegment-online_sales\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[IntervalExpressionSegment-INTERVAL\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[ExpressionSegment-CASE\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[ExpressionSegment-CAST(ROUND(online_sales\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[ExpressionSegment-name\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[SelectClauseElementSegment-MIN\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[ExpressionSegment-DATE_ADD(CURRENT_DATE('America/New_York'),\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[ExpressionSegment-my_array[1]]\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[ExpressionSegment-my_array[OFFSET(1)]]\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[ExpressionSegment-my_array[5:8]]\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[ExpressionSegment-4\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[ExpressionSegment-bits[OFFSET(0)]\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[SelectClauseElementSegment-(count_18_24\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[ExpressionSegment-count_18_24\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[SelectStatementSegment-SELECT\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[SelectClauseElementSegment-t.val/t.id]\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[SelectClauseElementSegment-CAST(num\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[SelectClauseElementSegment-a.*]\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[SelectClauseElementSegment-a.b.*]\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[SelectClauseElementSegment-a.b.c.*]\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[ObjectReferenceSegment-a..c.*]\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[SelectClauseElementSegment--some_variable]\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[SelectClauseElementSegment--\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[ExpressionSegment-concat(left(uaid,\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[ExpressionSegment-c\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[SelectClauseElementSegment-c\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[ExpressionSegment-NULL::INT]\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[SelectClauseElementSegment-NULL::INT\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_parses[TruncateStatementSegment-TRUNCATE\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_not_match[ObjectReferenceSegment-\\\\n\", \"test/dialects/ansi_test.py::test__dialect__ansi_specific_segment_not_parse[SELECT\", \"test/dialects/ansi_test.py::test__dialect__ansi_is_whitespace\", \"test/dialects/ansi_test.py::test__dialect__ansi_parse_indented_joins[select\", \"test/dialects/ansi_test.py::test__dialect__ansi_multiple_semicolons[;;-Line\"]"], "files_to_edit": ["src/sqlfluff/core/parser/helpers.py"], "metadata": {"hints_text": "Sounds similar to #1458 where we should handle \"empty\" statement/files better?\nNope, that's the different issue. I doubt that solving one of them would help in other one. I think both issues should stay, just in the case.\nBut what do you think @tunetheweb - should it just ignore these `;;` or raise something like `Found unparsable section:`? \nJust tested and in BigQuery it's an error.\r\nInterestingly Oracle is fine with it.\r\n\r\nI think it should be raised as `Found unparsable section`.", "created_at": "2021-10-06T07:57:35Z", "version": "0.6", "test_patch": "diff --git a/test/dialects/ansi_test.py b/test/dialects/ansi_test.py\n--- a/test/dialects/ansi_test.py\n+++ b/test/dialects/ansi_test.py\n@@ -3,7 +3,7 @@\n import pytest\n import logging\n \n-from sqlfluff.core import FluffConfig, Linter\n+from sqlfluff.core import FluffConfig, Linter, SQLParseError\n from sqlfluff.core.parser import Lexer\n \n \n@@ -214,3 +214,29 @@ def test__dialect__ansi_parse_indented_joins(sql_string, indented_joins, meta_lo\n         idx for idx, raw_seg in enumerate(parsed.tree.iter_raw_seg()) if raw_seg.is_meta\n     )\n     assert res_meta_locs == meta_loc\n+\n+\n+@pytest.mark.parametrize(\n+    \"raw,expected_message\",\n+    [\n+        (\";;\", \"Line 1, Position 1: Found unparsable section: ';;'\"),\n+        (\"select id from tbl;\", \"\"),\n+        (\"select id from tbl;;\", \"Could not parse: ;\"),\n+        (\"select id from tbl;;;;;;\", \"Could not parse: ;;;;;\"),\n+        (\"select id from tbl;select id2 from tbl2;\", \"\"),\n+        (\n+            \"select id from tbl;;select id2 from tbl2;\",\n+            \"Could not parse: ;select id2 from tbl2;\",\n+        ),\n+    ],\n+)\n+def test__dialect__ansi_multiple_semicolons(raw: str, expected_message: str) -> None:\n+    \"\"\"Multiple semicolons should be properly handled.\"\"\"\n+    lnt = Linter()\n+    parsed = lnt.parse_string(raw)\n+\n+    assert len(parsed.violations) == (1 if expected_message else 0)\n+    if expected_message:\n+        violation = parsed.violations[0]\n+        assert isinstance(violation, SQLParseError)\n+        assert violation.desc() == expected_message\n", "environment_setup_commit": "67023b85c41d23d6c6d69812a41b207c4f8a9331"}}
{"problem_id": "sqlfluff__sqlfluff-1763", "repo_owner": "sqlfluff", "repo_name": "sqlfluff", "repo_url": "https://github.com/sqlfluff/sqlfluff", "base_commit": "a10057635e5b2559293a676486f0b730981f037a", "problem": "dbt postgres fix command errors with UnicodeEncodeError and also wipes the .sql file\n_If this is a parsing or linting issue, please include a minimal SQL example which reproduces the issue, along with the `sqlfluff parse` output, `sqlfluff lint` output and `sqlfluff fix` output when relevant._\r\n\r\n## Expected Behaviour\r\nViolation failure notice at a minimum, without wiping the file. Would like a way to ignore the known error at a minimum as --noqa is not getting past this. Actually would expect --noqa to totally ignore this.\r\n\r\n## Observed Behaviour\r\nReported error: `UnicodeEncodeError: 'charmap' codec can't encode character '\\u2192' in position 120: character maps to <undefined>`\r\n\r\n## Steps to Reproduce\r\nSQL file:\r\n```sql\r\nSELECT\r\n    reacted_table_name_right.descendant_id AS category_id,\r\n    string_agg(redacted_table_name_left.name, ' \u2192 ' ORDER BY reacted_table_name_right.generations DESC) AS breadcrumbs -- noqa\r\nFROM {{ ref2('redacted_schema_name', 'redacted_table_name_left') }} AS redacted_table_name_left\r\nINNER JOIN {{ ref2('redacted_schema_name', 'reacted_table_name_right') }} AS reacted_table_name_right\r\n    ON redacted_table_name_left.id = order_issue_category_hierarchies.ancestor_id\r\nGROUP BY reacted_table_name_right.descendant_id\r\n```\r\nRunning `sqlfluff fix --ignore templating,parsing,lexing -vvvv` and accepting proposed fixes for linting violations.\r\n\r\n## Dialect\r\n`postgres`, with `dbt` templater\r\n\r\n## Version\r\n`python 3.7.12`\r\n`sqlfluff 0.7.0`\r\n`sqlfluff-templater-dbt 0.7.0`\r\n\r\n## Configuration\r\nI've tried a few, here's one:\r\n```\r\n[sqlfluff]\r\nverbose = 2\r\ndialect = postgres\r\ntemplater = dbt\r\nexclude_rules = None\r\noutput_line_length = 80\r\nrunaway_limit = 10\r\nignore_templated_areas = True\r\nprocesses = 3\r\n# Comma separated list of file extensions to lint.\r\n\r\n# NB: This config will only apply in the root folder.\r\nsql_file_exts = .sql\r\n\r\n[sqlfluff:indentation]\r\nindented_joins = False\r\nindented_using_on = True\r\ntemplate_blocks_indent = True\r\n\r\n[sqlfluff:templater]\r\nunwrap_wrapped_queries = True\r\n\r\n[sqlfluff:templater:jinja]\r\napply_dbt_builtins = True\r\n\r\n[sqlfluff:templater:jinja:macros]\r\n# Macros provided as builtins for dbt projects\r\ndbt_ref = {% macro ref(model_ref) %}{{model_ref}}{% endmacro %}\r\ndbt_source = {% macro source(source_name, table) %}{{source_name}}_{{table}}{% endmacro %}\r\ndbt_config = {% macro config() %}{% for k in kwargs %}{% endfor %}{% endmacro %}\r\ndbt_var = {% macro var(variable, default='') %}item{% endmacro %}\r\ndbt_is_incremental = {% macro is_incremental() %}True{% endmacro %}\r\n\r\n# Common config across rules\r\n[sqlfluff:rules]\r\ntab_space_size = 4\r\nindent_unit = space\r\nsingle_table_references = consistent\r\nunquoted_identifiers_policy = all\r\n\r\n# L001 - Remove trailing whitespace (fix)\r\n# L002 - Single section of whitespace should not contain both tabs and spaces (fix)\r\n# L003 - Keep consistent indentation (fix)\r\n# L004 - We use 4 spaces for indentation just for completeness (fix)\r\n# L005 - Remove space before commas (fix)\r\n# L006 - Operators (+, -, *, /) will be wrapped by a single space each side (fix)\r\n\r\n# L007 - Operators should not be at the end of a line\r\n[sqlfluff:rules:L007]  # Keywords\r\noperator_new_lines = after\r\n\r\n# L008 - Always use a single whitespace after a comma (fix)\r\n# L009 - Files will always end with a trailing newline\r\n\r\n# L010 - All keywords will use full upper case (fix)\r\n[sqlfluff:rules:L010]  # Keywords\r\ncapitalisation_policy = upper\r\n\r\n# L011 - Always explicitly alias tables (fix)\r\n[sqlfluff:rules:L011]  # Aliasing\r\naliasing = explicit\r\n\r\n# L012 - Do not have to explicitly alias all columns\r\n[sqlfluff:rules:L012]  # Aliasing\r\naliasing = explicit\r\n\r\n# L013 - Always explicitly alias a column with an expression in it (fix)\r\n[sqlfluff:rules:L013]  # Aliasing\r\nallow_scalar = False\r\n\r\n# L014 - Always user full lower case for 'quoted identifiers' -> column refs. without an alias (fix)\r\n[sqlfluff:rules:L014]  # Unquoted identifiers\r\nextended_capitalisation_policy = lower\r\n\r\n# L015 - Always remove parenthesis when using DISTINCT to be clear that DISTINCT applies to all columns (fix)\r\n\r\n# L016 - Lines should be 120 characters of less. Comment lines should not be ignored (fix)\r\n[sqlfluff:rules:L016]\r\nignore_comment_lines = False\r\nmax_line_length = 120\r\n\r\n# L017 - There should not be whitespace between function name and brackets (fix)\r\n# L018 - Always align closing bracket of WITH to the WITH keyword (fix)\r\n\r\n# L019 - Always use trailing commas / commas at the end of the line (fix)\r\n[sqlfluff:rules:L019]\r\ncomma_style = trailing\r\n\r\n# L020 - Table aliases will always be unique per statement\r\n# L021 - Remove any use of ambiguous DISTINCT and GROUP BY combinations. Lean on removing the GROUP BY.\r\n# L022 - Add blank lines after common table expressions (CTE) / WITH.\r\n# L023 - Always add a single whitespace after AS in a WITH clause (fix)\r\n\r\n[sqlfluff:rules:L026]\r\nforce_enable = False\r\n\r\n# L027 - Always add references if more than one referenced table or view is used\r\n\r\n[sqlfluff:rules:L028]\r\nforce_enable = False\r\n\r\n[sqlfluff:rules:L029]  # Keyword identifiers\r\nunquoted_identifiers_policy = aliases\r\n\r\n[sqlfluff:rules:L030]  # Function names\r\ncapitalisation_policy = upper\r\n\r\n# L032 - We prefer use of join keys rather than USING\r\n# L034 - We prefer ordering of columns in select statements as (fix):\r\n# 1. wildcards\r\n# 2. single identifiers\r\n# 3. calculations and aggregates\r\n\r\n# L035 - Omit 'else NULL'; it is redundant (fix)\r\n# L036 - Move select targets / identifiers onto new lines each (fix)\r\n# L037 - When using ORDER BY, make the direction explicit (fix)\r\n\r\n# L038 - Never use trailing commas at the end of the SELECT clause\r\n[sqlfluff:rules:L038]\r\nselect_clause_trailing_comma = forbid\r\n\r\n# L039 - Remove unnecessary whitespace (fix)\r\n\r\n[sqlfluff:rules:L040]  # Null & Boolean Literals\r\ncapitalisation_policy = upper\r\n\r\n# L042 - Join clauses should not contain subqueries. Use common tables expressions (CTE) instead.\r\n[sqlfluff:rules:L042]\r\n# By default, allow subqueries in from clauses, but not join clauses.\r\nforbid_subquery_in = join\r\n\r\n# L043 - Reduce CASE WHEN conditions to COALESCE (fix)\r\n# L044 - Prefer a known number of columns along the path to the source data\r\n# L045 - Remove unused common tables expressions (CTE) / WITH statements (fix)\r\n# L046 - Jinja tags should have a single whitespace on both sides\r\n\r\n# L047 - Use COUNT(*) instead of COUNT(0) or COUNT(1) alternatives (fix)\r\n[sqlfluff:rules:L047]  # Consistent syntax to count all rows\r\nprefer_count_1 = False\r\nprefer_count_0 = False\r\n\r\n# L048 - Quoted literals should be surrounded by a single whitespace (fix)\r\n# L049 - Always use IS or IS NOT for comparisons with NULL (fix)\r\n```\r\n\n", "issue_title": "Fix issue in sqlfluff/sqlfluff", "issue_body": "dbt postgres fix command errors with UnicodeEncodeError and also wipes the .sql file\n_If this is a parsing or linting issue, please include a minimal SQL example which reproduces the issue, along with the `sqlfluff parse` output, `sqlfluff lint` output and `sqlfluff fix` output when relevant._\r\n\r\n## Expected Behaviour\r\nViolation failure notice at a minimum, without wiping the file. Would like a way to ignore the known error at a minimum as --noqa is not getting past this. Actually would expect --noqa to totally ignore this.\r\n\r\n## Observed Behaviour\r\nReported error: `UnicodeEncodeError: 'charmap' codec can't encode character '\\u2192' in position 120: character maps to <undefined>`\r\n\r\n## Steps to Reproduce\r\nSQL file:\r\n```sql\r\nSELECT\r\n    reacted_table_name_right.descendant_id AS category_id,\r\n    string_agg(redacted_table_name_left.name, ' \u2192 ' ORDER BY reacted_table_name_right.generations DESC) AS breadcrumbs -- noqa\r\nFROM {{ ref2('redacted_schema_name', 'redacted_table_name_left') }} AS redacted_table_name_left\r\nINNER JOIN {{ ref2('redacted_schema_name', 'reacted_table_name_right') }} AS reacted_table_name_right\r\n    ON redacted_table_name_left.id = order_issue_category_hierarchies.ancestor_id\r\nGROUP BY reacted_table_name_right.descendant_id\r\n```\r\nRunning `sqlfluff fix --ignore templating,parsing,lexing -vvvv` and accepting proposed fixes for linting violations.\r\n\r\n## Dialect\r\n`postgres`, with `dbt` templater\r\n\r\n## Version\r\n`python 3.7.12`\r\n`sqlfluff 0.7.0`\r\n`sqlfluff-templater-dbt 0.7.0`\r\n\r\n## Configuration\r\nI've tried a few, here's one:\r\n```\r\n[sqlfluff]\r\nverbose = 2\r\ndialect = postgres\r\ntemplater = dbt\r\nexclude_rules = None\r\noutput_line_length = 80\r\nrunaway_limit = 10\r\nignore_templated_areas = True\r\nprocesses = 3\r\n# Comma separated list of file extensions to lint.\r\n\r\n# NB: This config will only apply in the root folder.\r\nsql_file_exts = .sql\r\n\r\n[sqlfluff:indentation]\r\nindented_joins = False\r\nindented_using_on = True\r\ntemplate_blocks_indent = True\r\n\r\n[sqlfluff:templater]\r\nunwrap_wrapped_queries = True\r\n\r\n[sqlfluff:templater:jinja]\r\napply_dbt_builtins = True\r\n\r\n[sqlfluff:templater:jinja:macros]\r\n# Macros provided as builtins for dbt projects\r\ndbt_ref = {% macro ref(model_ref) %}{{model_ref}}{% endmacro %}\r\ndbt_source = {% macro source(source_name, table) %}{{source_name}}_{{table}}{% endmacro %}\r\ndbt_config = {% macro config() %}{% for k in kwargs %}{% endfor %}{% endmacro %}\r\ndbt_var = {% macro var(variable, default='') %}item{% endmacro %}\r\ndbt_is_incremental = {% macro is_incremental() %}True{% endmacro %}\r\n\r\n# Common config across rules\r\n[sqlfluff:rules]\r\ntab_space_size = 4\r\nindent_unit = space\r\nsingle_table_references = consistent\r\nunquoted_identifiers_policy = all\r\n\r\n# L001 - Remove trailing whitespace (fix)\r\n# L002 - Single section of whitespace should not contain both tabs and spaces (fix)\r\n# L003 - Keep consistent indentation (fix)\r\n# L004 - We use 4 spaces for indentation just for completeness (fix)\r\n# L005 - Remove space before commas (fix)\r\n# L006 - Operators (+, -, *, /) will be wrapped by a single space each side (fix)\r\n\r\n# L007 - Operators should not be at the end of a line\r\n[sqlfluff:rules:L007]  # Keywords\r\noperator_new_lines = after\r\n\r\n# L008 - Always use a single whitespace after a comma (fix)\r\n# L009 - Files will always end with a trailing newline\r\n\r\n# L010 - All keywords will use full upper case (fix)\r\n[sqlfluff:rules:L010]  # Keywords\r\ncapitalisation_policy = upper\r\n\r\n# L011 - Always explicitly alias tables (fix)\r\n[sqlfluff:rules:L011]  # Aliasing\r\naliasing = explicit\r\n\r\n# L012 - Do not have to explicitly alias all columns\r\n[sqlfluff:rules:L012]  # Aliasing\r\naliasing = explicit\r\n\r\n# L013 - Always explicitly alias a column with an expression in it (fix)\r\n[sqlfluff:rules:L013]  # Aliasing\r\nallow_scalar = False\r\n\r\n# L014 - Always user full lower case for 'quoted identifiers' -> column refs. without an alias (fix)\r\n[sqlfluff:rules:L014]  # Unquoted identifiers\r\nextended_capitalisation_policy = lower\r\n\r\n# L015 - Always remove parenthesis when using DISTINCT to be clear that DISTINCT applies to all columns (fix)\r\n\r\n# L016 - Lines should be 120 characters of less. Comment lines should not be ignored (fix)\r\n[sqlfluff:rules:L016]\r\nignore_comment_lines = False\r\nmax_line_length = 120\r\n\r\n# L017 - There should not be whitespace between function name and brackets (fix)\r\n# L018 - Always align closing bracket of WITH to the WITH keyword (fix)\r\n\r\n# L019 - Always use trailing commas / commas at the end of the line (fix)\r\n[sqlfluff:rules:L019]\r\ncomma_style = trailing\r\n\r\n# L020 - Table aliases will always be unique per statement\r\n# L021 - Remove any use of ambiguous DISTINCT and GROUP BY combinations. Lean on removing the GROUP BY.\r\n# L022 - Add blank lines after common table expressions (CTE) / WITH.\r\n# L023 - Always add a single whitespace after AS in a WITH clause (fix)\r\n\r\n[sqlfluff:rules:L026]\r\nforce_enable = False\r\n\r\n# L027 - Always add references if more than one referenced table or view is used\r\n\r\n[sqlfluff:rules:L028]\r\nforce_enable = False\r\n\r\n[sqlfluff:rules:L029]  # Keyword identifiers\r\nunquoted_identifiers_policy = aliases\r\n\r\n[sqlfluff:rules:L030]  # Function names\r\ncapitalisation_policy = upper\r\n\r\n# L032 - We prefer use of join keys rather than USING\r\n# L034 - We prefer ordering of columns in select statements as (fix):\r\n# 1. wildcards\r\n# 2. single identifiers\r\n# 3. calculations and aggregates\r\n\r\n# L035 - Omit 'else NULL'; it is redundant (fix)\r\n# L036 - Move select targets / identifiers onto new lines each (fix)\r\n# L037 - When using ORDER BY, make the direction explicit (fix)\r\n\r\n# L038 - Never use trailing commas at the end of the SELECT clause\r\n[sqlfluff:rules:L038]\r\nselect_clause_trailing_comma = forbid\r\n\r\n# L039 - Remove unnecessary whitespace (fix)\r\n\r\n[sqlfluff:rules:L040]  # Null & Boolean Literals\r\ncapitalisation_policy = upper\r\n\r\n# L042 - Join clauses should not contain subqueries. Use common tables expressions (CTE) instead.\r\n[sqlfluff:rules:L042]\r\n# By default, allow subqueries in from clauses, but not join clauses.\r\nforbid_subquery_in = join\r\n\r\n# L043 - Reduce CASE WHEN conditions to COALESCE (fix)\r\n# L044 - Prefer a known number of columns along the path to the source data\r\n# L045 - Remove unused common tables expressions (CTE) / WITH statements (fix)\r\n# L046 - Jinja tags should have a single whitespace on both sides\r\n\r\n# L047 - Use COUNT(*) instead of COUNT(0) or COUNT(1) alternatives (fix)\r\n[sqlfluff:rules:L047]  # Consistent syntax to count all rows\r\nprefer_count_1 = False\r\nprefer_count_0 = False\r\n\r\n# L048 - Quoted literals should be surrounded by a single whitespace (fix)\r\n# L049 - Always use IS or IS NOT for comparisons with NULL (fix)\r\n```\r\n\n", "pr_diff": "diff --git a/src/sqlfluff/core/linter/linted_file.py b/src/sqlfluff/core/linter/linted_file.py\n--- a/src/sqlfluff/core/linter/linted_file.py\n+++ b/src/sqlfluff/core/linter/linted_file.py\n@@ -7,6 +7,8 @@\n \n import os\n import logging\n+import shutil\n+import tempfile\n from typing import (\n     Any,\n     Iterable,\n@@ -493,7 +495,24 @@ def persist_tree(self, suffix: str = \"\") -> bool:\n             if suffix:\n                 root, ext = os.path.splitext(fname)\n                 fname = root + suffix + ext\n-            # Actually write the file.\n-            with open(fname, \"w\", encoding=self.encoding) as f:\n-                f.write(write_buff)\n+            self._safe_create_replace_file(fname, write_buff, self.encoding)\n         return success\n+\n+    @staticmethod\n+    def _safe_create_replace_file(fname, write_buff, encoding):\n+        # Write to a temporary file first, so in case of encoding or other\n+        # issues, we don't delete or corrupt the user's existing file.\n+        dirname, basename = os.path.split(fname)\n+        with tempfile.NamedTemporaryFile(\n+            mode=\"w\",\n+            encoding=encoding,\n+            prefix=basename,\n+            dir=dirname,\n+            suffix=os.path.splitext(fname)[1],\n+            delete=False,\n+        ) as tmp:\n+            tmp.file.write(write_buff)\n+            tmp.flush()\n+            os.fsync(tmp.fileno())\n+        # Once the temp file is safely written, replace the existing file.\n+        shutil.move(tmp.name, fname)\n", "solution": "diff --git a/src/sqlfluff/core/linter/linted_file.py b/src/sqlfluff/core/linter/linted_file.py\n--- a/src/sqlfluff/core/linter/linted_file.py\n+++ b/src/sqlfluff/core/linter/linted_file.py\n@@ -7,6 +7,8 @@\n \n import os\n import logging\n+import shutil\n+import tempfile\n from typing import (\n     Any,\n     Iterable,\n@@ -493,7 +495,24 @@ def persist_tree(self, suffix: str = \"\") -> bool:\n             if suffix:\n                 root, ext = os.path.splitext(fname)\n                 fname = root + suffix + ext\n-            # Actually write the file.\n-            with open(fname, \"w\", encoding=self.encoding) as f:\n-                f.write(write_buff)\n+            self._safe_create_replace_file(fname, write_buff, self.encoding)\n         return success\n+\n+    @staticmethod\n+    def _safe_create_replace_file(fname, write_buff, encoding):\n+        # Write to a temporary file first, so in case of encoding or other\n+        # issues, we don't delete or corrupt the user's existing file.\n+        dirname, basename = os.path.split(fname)\n+        with tempfile.NamedTemporaryFile(\n+            mode=\"w\",\n+            encoding=encoding,\n+            prefix=basename,\n+            dir=dirname,\n+            suffix=os.path.splitext(fname)[1],\n+            delete=False,\n+        ) as tmp:\n+            tmp.file.write(write_buff)\n+            tmp.flush()\n+            os.fsync(tmp.fileno())\n+        # Once the temp file is safely written, replace the existing file.\n+        shutil.move(tmp.name, fname)\n", "test_command": "[\"test/core/linter_test.py::test_safe_create_replace_file[utf8_create]\", \"test/core/linter_test.py::test_safe_create_replace_file[utf8_update]\", \"test/core/linter_test.py::test_safe_create_replace_file[utf8_special_char]\"]", "test_commands": ["[\"test/core/linter_test.py::test_safe_create_replace_file[utf8_create]\", \"test/core/linter_test.py::test_safe_create_replace_file[utf8_update]\", \"test/core/linter_test.py::test_safe_create_replace_file[utf8_special_char]\"]", "[\"test/core/linter_test.py::test__linter__path_from_paths__dir\", \"test/core/linter_test.py::test__linter__path_from_paths__default\", \"test/core/linter_test.py::test__linter__path_from_paths__exts\", \"test/core/linter_test.py::test__linter__path_from_paths__file\", \"test/core/linter_test.py::test__linter__path_from_paths__not_exist\", \"test/core/linter_test.py::test__linter__path_from_paths__not_exist_ignore\", \"test/core/linter_test.py::test__linter__path_from_paths__explicit_ignore\", \"test/core/linter_test.py::test__linter__path_from_paths__dot\", \"test/core/linter_test.py::test__linter__path_from_paths__ignore[test/fixtures/linter/sqlfluffignore]\", \"test/core/linter_test.py::test__linter__path_from_paths__ignore[test/fixtures/linter/sqlfluffignore/]\", \"test/core/linter_test.py::test__linter__path_from_paths__ignore[test/fixtures/linter/sqlfluffignore/.]\", \"test/core/linter_test.py::test__linter__lint_string_vs_file[test/fixtures/linter/indentation_errors.sql]\", \"test/core/linter_test.py::test__linter__lint_string_vs_file[test/fixtures/linter/whitespace_errors.sql]\", \"test/core/linter_test.py::test__linter__get_violations_filter_rules[None-7]\", \"test/core/linter_test.py::test__linter__get_violations_filter_rules[L010-2]\", \"test/core/linter_test.py::test__linter__get_violations_filter_rules[rules2-2]\", \"test/core/linter_test.py::test__linter__linting_result__sum_dicts\", \"test/core/linter_test.py::test__linter__linting_result__combine_dicts\", \"test/core/linter_test.py::test__linter__linting_result_check_tuples_by_path[False-list]\", \"test/core/linter_test.py::test__linter__linting_result_check_tuples_by_path[True-dict]\", \"test/core/linter_test.py::test__linter__linting_result_get_violations[1]\", \"test/core/linter_test.py::test__linter__linting_result_get_violations[2]\", \"test/core/linter_test.py::test__linter__linting_parallel_thread[False]\", \"test/core/linter_test.py::test__linter__linting_parallel_thread[True]\", \"test/core/linter_test.py::test_lint_path_parallel_wrapper_exception\", \"test/core/linter_test.py::test__linter__linting_unexpected_error_handled_gracefully\", \"test/core/linter_test.py::test__linter__raises_malformed_noqa\", \"test/core/linter_test.py::test__linter__empty_file\", \"test/core/linter_test.py::test__linter__mask_templated_violations[True-check_tuples0]\", \"test/core/linter_test.py::test__linter__mask_templated_violations[False-check_tuples1]\", \"test/core/linter_test.py::test__linter__encoding[test/fixtures/linter/encoding-utf-8.sql-autodetect-False]\", \"test/core/linter_test.py::test__linter__encoding[test/fixtures/linter/encoding-utf-8-sig.sql-autodetect-False]\", \"test/core/linter_test.py::test__linter__encoding[test/fixtures/linter/encoding-utf-8.sql-utf-8-False]\", \"test/core/linter_test.py::test__linter__encoding[test/fixtures/linter/encoding-utf-8-sig.sql-utf-8-True]\", \"test/core/linter_test.py::test__linter__encoding[test/fixtures/linter/encoding-utf-8.sql-utf-8-sig-False]\", \"test/core/linter_test.py::test__linter__encoding[test/fixtures/linter/encoding-utf-8-sig.sql-utf-8-sig-False]\", \"test/core/linter_test.py::test_parse_noqa[-None]\", \"test/core/linter_test.py::test_parse_noqa[noqa-expected1]\", \"test/core/linter_test.py::test_parse_noqa[noqa?-SQLParseError]\", \"test/core/linter_test.py::test_parse_noqa[noqa:-expected3]\", \"test/core/linter_test.py::test_parse_noqa[noqa:L001,L002-expected4]\", \"test/core/linter_test.py::test_parse_noqa[noqa:\", \"test/core/linter_test.py::test_linted_file_ignore_masked_violations[1_violation_no_ignore]\", \"test/core/linter_test.py::test_linted_file_ignore_masked_violations[1_violation_ignore_specific_line]\", \"test/core/linter_test.py::test_linted_file_ignore_masked_violations[1_violation_ignore_different_specific_line]\", \"test/core/linter_test.py::test_linted_file_ignore_masked_violations[1_violation_ignore_different_specific_rule]\", \"test/core/linter_test.py::test_linted_file_ignore_masked_violations[1_violation_ignore_enable_this_range]\", \"test/core/linter_test.py::test_linted_file_ignore_masked_violations[1_violation_ignore_disable_this_range]\", \"test/core/linter_test.py::test_linted_file_ignore_masked_violations[1_violation_line_1_ignore_disable_specific_2_3]\", \"test/core/linter_test.py::test_linted_file_ignore_masked_violations[1_violation_line_2_ignore_disable_specific_2_3]\", \"test/core/linter_test.py::test_linted_file_ignore_masked_violations[1_violation_line_3_ignore_disable_specific_2_3]\", \"test/core/linter_test.py::test_linted_file_ignore_masked_violations[1_violation_line_4_ignore_disable_specific_2_3]\", \"test/core/linter_test.py::test_linted_file_ignore_masked_violations[1_violation_line_1_ignore_disable_all_2_3]\", \"test/core/linter_test.py::test_linted_file_ignore_masked_violations[1_violation_line_2_ignore_disable_all_2_3]\", \"test/core/linter_test.py::test_linted_file_ignore_masked_violations[1_violation_line_3_ignore_disable_all_2_3]\", \"test/core/linter_test.py::test_linted_file_ignore_masked_violations[1_violation_line_4_ignore_disable_all_2_3]\", \"test/core/linter_test.py::test_linted_file_ignore_masked_violations[4_violations_two_types_disable_specific_enable_all]\", \"test/core/linter_test.py::test_linted_file_ignore_masked_violations[4_violations_two_types_disable_all_enable_specific]\", \"test/core/linter_test.py::test_linter_noqa\", \"test/core/linter_test.py::test_linter_noqa_with_templating\", \"test/core/linter_test.py::test_delayed_exception\", \"test/core/linter_test.py::test__attempt_to_change_templater_warning\", \"test/core/linter_test.py::test_safe_create_replace_file[incorrect_encoding]\"]"], "files_to_edit": ["src/sqlfluff/core/linter/linted_file.py"], "metadata": {"hints_text": "I get a dbt-related error -- can you provide your project file as well? Also, what operating system are you running this on? I tested a simplified (non-dbt) version of your file on my Mac, and it worked okay.\r\n\r\n```\r\ndbt.exceptions.DbtProjectError: Runtime Error\r\n  no dbt_project.yml found at expected path /Users/bhart/dev/sqlfluff/dbt_project.yml\r\n```\nNever mind the questions above -- I managed to reproduce the error in a sample dbt project. Taking a look now...\n@Tumble17: Have you tried setting the `encoding` parameter in `.sqlfluff`? Do you know what encoding you're using? The default is `autodetect`, and SQLFluff \"thinks\" the file uses \"Windows-1252\" encoding, which I assume is incorrect -- that's why SQLFluff is unable to write out the updated file.\nI added this line to the first section of your `.sqlfluff`, and now it seems to work. I'll look into changing the behavior of `sqlfluff fix` so it doesn't erase the file when it fails.\r\n\r\n```\r\nencoding = utf-8\r\n```", "created_at": "2021-10-26T17:28:28Z", "version": "0.6", "test_patch": "diff --git a/test/core/linter_test.py b/test/core/linter_test.py\n--- a/test/core/linter_test.py\n+++ b/test/core/linter_test.py\n@@ -641,3 +641,56 @@ def test__attempt_to_change_templater_warning(caplog):\n         assert \"Attempt to set templater to \" in caplog.text\n     finally:\n         logger.propagate = original_propagate_value\n+\n+\n+@pytest.mark.parametrize(\n+    \"case\",\n+    [\n+        dict(\n+            name=\"utf8_create\",\n+            fname=\"test.sql\",\n+            encoding=\"utf-8\",\n+            existing=None,\n+            update=\"def\",\n+            expected=\"def\",\n+        ),\n+        dict(\n+            name=\"utf8_update\",\n+            fname=\"test.sql\",\n+            encoding=\"utf-8\",\n+            existing=\"abc\",\n+            update=\"def\",\n+            expected=\"def\",\n+        ),\n+        dict(\n+            name=\"utf8_special_char\",\n+            fname=\"test.sql\",\n+            encoding=\"utf-8\",\n+            existing=\"abc\",\n+            update=\"\u2192\",  # Special utf-8 character\n+            expected=\"\u2192\",\n+        ),\n+        dict(\n+            name=\"incorrect_encoding\",\n+            fname=\"test.sql\",\n+            encoding=\"Windows-1252\",\n+            existing=\"abc\",\n+            update=\"\u2192\",  # Not valid in Windows-1252\n+            expected=\"abc\",  # File should be unchanged\n+        ),\n+    ],\n+    ids=lambda case: case[\"name\"],\n+)\n+def test_safe_create_replace_file(case, tmp_path):\n+    \"\"\"Test creating or updating .sql files, various content and encoding.\"\"\"\n+    p = tmp_path / case[\"fname\"]\n+    if case[\"existing\"]:\n+        p.write_text(case[\"existing\"])\n+    try:\n+        linter.LintedFile._safe_create_replace_file(\n+            str(p), case[\"update\"], case[\"encoding\"]\n+        )\n+    except:  # noqa: E722\n+        pass\n+    actual = p.read_text(encoding=case[\"encoding\"])\n+    assert case[\"expected\"] == actual\n", "environment_setup_commit": "67023b85c41d23d6c6d69812a41b207c4f8a9331"}}
{"problem_id": "marshmallow-code__marshmallow-1359", "repo_owner": "marshmallow-code", "repo_name": "marshmallow", "repo_url": "https://github.com/marshmallow-code/marshmallow", "base_commit": "b40a0f4e33823e6d0f341f7e8684e359a99060d1", "problem": "3.0: DateTime fields cannot be used as inner field for List or Tuple fields\nBetween releases 3.0.0rc8 and 3.0.0rc9, `DateTime` fields have started throwing an error when being instantiated as inner fields of container fields like `List` or `Tuple`. The snippet below works in <=3.0.0rc8 and throws the error below in >=3.0.0rc9 (and, worryingly, 3.0.0):\r\n\r\n```python\r\nfrom marshmallow import fields, Schema\r\n\r\nclass MySchema(Schema):\r\n    times = fields.List(fields.DateTime())\r\n\r\ns = MySchema()\r\n```\r\n\r\nTraceback:\r\n```\r\nTraceback (most recent call last):\r\n  File \"test-mm.py\", line 8, in <module>\r\n    s = MySchema()\r\n  File \"/Users/victor/.pyenv/versions/marshmallow/lib/python3.6/site-packages/marshmallow/schema.py\", line 383, in __init__\r\n    self.fields = self._init_fields()\r\n  File \"/Users/victor/.pyenv/versions/marshmallow/lib/python3.6/site-packages/marshmallow/schema.py\", line 913, in _init_fields\r\n    self._bind_field(field_name, field_obj)\r\n  File \"/Users/victor/.pyenv/versions/marshmallow/lib/python3.6/site-packages/marshmallow/schema.py\", line 969, in _bind_field\r\n    field_obj._bind_to_schema(field_name, self)\r\n  File \"/Users/victor/.pyenv/versions/marshmallow/lib/python3.6/site-packages/marshmallow/fields.py\", line 636, in _bind_to_schema\r\n    self.inner._bind_to_schema(field_name, self)\r\n  File \"/Users/victor/.pyenv/versions/marshmallow/lib/python3.6/site-packages/marshmallow/fields.py\", line 1117, in _bind_to_schema\r\n    or getattr(schema.opts, self.SCHEMA_OPTS_VAR_NAME)\r\nAttributeError: 'List' object has no attribute 'opts'\r\n```\r\n\r\nIt seems like it's treating the parent field as a Schema without checking that it is indeed a schema, so the `schema.opts` statement fails as fields don't have an `opts` attribute.\n", "issue_title": "Fix issue in marshmallow-code/marshmallow", "issue_body": "3.0: DateTime fields cannot be used as inner field for List or Tuple fields\nBetween releases 3.0.0rc8 and 3.0.0rc9, `DateTime` fields have started throwing an error when being instantiated as inner fields of container fields like `List` or `Tuple`. The snippet below works in <=3.0.0rc8 and throws the error below in >=3.0.0rc9 (and, worryingly, 3.0.0):\r\n\r\n```python\r\nfrom marshmallow import fields, Schema\r\n\r\nclass MySchema(Schema):\r\n    times = fields.List(fields.DateTime())\r\n\r\ns = MySchema()\r\n```\r\n\r\nTraceback:\r\n```\r\nTraceback (most recent call last):\r\n  File \"test-mm.py\", line 8, in <module>\r\n    s = MySchema()\r\n  File \"/Users/victor/.pyenv/versions/marshmallow/lib/python3.6/site-packages/marshmallow/schema.py\", line 383, in __init__\r\n    self.fields = self._init_fields()\r\n  File \"/Users/victor/.pyenv/versions/marshmallow/lib/python3.6/site-packages/marshmallow/schema.py\", line 913, in _init_fields\r\n    self._bind_field(field_name, field_obj)\r\n  File \"/Users/victor/.pyenv/versions/marshmallow/lib/python3.6/site-packages/marshmallow/schema.py\", line 969, in _bind_field\r\n    field_obj._bind_to_schema(field_name, self)\r\n  File \"/Users/victor/.pyenv/versions/marshmallow/lib/python3.6/site-packages/marshmallow/fields.py\", line 636, in _bind_to_schema\r\n    self.inner._bind_to_schema(field_name, self)\r\n  File \"/Users/victor/.pyenv/versions/marshmallow/lib/python3.6/site-packages/marshmallow/fields.py\", line 1117, in _bind_to_schema\r\n    or getattr(schema.opts, self.SCHEMA_OPTS_VAR_NAME)\r\nAttributeError: 'List' object has no attribute 'opts'\r\n```\r\n\r\nIt seems like it's treating the parent field as a Schema without checking that it is indeed a schema, so the `schema.opts` statement fails as fields don't have an `opts` attribute.\n", "pr_diff": "diff --git a/src/marshmallow/fields.py b/src/marshmallow/fields.py\n--- a/src/marshmallow/fields.py\n+++ b/src/marshmallow/fields.py\n@@ -1114,7 +1114,7 @@ def _bind_to_schema(self, field_name, schema):\n         super()._bind_to_schema(field_name, schema)\n         self.format = (\n             self.format\n-            or getattr(schema.opts, self.SCHEMA_OPTS_VAR_NAME)\n+            or getattr(self.root.opts, self.SCHEMA_OPTS_VAR_NAME)\n             or self.DEFAULT_FORMAT\n         )\n \n", "solution": "diff --git a/src/marshmallow/fields.py b/src/marshmallow/fields.py\n--- a/src/marshmallow/fields.py\n+++ b/src/marshmallow/fields.py\n@@ -1114,7 +1114,7 @@ def _bind_to_schema(self, field_name, schema):\n         super()._bind_to_schema(field_name, schema)\n         self.format = (\n             self.format\n-            or getattr(schema.opts, self.SCHEMA_OPTS_VAR_NAME)\n+            or getattr(self.root.opts, self.SCHEMA_OPTS_VAR_NAME)\n             or self.DEFAULT_FORMAT\n         )\n \n", "test_command": "[\"tests/test_fields.py::TestParentAndName::test_datetime_list_inner_format\"]", "test_commands": ["[\"tests/test_fields.py::TestParentAndName::test_datetime_list_inner_format\"]", "[\"tests/test_fields.py::test_field_aliases[Integer-Integer]\", \"tests/test_fields.py::test_field_aliases[String-String]\", \"tests/test_fields.py::test_field_aliases[Boolean-Boolean]\", \"tests/test_fields.py::test_field_aliases[Url-Url]\", \"tests/test_fields.py::TestField::test_repr\", \"tests/test_fields.py::TestField::test_error_raised_if_uncallable_validator_passed\", \"tests/test_fields.py::TestField::test_error_raised_if_missing_is_set_on_required_field\", \"tests/test_fields.py::TestField::test_custom_field_receives_attr_and_obj\", \"tests/test_fields.py::TestField::test_custom_field_receives_data_key_if_set\", \"tests/test_fields.py::TestField::test_custom_field_follows_data_key_if_set\", \"tests/test_fields.py::TestParentAndName::test_simple_field_parent_and_name\", \"tests/test_fields.py::TestParentAndName::test_unbound_field_root_returns_none\", \"tests/test_fields.py::TestParentAndName::test_list_field_inner_parent_and_name\", \"tests/test_fields.py::TestParentAndName::test_tuple_field_inner_parent_and_name\", \"tests/test_fields.py::TestParentAndName::test_mapping_field_inner_parent_and_name\", \"tests/test_fields.py::TestParentAndName::test_simple_field_root\", \"tests/test_fields.py::TestParentAndName::test_list_field_inner_root\", \"tests/test_fields.py::TestParentAndName::test_tuple_field_inner_root\", \"tests/test_fields.py::TestParentAndName::test_list_root_inheritance\", \"tests/test_fields.py::TestParentAndName::test_dict_root_inheritance\", \"tests/test_fields.py::TestMetadata::test_extra_metadata_may_be_added_to_field[String]\", \"tests/test_fields.py::TestMetadata::test_extra_metadata_may_be_added_to_field[Integer]\", \"tests/test_fields.py::TestMetadata::test_extra_metadata_may_be_added_to_field[Boolean]\", \"tests/test_fields.py::TestMetadata::test_extra_metadata_may_be_added_to_field[Float]\", \"tests/test_fields.py::TestMetadata::test_extra_metadata_may_be_added_to_field[Number]\", \"tests/test_fields.py::TestMetadata::test_extra_metadata_may_be_added_to_field[DateTime]\", \"tests/test_fields.py::TestMetadata::test_extra_metadata_may_be_added_to_field[Time]\", \"tests/test_fields.py::TestMetadata::test_extra_metadata_may_be_added_to_field[Date]\", \"tests/test_fields.py::TestMetadata::test_extra_metadata_may_be_added_to_field[TimeDelta]\", \"tests/test_fields.py::TestMetadata::test_extra_metadata_may_be_added_to_field[Dict]\", \"tests/test_fields.py::TestMetadata::test_extra_metadata_may_be_added_to_field[Url]\", \"tests/test_fields.py::TestMetadata::test_extra_metadata_may_be_added_to_field[Email]\", \"tests/test_fields.py::TestMetadata::test_extra_metadata_may_be_added_to_field[UUID]\", \"tests/test_fields.py::TestMetadata::test_extra_metadata_may_be_added_to_field[Decimal]\", \"tests/test_fields.py::TestErrorMessages::test_default_error_messages_get_merged_with_parent_error_messages_cstm_msg\", \"tests/test_fields.py::TestErrorMessages::test_default_error_messages_get_merged_with_parent_error_messages\", \"tests/test_fields.py::TestErrorMessages::test_make_error[required-Missing\", \"tests/test_fields.py::TestErrorMessages::test_make_error[null-Field\", \"tests/test_fields.py::TestErrorMessages::test_make_error[custom-Custom\", \"tests/test_fields.py::TestErrorMessages::test_make_error[validator_failed-Invalid\", \"tests/test_fields.py::TestErrorMessages::test_fail[required-Missing\", \"tests/test_fields.py::TestErrorMessages::test_fail[null-Field\", \"tests/test_fields.py::TestErrorMessages::test_fail[custom-Custom\", \"tests/test_fields.py::TestErrorMessages::test_fail[validator_failed-Invalid\", \"tests/test_fields.py::TestErrorMessages::test_make_error_key_doesnt_exist\", \"tests/test_fields.py::TestNestedField::test_nested_only_and_exclude_as_string[only]\", \"tests/test_fields.py::TestNestedField::test_nested_only_and_exclude_as_string[exclude]\", \"tests/test_fields.py::TestNestedField::test_nested_unknown_override[None-exclude]\", \"tests/test_fields.py::TestNestedField::test_nested_unknown_override[None-include]\", \"tests/test_fields.py::TestNestedField::test_nested_unknown_override[None-raise]\", \"tests/test_fields.py::TestNestedField::test_nested_unknown_override[exclude-exclude]\", \"tests/test_fields.py::TestNestedField::test_nested_unknown_override[exclude-include]\", \"tests/test_fields.py::TestNestedField::test_nested_unknown_override[exclude-raise]\", \"tests/test_fields.py::TestNestedField::test_nested_unknown_override[include-exclude]\", \"tests/test_fields.py::TestNestedField::test_nested_unknown_override[include-include]\", \"tests/test_fields.py::TestNestedField::test_nested_unknown_override[include-raise]\", \"tests/test_fields.py::TestNestedField::test_nested_unknown_override[raise-exclude]\", \"tests/test_fields.py::TestNestedField::test_nested_unknown_override[raise-include]\", \"tests/test_fields.py::TestNestedField::test_nested_unknown_override[raise-raise]\", \"tests/test_fields.py::TestListNested::test_list_nested_only_exclude_dump_only_load_only_propagated_to_nested[only]\", \"tests/test_fields.py::TestListNested::test_list_nested_only_exclude_dump_only_load_only_propagated_to_nested[exclude]\", \"tests/test_fields.py::TestListNested::test_list_nested_only_exclude_dump_only_load_only_propagated_to_nested[dump_only]\", \"tests/test_fields.py::TestListNested::test_list_nested_only_exclude_dump_only_load_only_propagated_to_nested[load_only]\", \"tests/test_fields.py::TestListNested::test_list_nested_only_and_exclude_merged_with_nested[only-expected0]\", \"tests/test_fields.py::TestListNested::test_list_nested_only_and_exclude_merged_with_nested[exclude-expected1]\", \"tests/test_fields.py::TestListNested::test_list_nested_partial_propagated_to_nested\", \"tests/test_fields.py::TestTupleNested::test_tuple_nested_only_exclude_dump_only_load_only_propagated_to_nested[dump_only]\", \"tests/test_fields.py::TestTupleNested::test_tuple_nested_only_exclude_dump_only_load_only_propagated_to_nested[load_only]\", \"tests/test_fields.py::TestTupleNested::test_tuple_nested_partial_propagated_to_nested\", \"tests/test_fields.py::TestDictNested::test_dict_nested_only_exclude_dump_only_load_only_propagated_to_nested[only]\", \"tests/test_fields.py::TestDictNested::test_dict_nested_only_exclude_dump_only_load_only_propagated_to_nested[exclude]\", \"tests/test_fields.py::TestDictNested::test_dict_nested_only_exclude_dump_only_load_only_propagated_to_nested[dump_only]\", \"tests/test_fields.py::TestDictNested::test_dict_nested_only_exclude_dump_only_load_only_propagated_to_nested[load_only]\", \"tests/test_fields.py::TestDictNested::test_dict_nested_only_and_exclude_merged_with_nested[only-expected0]\", \"tests/test_fields.py::TestDictNested::test_dict_nested_only_and_exclude_merged_with_nested[exclude-expected1]\", \"tests/test_fields.py::TestDictNested::test_dict_nested_partial_propagated_to_nested\"]"], "files_to_edit": ["src/marshmallow/fields.py"], "metadata": {"hints_text": "Thanks for reporting. I don't think I'll have time to look into this until the weekend. Would you like to send a PR? \nI'm afraid I don't have any time either, and I don't really have enough context on the `_bind_to_schema` process to make sure I'm not breaking stuff.\nOK, no problem. @lafrech Will you have a chance to look into this?\nI've found the patch below to fix the minimal example above, but I'm not really sure what it's missing out on or how to test it properly:\r\n```patch\r\ndiff --git a/src/marshmallow/fields.py b/src/marshmallow/fields.py\r\nindex 0b18e7d..700732e 100644\r\n--- a/src/marshmallow/fields.py\r\n+++ b/src/marshmallow/fields.py\r\n@@ -1114,7 +1114,7 @@ class DateTime(Field):\r\n         super()._bind_to_schema(field_name, schema)\r\n         self.format = (\r\n             self.format\r\n-            or getattr(schema.opts, self.SCHEMA_OPTS_VAR_NAME)\r\n+            or getattr(getattr(schema, \"opts\", None), self.SCHEMA_OPTS_VAR_NAME, None)\r\n             or self.DEFAULT_FORMAT\r\n         )\r\n```\n    git difftool 3.0.0rc8 3.0.0rc9 src/marshmallow/fields.py\r\n\r\nWhen reworking container stuff, I changed\r\n\r\n```py\r\n        self.inner.parent = self\r\n        self.inner.name = field_name\r\n```\r\ninto\r\n\r\n```py\r\n        self.inner._bind_to_schema(field_name, self)\r\n```\r\n\r\nAFAIR, I did this merely to avoid duplication. On second thought, I think it was the right thing to do, not only for duplication but to actually bind inner fields to the `Schema`.\r\n\r\nReverting this avoids the error but the inner field's `_bind_to_schema` method is not called so I'm not sure it is desirable.\r\n\r\nI think we really mean to call that method, not only in this case but also generally.\r\n\r\nChanging\r\n\r\n```py\r\n            or getattr(schema.opts, self.SCHEMA_OPTS_VAR_NAME)\r\n```\r\n\r\ninto\r\n\r\n```py\r\n            or getattr(self.root.opts, self.SCHEMA_OPTS_VAR_NAME)\r\n```\r\n\r\nmight be a better fix. Can anyone confirm (@sloria, @deckar01)?\r\n\r\nThe fix in https://github.com/marshmallow-code/marshmallow/issues/1357#issuecomment-523465528 removes the error but also the feature: `DateTime` fields buried into container fields won't respect the format set in the `Schema`.\r\n\r\nI didn't double-check that but AFAIU, the change I mentioned above (in container stuff rework) was the right thing to do. The feature was already broken (format set in `Schema` not respected if `DateTime` field in container field) and that's just one of the issues that may arise due to the inner field not being bound to the `Schema`. But I may be wrong.\nOn quick glance, your analysis and fix look correct @lafrech \nLet's do that, then.\r\n\r\nNot much time either. The first who gets the time can do it.\r\n\r\nFor the non-reg tests :\r\n\r\n1/ a test that checks the format set in the schema is respected if the `DateTime` field is in a container field\r\n\r\n2/ a set of tests asserting the `_bind_to_schema` method of inner fields `List`, `Dict`, `Tuple` is called from container fields (we can use `DateTime` with the same test case for that)\r\n\r\nPerhaps 1/ is useless if 2/ is done.", "created_at": "2019-08-21T15:45:13Z", "version": "3.0", "test_patch": "diff --git a/tests/test_fields.py b/tests/test_fields.py\n--- a/tests/test_fields.py\n+++ b/tests/test_fields.py\n@@ -169,6 +169,20 @@ class OtherSchema(MySchema):\n         assert schema2.fields[\"foo\"].key_field.root == schema2\n         assert schema2.fields[\"foo\"].value_field.root == schema2\n \n+    # Regression test for https://github.com/marshmallow-code/marshmallow/issues/1357\n+    def test_datetime_list_inner_format(self, schema):\n+        class MySchema(Schema):\n+            foo = fields.List(fields.DateTime())\n+            bar = fields.Tuple((fields.DateTime(),))\n+\n+            class Meta:\n+                datetimeformat = \"iso8601\"\n+                dateformat = \"iso8601\"\n+\n+        schema = MySchema()\n+        assert schema.fields[\"foo\"].inner.format == \"iso8601\"\n+        assert schema.fields[\"bar\"].tuple_fields[0].format == \"iso8601\"\n+\n \n class TestMetadata:\n     @pytest.mark.parametrize(\"FieldClass\", ALL_FIELDS)\n", "environment_setup_commit": "8b3a32614fd4a74e93e9a63a042e74c1fea34466"}}
{"problem_id": "marshmallow-code__marshmallow-1343", "repo_owner": "marshmallow-code", "repo_name": "marshmallow", "repo_url": "https://github.com/marshmallow-code/marshmallow", "base_commit": "2be2d83a1a9a6d3d9b85804f3ab545cecc409bb0", "problem": "[version 2.20.0] TypeError: 'NoneType' object is not subscriptable\nAfter update from version 2.19.5 to 2.20.0 I got error for code like:\r\n\r\n```python\r\nfrom marshmallow import Schema, fields, validates\r\n\r\n\r\nclass Bar(Schema):\r\n    value = fields.String()\r\n\r\n    @validates('value')  # <- issue here\r\n    def validate_value(self, value):\r\n        pass\r\n\r\n\r\nclass Foo(Schema):\r\n    bar = fields.Nested(Bar)\r\n\r\n\r\nsch = Foo()\r\n\r\nsch.validate({\r\n    'bar': 'invalid',\r\n})\r\n```\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/_/bug_mschema.py\", line 19, in <module>\r\n    'bar': 'invalid',\r\n  File \"/_/env/lib/python3.7/site-packages/marshmallow/schema.py\", line 628, in validate\r\n    _, errors = self._do_load(data, many, partial=partial, postprocess=False)\r\n  File \"/_/env/lib/python3.7/site-packages/marshmallow/schema.py\", line 670, in _do_load\r\n    index_errors=self.opts.index_errors,\r\n  File \"/_/env/lib/python3.7/site-packages/marshmallow/marshalling.py\", line 292, in deserialize\r\n    index=(index if index_errors else None)\r\n  File \"/_/env/lib/python3.7/site-packages/marshmallow/marshalling.py\", line 65, in call_and_store\r\n    value = getter_func(data)\r\n  File \"/_/env/lib/python3.7/site-packages/marshmallow/marshalling.py\", line 285, in <lambda>\r\n    data\r\n  File \"/_/env/lib/python3.7/site-packages/marshmallow/fields.py\", line 265, in deserialize\r\n    output = self._deserialize(value, attr, data)\r\n  File \"/_/env/lib/python3.7/site-packages/marshmallow/fields.py\", line 465, in _deserialize\r\n    data, errors = self.schema.load(value)\r\n  File \"/_/env/lib/python3.7/site-packages/marshmallow/schema.py\", line 588, in load\r\n    result, errors = self._do_load(data, many, partial=partial, postprocess=True)\r\n  File \"/_/env/lib/python3.7/site-packages/marshmallow/schema.py\", line 674, in _do_load\r\n    self._invoke_field_validators(unmarshal, data=result, many=many)\r\n  File \"/_/env/lib/python3.7/site-packages/marshmallow/schema.py\", line 894, in _invoke_field_validators\r\n    value = data[field_obj.attribute or field_name]\r\nTypeError: 'NoneType' object is not subscriptable\r\n```\n", "issue_title": "Fix issue in marshmallow-code/marshmallow", "issue_body": "[version 2.20.0] TypeError: 'NoneType' object is not subscriptable\nAfter update from version 2.19.5 to 2.20.0 I got error for code like:\r\n\r\n```python\r\nfrom marshmallow import Schema, fields, validates\r\n\r\n\r\nclass Bar(Schema):\r\n    value = fields.String()\r\n\r\n    @validates('value')  # <- issue here\r\n    def validate_value(self, value):\r\n        pass\r\n\r\n\r\nclass Foo(Schema):\r\n    bar = fields.Nested(Bar)\r\n\r\n\r\nsch = Foo()\r\n\r\nsch.validate({\r\n    'bar': 'invalid',\r\n})\r\n```\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/_/bug_mschema.py\", line 19, in <module>\r\n    'bar': 'invalid',\r\n  File \"/_/env/lib/python3.7/site-packages/marshmallow/schema.py\", line 628, in validate\r\n    _, errors = self._do_load(data, many, partial=partial, postprocess=False)\r\n  File \"/_/env/lib/python3.7/site-packages/marshmallow/schema.py\", line 670, in _do_load\r\n    index_errors=self.opts.index_errors,\r\n  File \"/_/env/lib/python3.7/site-packages/marshmallow/marshalling.py\", line 292, in deserialize\r\n    index=(index if index_errors else None)\r\n  File \"/_/env/lib/python3.7/site-packages/marshmallow/marshalling.py\", line 65, in call_and_store\r\n    value = getter_func(data)\r\n  File \"/_/env/lib/python3.7/site-packages/marshmallow/marshalling.py\", line 285, in <lambda>\r\n    data\r\n  File \"/_/env/lib/python3.7/site-packages/marshmallow/fields.py\", line 265, in deserialize\r\n    output = self._deserialize(value, attr, data)\r\n  File \"/_/env/lib/python3.7/site-packages/marshmallow/fields.py\", line 465, in _deserialize\r\n    data, errors = self.schema.load(value)\r\n  File \"/_/env/lib/python3.7/site-packages/marshmallow/schema.py\", line 588, in load\r\n    result, errors = self._do_load(data, many, partial=partial, postprocess=True)\r\n  File \"/_/env/lib/python3.7/site-packages/marshmallow/schema.py\", line 674, in _do_load\r\n    self._invoke_field_validators(unmarshal, data=result, many=many)\r\n  File \"/_/env/lib/python3.7/site-packages/marshmallow/schema.py\", line 894, in _invoke_field_validators\r\n    value = data[field_obj.attribute or field_name]\r\nTypeError: 'NoneType' object is not subscriptable\r\n```\n", "pr_diff": "diff --git a/src/marshmallow/schema.py b/src/marshmallow/schema.py\n--- a/src/marshmallow/schema.py\n+++ b/src/marshmallow/schema.py\n@@ -877,7 +877,7 @@ def _invoke_field_validators(self, unmarshal, data, many):\n                 for idx, item in enumerate(data):\n                     try:\n                         value = item[field_obj.attribute or field_name]\n-                    except KeyError:\n+                    except (KeyError, TypeError):\n                         pass\n                     else:\n                         validated_value = unmarshal.call_and_store(\n@@ -892,7 +892,7 @@ def _invoke_field_validators(self, unmarshal, data, many):\n             else:\n                 try:\n                     value = data[field_obj.attribute or field_name]\n-                except KeyError:\n+                except (KeyError, TypeError):\n                     pass\n                 else:\n                     validated_value = unmarshal.call_and_store(\n", "solution": "diff --git a/src/marshmallow/schema.py b/src/marshmallow/schema.py\n--- a/src/marshmallow/schema.py\n+++ b/src/marshmallow/schema.py\n@@ -877,7 +877,7 @@ def _invoke_field_validators(self, unmarshal, data, many):\n                 for idx, item in enumerate(data):\n                     try:\n                         value = item[field_obj.attribute or field_name]\n-                    except KeyError:\n+                    except (KeyError, TypeError):\n                         pass\n                     else:\n                         validated_value = unmarshal.call_and_store(\n@@ -892,7 +892,7 @@ def _invoke_field_validators(self, unmarshal, data, many):\n             else:\n                 try:\n                     value = data[field_obj.attribute or field_name]\n-                except KeyError:\n+                except (KeyError, TypeError):\n                     pass\n                 else:\n                     validated_value = unmarshal.call_and_store(\n", "test_command": "[\"tests/test_marshalling.py::TestUnmarshaller::test_deserialize_wrong_nested_type_with_validates_method\"]", "test_commands": ["[\"tests/test_marshalling.py::TestUnmarshaller::test_deserialize_wrong_nested_type_with_validates_method\"]", "[\"tests/test_marshalling.py::test_missing_is_falsy\", \"tests/test_marshalling.py::TestMarshaller::test_prefix\", \"tests/test_marshalling.py::TestMarshaller::test_marshalling_generator\", \"tests/test_marshalling.py::TestMarshaller::test_default_to_missing\", \"tests/test_marshalling.py::TestMarshaller::test_serialize_fields_with_load_only_param\", \"tests/test_marshalling.py::TestMarshaller::test_missing_data_are_skipped\", \"tests/test_marshalling.py::TestMarshaller::test_serialize_with_load_only_doesnt_validate\", \"tests/test_marshalling.py::TestMarshaller::test_serialize_fields_with_dump_to_param\", \"tests/test_marshalling.py::TestMarshaller::test_serialize_fields_with_dump_to_and_prefix_params\", \"tests/test_marshalling.py::TestMarshaller::test_stores_indices_of_errors_when_many_equals_true\", \"tests/test_marshalling.py::TestMarshaller::test_doesnt_store_errors_when_index_errors_equals_false\", \"tests/test_marshalling.py::TestUnmarshaller::test_extra_data_is_ignored\", \"tests/test_marshalling.py::TestUnmarshaller::test_stores_errors\", \"tests/test_marshalling.py::TestUnmarshaller::test_stores_indices_of_errors_when_many_equals_true\", \"tests/test_marshalling.py::TestUnmarshaller::test_doesnt_store_errors_when_index_errors_equals_false\", \"tests/test_marshalling.py::TestUnmarshaller::test_deserialize\", \"tests/test_marshalling.py::TestUnmarshaller::test_extra_fields\", \"tests/test_marshalling.py::TestUnmarshaller::test_deserialize_many\", \"tests/test_marshalling.py::TestUnmarshaller::test_deserialize_stores_errors\", \"tests/test_marshalling.py::TestUnmarshaller::test_deserialize_fields_with_attribute_param\", \"tests/test_marshalling.py::TestUnmarshaller::test_deserialize_fields_with_load_from_param\", \"tests/test_marshalling.py::TestUnmarshaller::test_deserialize_fields_with_dump_only_param\", \"tests/test_marshalling.py::TestUnmarshaller::test_deserialize_wrong_type_root_data\", \"tests/test_marshalling.py::TestUnmarshaller::test_deserialize_wrong_type_nested_data\"]"], "files_to_edit": ["src/marshmallow/schema.py"], "metadata": {"hints_text": "Thanks for reporting. I was able to reproduce this on 2.20.0. This is likely a regression from https://github.com/marshmallow-code/marshmallow/pull/1323 . I don't have time to look into it now. Would appreciate a PR.", "created_at": "2019-08-13T04:36:01Z", "version": "2.20", "test_patch": "diff --git a/tests/test_marshalling.py b/tests/test_marshalling.py\n--- a/tests/test_marshalling.py\n+++ b/tests/test_marshalling.py\n@@ -2,7 +2,7 @@\n \n import pytest\n \n-from marshmallow import fields, Schema\n+from marshmallow import fields, Schema, validates\n from marshmallow.marshalling import Marshaller, Unmarshaller, missing\n from marshmallow.exceptions import ValidationError\n \n@@ -283,3 +283,24 @@ class TestSchema(Schema):\n \n             assert result is None\n             assert excinfo.value.messages == {'foo': {'_schema': ['Invalid input type.']}}\n+\n+    # Regression test for https://github.com/marshmallow-code/marshmallow/issues/1342\n+    def test_deserialize_wrong_nested_type_with_validates_method(self, unmarshal):\n+        class TestSchema(Schema):\n+            value = fields.String()\n+\n+            @validates('value')\n+            def validate_value(self, value):\n+                pass\n+\n+        data = {\n+            'foo': 'not what we need'\n+        }\n+        fields_dict = {\n+            'foo': fields.Nested(TestSchema, required=True)\n+        }\n+        with pytest.raises(ValidationError) as excinfo:\n+            result = unmarshal.deserialize(data, fields_dict)\n+\n+            assert result is None\n+            assert excinfo.value.messages == {'foo': {'_schema': ['Invalid input type.']}}\n", "environment_setup_commit": "7015fc4333a2f32cd58c3465296e834acd4496ff"}}
{"problem_id": "pvlib__pvlib-python-1707", "repo_owner": "pvlib", "repo_name": "pvlib-python", "repo_url": "https://github.com/pvlib/pvlib-python", "base_commit": "40e9e978c170bdde4eeee1547729417665dbc34c", "problem": "regression: iam.physical returns nan for aoi > 90\u00b0 when n = 1\n**Describe the bug**\r\nFor pvlib==0.9.5, when n = 1 (no reflection) and aoi > 90\u00b0, we get nan as result.\r\n\r\n**To Reproduce**\r\n```python\r\nimport pvlib\r\npvlib.iam.physical(aoi=100, n=1)\r\n```\r\nreturns `nan`.\r\n\r\n**Expected behavior**\r\nThe result should be `0`, as it was for pvlib <= 0.9.4.\r\n\r\n\r\n**Versions:**\r\n - ``pvlib.__version__``: '0.9.5'\r\n - ``pandas.__version__``:  '1.5.3'\r\n - python: 3.10.4\r\n\n", "issue_title": "Fix issue in pvlib/pvlib-python", "issue_body": "regression: iam.physical returns nan for aoi > 90\u00b0 when n = 1\n**Describe the bug**\r\nFor pvlib==0.9.5, when n = 1 (no reflection) and aoi > 90\u00b0, we get nan as result.\r\n\r\n**To Reproduce**\r\n```python\r\nimport pvlib\r\npvlib.iam.physical(aoi=100, n=1)\r\n```\r\nreturns `nan`.\r\n\r\n**Expected behavior**\r\nThe result should be `0`, as it was for pvlib <= 0.9.4.\r\n\r\n\r\n**Versions:**\r\n - ``pvlib.__version__``: '0.9.5'\r\n - ``pandas.__version__``:  '1.5.3'\r\n - python: 3.10.4\r\n\n", "pr_diff": "diff --git a/pvlib/iam.py b/pvlib/iam.py\n--- a/pvlib/iam.py\n+++ b/pvlib/iam.py\n@@ -175,8 +175,12 @@ def physical(aoi, n=1.526, K=4.0, L=0.002, *, n_ar=None):\n     n2costheta2 = n2 * costheta\n \n     # reflectance of s-, p-polarized, and normal light by the first interface\n-    rho12_s = ((n1costheta1 - n2costheta2) / (n1costheta1 + n2costheta2)) ** 2\n-    rho12_p = ((n1costheta2 - n2costheta1) / (n1costheta2 + n2costheta1)) ** 2\n+    with np.errstate(divide='ignore', invalid='ignore'):\n+        rho12_s = \\\n+            ((n1costheta1 - n2costheta2) / (n1costheta1 + n2costheta2)) ** 2\n+        rho12_p = \\\n+            ((n1costheta2 - n2costheta1) / (n1costheta2 + n2costheta1)) ** 2\n+\n     rho12_0 = ((n1 - n2) / (n1 + n2)) ** 2\n \n     # transmittance through the first interface\n@@ -208,13 +212,22 @@ def physical(aoi, n=1.526, K=4.0, L=0.002, *, n_ar=None):\n         tau_0 *= (1 - rho23_0) / (1 - rho23_0 * rho12_0)\n \n     # transmittance after absorption in the glass\n-    tau_s *= np.exp(-K * L / costheta)\n-    tau_p *= np.exp(-K * L / costheta)\n+    with np.errstate(divide='ignore', invalid='ignore'):\n+        tau_s *= np.exp(-K * L / costheta)\n+        tau_p *= np.exp(-K * L / costheta)\n+\n     tau_0 *= np.exp(-K * L)\n \n     # incidence angle modifier\n     iam = (tau_s + tau_p) / 2 / tau_0\n \n+    # for light coming from behind the plane, none can enter the module\n+    # when n2 > 1, this is already the case\n+    if np.isclose(n2, 1).any():\n+        iam = np.where(aoi >= 90, 0, iam)\n+        if isinstance(aoi, pd.Series):\n+            iam = pd.Series(iam, index=aoi.index)\n+\n     return iam\n \n \n", "solution": "diff --git a/pvlib/iam.py b/pvlib/iam.py\n--- a/pvlib/iam.py\n+++ b/pvlib/iam.py\n@@ -175,8 +175,12 @@ def physical(aoi, n=1.526, K=4.0, L=0.002, *, n_ar=None):\n     n2costheta2 = n2 * costheta\n \n     # reflectance of s-, p-polarized, and normal light by the first interface\n-    rho12_s = ((n1costheta1 - n2costheta2) / (n1costheta1 + n2costheta2)) ** 2\n-    rho12_p = ((n1costheta2 - n2costheta1) / (n1costheta2 + n2costheta1)) ** 2\n+    with np.errstate(divide='ignore', invalid='ignore'):\n+        rho12_s = \\\n+            ((n1costheta1 - n2costheta2) / (n1costheta1 + n2costheta2)) ** 2\n+        rho12_p = \\\n+            ((n1costheta2 - n2costheta1) / (n1costheta2 + n2costheta1)) ** 2\n+\n     rho12_0 = ((n1 - n2) / (n1 + n2)) ** 2\n \n     # transmittance through the first interface\n@@ -208,13 +212,22 @@ def physical(aoi, n=1.526, K=4.0, L=0.002, *, n_ar=None):\n         tau_0 *= (1 - rho23_0) / (1 - rho23_0 * rho12_0)\n \n     # transmittance after absorption in the glass\n-    tau_s *= np.exp(-K * L / costheta)\n-    tau_p *= np.exp(-K * L / costheta)\n+    with np.errstate(divide='ignore', invalid='ignore'):\n+        tau_s *= np.exp(-K * L / costheta)\n+        tau_p *= np.exp(-K * L / costheta)\n+\n     tau_0 *= np.exp(-K * L)\n \n     # incidence angle modifier\n     iam = (tau_s + tau_p) / 2 / tau_0\n \n+    # for light coming from behind the plane, none can enter the module\n+    # when n2 > 1, this is already the case\n+    if np.isclose(n2, 1).any():\n+        iam = np.where(aoi >= 90, 0, iam)\n+        if isinstance(aoi, pd.Series):\n+            iam = pd.Series(iam, index=aoi.index)\n+\n     return iam\n \n \n", "test_command": "[\"pvlib/tests/test_iam.py::test_physical_n1_L0\"]", "test_commands": ["[\"pvlib/tests/test_iam.py::test_physical_n1_L0\"]", "[\"pvlib/tests/test_iam.py::test_ashrae\", \"pvlib/tests/test_iam.py::test_ashrae_scalar\", \"pvlib/tests/test_iam.py::test_physical\", \"pvlib/tests/test_iam.py::test_physical_ar\", \"pvlib/tests/test_iam.py::test_physical_noar\", \"pvlib/tests/test_iam.py::test_physical_scalar\", \"pvlib/tests/test_iam.py::test_martin_ruiz\", \"pvlib/tests/test_iam.py::test_martin_ruiz_exception\", \"pvlib/tests/test_iam.py::test_martin_ruiz_diffuse\", \"pvlib/tests/test_iam.py::test_iam_interp\", \"pvlib/tests/test_iam.py::test_sapm[45-0.9975036250000002]\", \"pvlib/tests/test_iam.py::test_sapm[aoi1-expected1]\", \"pvlib/tests/test_iam.py::test_sapm[aoi2-expected2]\", \"pvlib/tests/test_iam.py::test_sapm_limits\", \"pvlib/tests/test_iam.py::test_marion_diffuse_model\", \"pvlib/tests/test_iam.py::test_marion_diffuse_kwargs\", \"pvlib/tests/test_iam.py::test_marion_diffuse_invalid\", \"pvlib/tests/test_iam.py::test_marion_integrate_scalar[sky-180-0.9596085829811408]\", \"pvlib/tests/test_iam.py::test_marion_integrate_scalar[horizon-1800-0.8329070417832541]\", \"pvlib/tests/test_iam.py::test_marion_integrate_scalar[ground-180-0.719823559106309]\", \"pvlib/tests/test_iam.py::test_marion_integrate_list[sky-180-expected0]\", \"pvlib/tests/test_iam.py::test_marion_integrate_list[horizon-1800-expected1]\", \"pvlib/tests/test_iam.py::test_marion_integrate_list[ground-180-expected2]\", \"pvlib/tests/test_iam.py::test_marion_integrate_series[sky-180-expected0]\", \"pvlib/tests/test_iam.py::test_marion_integrate_series[horizon-1800-expected1]\", \"pvlib/tests/test_iam.py::test_marion_integrate_series[ground-180-expected2]\", \"pvlib/tests/test_iam.py::test_marion_integrate_ground_flat\", \"pvlib/tests/test_iam.py::test_marion_integrate_invalid\", \"pvlib/tests/test_iam.py::test_schlick\", \"pvlib/tests/test_iam.py::test_schlick_diffuse\"]"], "files_to_edit": ["pvlib/iam.py"], "metadata": {"hints_text": "", "created_at": "2023-03-24T10:46:42Z", "version": "0.9", "test_patch": "diff --git a/pvlib/tests/test_iam.py b/pvlib/tests/test_iam.py\n--- a/pvlib/tests/test_iam.py\n+++ b/pvlib/tests/test_iam.py\n@@ -51,6 +51,18 @@ def test_physical():\n     assert_series_equal(iam, expected)\n \n \n+def test_physical_n1_L0():\n+    aoi = np.array([0, 22.5, 45, 67.5, 90, 100, np.nan])\n+    expected = np.array([1, 1, 1, 1, 0, 0, np.nan])\n+    iam = _iam.physical(aoi, n=1, L=0)\n+    assert_allclose(iam, expected, equal_nan=True)\n+\n+    aoi = pd.Series(aoi)\n+    expected = pd.Series(expected)\n+    iam = _iam.physical(aoi, n=1, L=0)\n+    assert_series_equal(iam, expected)\n+\n+\n def test_physical_ar():\n     aoi = np.array([0, 22.5, 45, 67.5, 90, 100, np.nan])\n     expected = np.array([1, 0.99944171, 0.9917463, 0.91506158, 0, 0, np.nan])\n", "environment_setup_commit": "6072e0982c3c0236f532ddfa48fbf461180d834e"}}
{"problem_id": "pvlib__pvlib-python-1072", "repo_owner": "pvlib", "repo_name": "pvlib-python", "repo_url": "https://github.com/pvlib/pvlib-python", "base_commit": "04a523fafbd61bc2e49420963b84ed8e2bd1b3cf", "problem": "temperature.fuentes errors when given tz-aware inputs on pandas>=1.0.0\n**Describe the bug**\r\nWhen the weather timeseries inputs to `temperature.fuentes` have tz-aware index, an internal call to `np.diff(index)` returns an array of `Timedelta` objects instead of an array of nanosecond ints, throwing an error immediately after.  The error only happens when using pandas>=1.0.0; using 0.25.3 runs successfully, but emits the warning:\r\n\r\n```\r\n  /home/kevin/anaconda3/envs/pvlib-dev/lib/python3.7/site-packages/numpy/lib/function_base.py:1243: FutureWarning: Converting timezone-aware DatetimeArray to timezone-naive ndarray with 'datetime64[ns]' dtype. In the future, this will return an ndarray with 'object' dtype where each element is a 'pandas.Timestamp' with the correct 'tz'.\r\n  \tTo accept the future behavior, pass 'dtype=object'.\r\n  \tTo keep the old behavior, pass 'dtype=\"datetime64[ns]\"'.\r\n    a = asanyarray(a)\r\n```\r\n\r\n**To Reproduce**\r\n```python\r\nIn [1]: import pvlib\r\n   ...: import pandas as pd\r\n   ...: \r\n   ...: index_naive = pd.date_range('2019-01-01', freq='h', periods=3)\r\n   ...: \r\n   ...: kwargs = {\r\n   ...:     'poa_global': pd.Series(1000, index_naive),\r\n   ...:     'temp_air': pd.Series(20, index_naive),\r\n   ...:     'wind_speed': pd.Series(1, index_naive),\r\n   ...:     'noct_installed': 45\r\n   ...: }\r\n   ...: \r\n\r\nIn [2]: print(pvlib.temperature.fuentes(**kwargs))\r\n2019-01-01 00:00:00    47.85\r\n2019-01-01 01:00:00    50.85\r\n2019-01-01 02:00:00    50.85\r\nFreq: H, Name: tmod, dtype: float64\r\n\r\nIn [3]: kwargs['poa_global'].index = index_naive.tz_localize('UTC')\r\n   ...: print(pvlib.temperature.fuentes(**kwargs))\r\n   ...: \r\nTraceback (most recent call last):\r\n\r\n  File \"<ipython-input-3-ff99badadc91>\", line 2, in <module>\r\n    print(pvlib.temperature.fuentes(**kwargs))\r\n\r\n  File \"/home/kevin/anaconda3/lib/python3.7/site-packages/pvlib/temperature.py\", line 602, in fuentes\r\n    timedelta_hours = np.diff(poa_global.index).astype(float) / 1e9 / 60 / 60\r\n\r\nTypeError: float() argument must be a string or a number, not 'Timedelta'\r\n```\r\n\r\n**Expected behavior**\r\n`temperature.fuentes` should work with both tz-naive and tz-aware inputs.\r\n\r\n\r\n**Versions:**\r\n - ``pvlib.__version__``: 0.8.0\r\n - ``pandas.__version__``: 1.0.0+\r\n - python: 3.7.4 (default, Aug 13 2019, 20:35:49) \\n[GCC 7.3.0]\r\n\r\n\n", "issue_title": "Fix issue in pvlib/pvlib-python", "issue_body": "temperature.fuentes errors when given tz-aware inputs on pandas>=1.0.0\n**Describe the bug**\r\nWhen the weather timeseries inputs to `temperature.fuentes` have tz-aware index, an internal call to `np.diff(index)` returns an array of `Timedelta` objects instead of an array of nanosecond ints, throwing an error immediately after.  The error only happens when using pandas>=1.0.0; using 0.25.3 runs successfully, but emits the warning:\r\n\r\n```\r\n  /home/kevin/anaconda3/envs/pvlib-dev/lib/python3.7/site-packages/numpy/lib/function_base.py:1243: FutureWarning: Converting timezone-aware DatetimeArray to timezone-naive ndarray with 'datetime64[ns]' dtype. In the future, this will return an ndarray with 'object' dtype where each element is a 'pandas.Timestamp' with the correct 'tz'.\r\n  \tTo accept the future behavior, pass 'dtype=object'.\r\n  \tTo keep the old behavior, pass 'dtype=\"datetime64[ns]\"'.\r\n    a = asanyarray(a)\r\n```\r\n\r\n**To Reproduce**\r\n```python\r\nIn [1]: import pvlib\r\n   ...: import pandas as pd\r\n   ...: \r\n   ...: index_naive = pd.date_range('2019-01-01', freq='h', periods=3)\r\n   ...: \r\n   ...: kwargs = {\r\n   ...:     'poa_global': pd.Series(1000, index_naive),\r\n   ...:     'temp_air': pd.Series(20, index_naive),\r\n   ...:     'wind_speed': pd.Series(1, index_naive),\r\n   ...:     'noct_installed': 45\r\n   ...: }\r\n   ...: \r\n\r\nIn [2]: print(pvlib.temperature.fuentes(**kwargs))\r\n2019-01-01 00:00:00    47.85\r\n2019-01-01 01:00:00    50.85\r\n2019-01-01 02:00:00    50.85\r\nFreq: H, Name: tmod, dtype: float64\r\n\r\nIn [3]: kwargs['poa_global'].index = index_naive.tz_localize('UTC')\r\n   ...: print(pvlib.temperature.fuentes(**kwargs))\r\n   ...: \r\nTraceback (most recent call last):\r\n\r\n  File \"<ipython-input-3-ff99badadc91>\", line 2, in <module>\r\n    print(pvlib.temperature.fuentes(**kwargs))\r\n\r\n  File \"/home/kevin/anaconda3/lib/python3.7/site-packages/pvlib/temperature.py\", line 602, in fuentes\r\n    timedelta_hours = np.diff(poa_global.index).astype(float) / 1e9 / 60 / 60\r\n\r\nTypeError: float() argument must be a string or a number, not 'Timedelta'\r\n```\r\n\r\n**Expected behavior**\r\n`temperature.fuentes` should work with both tz-naive and tz-aware inputs.\r\n\r\n\r\n**Versions:**\r\n - ``pvlib.__version__``: 0.8.0\r\n - ``pandas.__version__``: 1.0.0+\r\n - python: 3.7.4 (default, Aug 13 2019, 20:35:49) \\n[GCC 7.3.0]\r\n\r\n\n", "pr_diff": "diff --git a/pvlib/temperature.py b/pvlib/temperature.py\n--- a/pvlib/temperature.py\n+++ b/pvlib/temperature.py\n@@ -599,8 +599,9 @@ def fuentes(poa_global, temp_air, wind_speed, noct_installed, module_height=5,\n     # n.b. the way Fuentes calculates the first timedelta makes it seem like\n     # the value doesn't matter -- rather than recreate it here, just assume\n     # it's the same as the second timedelta:\n-    timedelta_hours = np.diff(poa_global.index).astype(float) / 1e9 / 60 / 60\n-    timedelta_hours = np.append([timedelta_hours[0]], timedelta_hours)\n+    timedelta_seconds = poa_global.index.to_series().diff().dt.total_seconds()\n+    timedelta_hours = timedelta_seconds / 3600\n+    timedelta_hours.iloc[0] = timedelta_hours.iloc[1]\n \n     tamb_array = temp_air + 273.15\n     sun_array = poa_global * absorp\n", "solution": "diff --git a/pvlib/temperature.py b/pvlib/temperature.py\n--- a/pvlib/temperature.py\n+++ b/pvlib/temperature.py\n@@ -599,8 +599,9 @@ def fuentes(poa_global, temp_air, wind_speed, noct_installed, module_height=5,\n     # n.b. the way Fuentes calculates the first timedelta makes it seem like\n     # the value doesn't matter -- rather than recreate it here, just assume\n     # it's the same as the second timedelta:\n-    timedelta_hours = np.diff(poa_global.index).astype(float) / 1e9 / 60 / 60\n-    timedelta_hours = np.append([timedelta_hours[0]], timedelta_hours)\n+    timedelta_seconds = poa_global.index.to_series().diff().dt.total_seconds()\n+    timedelta_hours = timedelta_seconds / 3600\n+    timedelta_hours.iloc[0] = timedelta_hours.iloc[1]\n \n     tamb_array = temp_air + 273.15\n     sun_array = poa_global * absorp\n", "test_command": "[\"pvlib/tests/test_temperature.py::test_fuentes_timezone[Etc/GMT+5]\"]", "test_commands": ["[\"pvlib/tests/test_temperature.py::test_fuentes_timezone[Etc/GMT+5]\"]", "[\"pvlib/tests/test_temperature.py::test_sapm_cell\", \"pvlib/tests/test_temperature.py::test_sapm_module\", \"pvlib/tests/test_temperature.py::test_sapm_cell_from_module\", \"pvlib/tests/test_temperature.py::test_sapm_ndarray\", \"pvlib/tests/test_temperature.py::test_sapm_series\", \"pvlib/tests/test_temperature.py::test_pvsyst_cell_default\", \"pvlib/tests/test_temperature.py::test_pvsyst_cell_kwargs\", \"pvlib/tests/test_temperature.py::test_pvsyst_cell_ndarray\", \"pvlib/tests/test_temperature.py::test_pvsyst_cell_series\", \"pvlib/tests/test_temperature.py::test_faiman_default\", \"pvlib/tests/test_temperature.py::test_faiman_kwargs\", \"pvlib/tests/test_temperature.py::test_faiman_list\", \"pvlib/tests/test_temperature.py::test_faiman_ndarray\", \"pvlib/tests/test_temperature.py::test_faiman_series\", \"pvlib/tests/test_temperature.py::test__temperature_model_params\", \"pvlib/tests/test_temperature.py::test_fuentes[pvwatts_8760_rackmount.csv-45]\", \"pvlib/tests/test_temperature.py::test_fuentes[pvwatts_8760_roofmount.csv-49]\", \"pvlib/tests/test_temperature.py::test_fuentes_timezone[None]\"]"], "files_to_edit": ["pvlib/temperature.py"], "metadata": {"hints_text": "", "created_at": "2020-10-01T00:53:14Z", "version": "0.7", "test_patch": "diff --git a/pvlib/tests/test_temperature.py b/pvlib/tests/test_temperature.py\n--- a/pvlib/tests/test_temperature.py\n+++ b/pvlib/tests/test_temperature.py\n@@ -190,3 +190,17 @@ def test_fuentes(filename, inoct):\n     night_difference = expected_tcell[is_night] - actual_tcell[is_night]\n     assert night_difference.max() < 6\n     assert night_difference.min() > 0\n+\n+\n+@pytest.mark.parametrize('tz', [None, 'Etc/GMT+5'])\n+def test_fuentes_timezone(tz):\n+    index = pd.date_range('2019-01-01', freq='h', periods=3, tz=tz)\n+\n+    df = pd.DataFrame({'poa_global': 1000, 'temp_air': 20, 'wind_speed': 1},\n+                      index)\n+\n+    out = temperature.fuentes(df['poa_global'], df['temp_air'],\n+                              df['wind_speed'], noct_installed=45)\n+\n+    assert_series_equal(out, pd.Series([47.85, 50.85, 50.85], index=index,\n+                                       name='tmod'))\n", "environment_setup_commit": "6e5148f59c5050e8f7a0084b7ae39e93b80f72e6"}}
{"problem_id": "pvlib__pvlib-python-1606", "repo_owner": "pvlib", "repo_name": "pvlib-python", "repo_url": "https://github.com/pvlib/pvlib-python", "base_commit": "c78b50f4337ecbe536a961336ca91a1176efc0e8", "problem": "golden-section search fails when upper and lower bounds are equal\n**Describe the bug**\r\nI was using pvlib for sometime now and until now I was always passing a big dataframe containing readings of a long period. Because of some changes in our software architecture, I need to pass the weather readings as a single reading (a dataframe with only one row) and I noticed that for readings that GHI-DHI are zero pvlib fails to calculate the output and returns below error while the same code executes correctly with weather information that has non-zero GHI-DHI:\r\n```python\r\nimport os\r\nimport pathlib\r\nimport time\r\nimport json\r\nfrom datetime import datetime\r\nfrom time import mktime, gmtime\r\n\r\nimport pandas as pd\r\n\r\nfrom pvlib import pvsystem\r\nfrom pvlib import location as pvlocation\r\nfrom pvlib import modelchain\r\nfrom pvlib.temperature import TEMPERATURE_MODEL_PARAMETERS as PARAMS # not used -- to remove\r\nfrom pvlib.bifacial.pvfactors import pvfactors_timeseries\r\nfrom pvlib.temperature import TEMPERATURE_MODEL_PARAMETERS\r\n\r\nclass PV:\r\n    def pv_transform_time(self, val):\r\n        # tt = gmtime(val / 1000)\r\n        tt = gmtime(val)\r\n        dd = datetime.fromtimestamp(mktime(tt))\r\n        timestamp = pd.Timestamp(dd)\r\n        return timestamp\r\n\r\n    def __init__(self, model: str, inverter: str, latitude: float, longitude: float, **kwargs):\r\n        # super().__init__(**kwargs)\r\n\r\n        temperature_model_parameters = TEMPERATURE_MODEL_PARAMETERS[\"sapm\"][\r\n            \"open_rack_glass_glass\"\r\n        ]\r\n        # Load the database of CEC module model parameters\r\n        modules = pvsystem.retrieve_sam(\"cecmod\")\r\n        # Load the database of CEC inverter model parameters\r\n        inverters = pvsystem.retrieve_sam(\"cecinverter\")\r\n\r\n\r\n        # A bare bone PV simulator\r\n\r\n        # Load the database of CEC module model parameters\r\n        modules = pvsystem.retrieve_sam('cecmod')\r\n        inverters = pvsystem.retrieve_sam('cecinverter')\r\n        module_parameters = modules[model]\r\n        inverter_parameters = inverters[inverter]\r\n\r\n        location = pvlocation.Location(latitude=latitude, longitude=longitude)\r\n        system = pvsystem.PVSystem(module_parameters=module_parameters, inverter_parameters=inverter_parameters, temperature_model_parameters=temperature_model_parameters)\r\n        self.modelchain = modelchain.ModelChain(system, location, aoi_model='no_loss', spectral_model=\"no_loss\")\r\n\r\n    def process(self, data):\r\n        weather = pd.read_json(data)\r\n        # print(f\"raw_weather: {weather}\")\r\n        weather.drop('time.1', axis=1, inplace=True)\r\n        weather['time'] = pd.to_datetime(weather['time']).map(datetime.timestamp) # --> this works for the new process_weather code and also the old weather file\r\n        weather[\"time\"] = weather[\"time\"].apply(self.pv_transform_time)\r\n        weather.index = weather[\"time\"]\r\n        # print(f\"weather: {weather}\")\r\n        # print(weather.dtypes)\r\n        # print(weather['ghi'][0])\r\n        # print(type(weather['ghi'][0]))\r\n\r\n        # simulate\r\n        self.modelchain.run_model(weather)\r\n        # print(self.modelchain.results.ac.to_frame().to_json())\r\n        print(self.modelchain.results.ac)\r\n\r\n\r\n# good data\r\ngood_data = \"{\\\"time\\\":{\\\"12\\\":\\\"2010-01-01 13:30:00+00:00\\\"},\\\"ghi\\\":{\\\"12\\\":36},\\\"dhi\\\":{\\\"12\\\":36},\\\"dni\\\":{\\\"12\\\":0},\\\"Tamb\\\":{\\\"12\\\":8.0},\\\"WindVel\\\":{\\\"12\\\":5.0},\\\"WindDir\\\":{\\\"12\\\":270},\\\"time.1\\\":{\\\"12\\\":\\\"2010-01-01 13:30:00+00:00\\\"}}\"\r\n\r\n# data that causes error\r\ndata = \"{\\\"time\\\":{\\\"4\\\":\\\"2010-01-01 05:30:00+00:00\\\"},\\\"ghi\\\":{\\\"4\\\":0},\\\"dhi\\\":{\\\"4\\\":0},\\\"dni\\\":{\\\"4\\\":0},\\\"Tamb\\\":{\\\"4\\\":8.0},\\\"WindVel\\\":{\\\"4\\\":4.0},\\\"WindDir\\\":{\\\"4\\\":240},\\\"time.1\\\":{\\\"4\\\":\\\"2010-01-01 05:30:00+00:00\\\"}}\"\r\np1 = PV(model=\"Trina_Solar_TSM_300DEG5C_07_II_\", inverter=\"ABB__MICRO_0_25_I_OUTD_US_208__208V_\", latitude=51.204483, longitude=5.265472)\r\np1.process(good_data)\r\nprint(\"=====\")\r\np1.process(data)\r\n```\r\nError:\r\n```log\r\n$ python3 ./tmp-pv.py \r\ntime\r\n2010-01-01 13:30:00    7.825527\r\ndtype: float64\r\n=====\r\n/home/user/.local/lib/python3.10/site-packages/pvlib/tools.py:340: RuntimeWarning: divide by zero encountered in divide\r\n  np.trunc(np.log(atol / (df['VH'] - df['VL'])) / np.log(phim1)))\r\nTraceback (most recent call last):\r\n  File \"/home/user/workspace/enorch/simulator/simulator_processor/src/pv/./tmp-pv.py\", line 88, in <module>\r\n    p1.process(data)\r\n  File \"/home/user/workspace/enorch/simulator/simulator_processor/src/pv/./tmp-pv.py\", line 75, in process\r\n    self.modelchain.run_model(weather)\r\n  File \"/home/user/.local/lib/python3.10/site-packages/pvlib/modelchain.py\", line 1770, in run_model\r\n    self._run_from_effective_irrad(weather)\r\n  File \"/home/user/.local/lib/python3.10/site-packages/pvlib/modelchain.py\", line 1858, in _run_from_effective_irrad\r\n    self.dc_model()\r\n  File \"/home/user/.local/lib/python3.10/site-packages/pvlib/modelchain.py\", line 790, in cec\r\n    return self._singlediode(self.system.calcparams_cec)\r\n  File \"/home/user/.local/lib/python3.10/site-packages/pvlib/modelchain.py\", line 772, in _singlediode\r\n    self.results.dc = tuple(itertools.starmap(\r\n  File \"/home/user/.local/lib/python3.10/site-packages/pvlib/pvsystem.py\", line 931, in singlediode\r\n    return singlediode(photocurrent, saturation_current,\r\n  File \"/home/user/.local/lib/python3.10/site-packages/pvlib/pvsystem.py\", line 2826, in singlediode\r\n    out = _singlediode._lambertw(\r\n  File \"/home/user/.local/lib/python3.10/site-packages/pvlib/singlediode.py\", line 651, in _lambertw\r\n    p_mp, v_mp = _golden_sect_DataFrame(params, 0., v_oc * 1.14,\r\n  File \"/home/user/.local/lib/python3.10/site-packages/pvlib/tools.py\", line 364, in _golden_sect_DataFrame\r\n    raise Exception(\"Iterations exceeded maximum. Check that func\",\r\nException: ('Iterations exceeded maximum. Check that func', ' is not NaN in (lower, upper)')\r\n```\r\n\r\nI have to mention that for now the workaround that I am using is to pass the weather data as a dataframe with two rows, the first row is a good weather data that pvlib can process and the second row is the incoming weather reading (I can also post that code if you want).\r\n\r\n**Expected behavior**\r\nPVlib should have consistent behavior and regardless of GHI-DHI readings.\r\n\r\n**Versions:**\r\n```python\r\n>>> import pvlib\r\n>>> import pandas\r\n>>> pvlib.__version__\r\n'0.9.1'\r\n>>> pandas.__version__\r\n'1.4.3'\r\n``` \r\n - python: 3.10.6\r\n- OS: Ubuntu 22.04.1 LTS\n", "issue_title": "Fix issue in pvlib/pvlib-python", "issue_body": "golden-section search fails when upper and lower bounds are equal\n**Describe the bug**\r\nI was using pvlib for sometime now and until now I was always passing a big dataframe containing readings of a long period. Because of some changes in our software architecture, I need to pass the weather readings as a single reading (a dataframe with only one row) and I noticed that for readings that GHI-DHI are zero pvlib fails to calculate the output and returns below error while the same code executes correctly with weather information that has non-zero GHI-DHI:\r\n```python\r\nimport os\r\nimport pathlib\r\nimport time\r\nimport json\r\nfrom datetime import datetime\r\nfrom time import mktime, gmtime\r\n\r\nimport pandas as pd\r\n\r\nfrom pvlib import pvsystem\r\nfrom pvlib import location as pvlocation\r\nfrom pvlib import modelchain\r\nfrom pvlib.temperature import TEMPERATURE_MODEL_PARAMETERS as PARAMS # not used -- to remove\r\nfrom pvlib.bifacial.pvfactors import pvfactors_timeseries\r\nfrom pvlib.temperature import TEMPERATURE_MODEL_PARAMETERS\r\n\r\nclass PV:\r\n    def pv_transform_time(self, val):\r\n        # tt = gmtime(val / 1000)\r\n        tt = gmtime(val)\r\n        dd = datetime.fromtimestamp(mktime(tt))\r\n        timestamp = pd.Timestamp(dd)\r\n        return timestamp\r\n\r\n    def __init__(self, model: str, inverter: str, latitude: float, longitude: float, **kwargs):\r\n        # super().__init__(**kwargs)\r\n\r\n        temperature_model_parameters = TEMPERATURE_MODEL_PARAMETERS[\"sapm\"][\r\n            \"open_rack_glass_glass\"\r\n        ]\r\n        # Load the database of CEC module model parameters\r\n        modules = pvsystem.retrieve_sam(\"cecmod\")\r\n        # Load the database of CEC inverter model parameters\r\n        inverters = pvsystem.retrieve_sam(\"cecinverter\")\r\n\r\n\r\n        # A bare bone PV simulator\r\n\r\n        # Load the database of CEC module model parameters\r\n        modules = pvsystem.retrieve_sam('cecmod')\r\n        inverters = pvsystem.retrieve_sam('cecinverter')\r\n        module_parameters = modules[model]\r\n        inverter_parameters = inverters[inverter]\r\n\r\n        location = pvlocation.Location(latitude=latitude, longitude=longitude)\r\n        system = pvsystem.PVSystem(module_parameters=module_parameters, inverter_parameters=inverter_parameters, temperature_model_parameters=temperature_model_parameters)\r\n        self.modelchain = modelchain.ModelChain(system, location, aoi_model='no_loss', spectral_model=\"no_loss\")\r\n\r\n    def process(self, data):\r\n        weather = pd.read_json(data)\r\n        # print(f\"raw_weather: {weather}\")\r\n        weather.drop('time.1', axis=1, inplace=True)\r\n        weather['time'] = pd.to_datetime(weather['time']).map(datetime.timestamp) # --> this works for the new process_weather code and also the old weather file\r\n        weather[\"time\"] = weather[\"time\"].apply(self.pv_transform_time)\r\n        weather.index = weather[\"time\"]\r\n        # print(f\"weather: {weather}\")\r\n        # print(weather.dtypes)\r\n        # print(weather['ghi'][0])\r\n        # print(type(weather['ghi'][0]))\r\n\r\n        # simulate\r\n        self.modelchain.run_model(weather)\r\n        # print(self.modelchain.results.ac.to_frame().to_json())\r\n        print(self.modelchain.results.ac)\r\n\r\n\r\n# good data\r\ngood_data = \"{\\\"time\\\":{\\\"12\\\":\\\"2010-01-01 13:30:00+00:00\\\"},\\\"ghi\\\":{\\\"12\\\":36},\\\"dhi\\\":{\\\"12\\\":36},\\\"dni\\\":{\\\"12\\\":0},\\\"Tamb\\\":{\\\"12\\\":8.0},\\\"WindVel\\\":{\\\"12\\\":5.0},\\\"WindDir\\\":{\\\"12\\\":270},\\\"time.1\\\":{\\\"12\\\":\\\"2010-01-01 13:30:00+00:00\\\"}}\"\r\n\r\n# data that causes error\r\ndata = \"{\\\"time\\\":{\\\"4\\\":\\\"2010-01-01 05:30:00+00:00\\\"},\\\"ghi\\\":{\\\"4\\\":0},\\\"dhi\\\":{\\\"4\\\":0},\\\"dni\\\":{\\\"4\\\":0},\\\"Tamb\\\":{\\\"4\\\":8.0},\\\"WindVel\\\":{\\\"4\\\":4.0},\\\"WindDir\\\":{\\\"4\\\":240},\\\"time.1\\\":{\\\"4\\\":\\\"2010-01-01 05:30:00+00:00\\\"}}\"\r\np1 = PV(model=\"Trina_Solar_TSM_300DEG5C_07_II_\", inverter=\"ABB__MICRO_0_25_I_OUTD_US_208__208V_\", latitude=51.204483, longitude=5.265472)\r\np1.process(good_data)\r\nprint(\"=====\")\r\np1.process(data)\r\n```\r\nError:\r\n```log\r\n$ python3 ./tmp-pv.py \r\ntime\r\n2010-01-01 13:30:00    7.825527\r\ndtype: float64\r\n=====\r\n/home/user/.local/lib/python3.10/site-packages/pvlib/tools.py:340: RuntimeWarning: divide by zero encountered in divide\r\n  np.trunc(np.log(atol / (df['VH'] - df['VL'])) / np.log(phim1)))\r\nTraceback (most recent call last):\r\n  File \"/home/user/workspace/enorch/simulator/simulator_processor/src/pv/./tmp-pv.py\", line 88, in <module>\r\n    p1.process(data)\r\n  File \"/home/user/workspace/enorch/simulator/simulator_processor/src/pv/./tmp-pv.py\", line 75, in process\r\n    self.modelchain.run_model(weather)\r\n  File \"/home/user/.local/lib/python3.10/site-packages/pvlib/modelchain.py\", line 1770, in run_model\r\n    self._run_from_effective_irrad(weather)\r\n  File \"/home/user/.local/lib/python3.10/site-packages/pvlib/modelchain.py\", line 1858, in _run_from_effective_irrad\r\n    self.dc_model()\r\n  File \"/home/user/.local/lib/python3.10/site-packages/pvlib/modelchain.py\", line 790, in cec\r\n    return self._singlediode(self.system.calcparams_cec)\r\n  File \"/home/user/.local/lib/python3.10/site-packages/pvlib/modelchain.py\", line 772, in _singlediode\r\n    self.results.dc = tuple(itertools.starmap(\r\n  File \"/home/user/.local/lib/python3.10/site-packages/pvlib/pvsystem.py\", line 931, in singlediode\r\n    return singlediode(photocurrent, saturation_current,\r\n  File \"/home/user/.local/lib/python3.10/site-packages/pvlib/pvsystem.py\", line 2826, in singlediode\r\n    out = _singlediode._lambertw(\r\n  File \"/home/user/.local/lib/python3.10/site-packages/pvlib/singlediode.py\", line 651, in _lambertw\r\n    p_mp, v_mp = _golden_sect_DataFrame(params, 0., v_oc * 1.14,\r\n  File \"/home/user/.local/lib/python3.10/site-packages/pvlib/tools.py\", line 364, in _golden_sect_DataFrame\r\n    raise Exception(\"Iterations exceeded maximum. Check that func\",\r\nException: ('Iterations exceeded maximum. Check that func', ' is not NaN in (lower, upper)')\r\n```\r\n\r\nI have to mention that for now the workaround that I am using is to pass the weather data as a dataframe with two rows, the first row is a good weather data that pvlib can process and the second row is the incoming weather reading (I can also post that code if you want).\r\n\r\n**Expected behavior**\r\nPVlib should have consistent behavior and regardless of GHI-DHI readings.\r\n\r\n**Versions:**\r\n```python\r\n>>> import pvlib\r\n>>> import pandas\r\n>>> pvlib.__version__\r\n'0.9.1'\r\n>>> pandas.__version__\r\n'1.4.3'\r\n``` \r\n - python: 3.10.6\r\n- OS: Ubuntu 22.04.1 LTS\n", "pr_diff": "diff --git a/pvlib/tools.py b/pvlib/tools.py\n--- a/pvlib/tools.py\n+++ b/pvlib/tools.py\n@@ -341,6 +341,8 @@ def _golden_sect_DataFrame(params, lower, upper, func, atol=1e-8):\n     --------\n     pvlib.singlediode._pwr_optfcn\n     \"\"\"\n+    if np.any(upper - lower < 0.):\n+        raise ValueError('upper >= lower is required')\n \n     phim1 = (np.sqrt(5) - 1) / 2\n \n@@ -349,16 +351,8 @@ def _golden_sect_DataFrame(params, lower, upper, func, atol=1e-8):\n     df['VL'] = lower\n \n     converged = False\n-    iterations = 0\n \n-    # handle all NaN case gracefully\n-    with warnings.catch_warnings():\n-        warnings.filterwarnings(action='ignore',\n-                                message='All-NaN slice encountered')\n-        iterlimit = 1 + np.nanmax(\n-            np.trunc(np.log(atol / (df['VH'] - df['VL'])) / np.log(phim1)))\n-\n-    while not converged and (iterations <= iterlimit):\n+    while not converged:\n \n         phi = phim1 * (df['VH'] - df['VL'])\n         df['V1'] = df['VL'] + phi\n@@ -373,22 +367,16 @@ def _golden_sect_DataFrame(params, lower, upper, func, atol=1e-8):\n \n         err = abs(df['V2'] - df['V1'])\n \n-        # works with single value because err is np.float64\n-        converged = (err[~np.isnan(err)] < atol).all()\n-        # err will be less than atol before iterations hit the limit\n-        # but just to be safe\n-        iterations += 1\n-\n-    if iterations > iterlimit:\n-        raise Exception(\"Iterations exceeded maximum. Check that func\",\n-                        \" is not NaN in (lower, upper)\")  # pragma: no cover\n+        # handle all NaN case gracefully\n+        with warnings.catch_warnings():\n+            warnings.filterwarnings(action='ignore',\n+                                    message='All-NaN slice encountered')\n+            converged = np.all(err[~np.isnan(err)] < atol)\n \n-    try:\n-        func_result = func(df, 'V1')\n-        x = np.where(np.isnan(func_result), np.nan, df['V1'])\n-    except KeyError:\n-        func_result = np.full_like(upper, np.nan)\n-        x = func_result.copy()\n+    # best estimate of location of maximum\n+    df['max'] = 0.5 * (df['V1'] + df['V2'])\n+    func_result = func(df, 'max')\n+    x = np.where(np.isnan(func_result), np.nan, df['max'])\n \n     return func_result, x\n \n", "solution": "diff --git a/pvlib/tools.py b/pvlib/tools.py\n--- a/pvlib/tools.py\n+++ b/pvlib/tools.py\n@@ -341,6 +341,8 @@ def _golden_sect_DataFrame(params, lower, upper, func, atol=1e-8):\n     --------\n     pvlib.singlediode._pwr_optfcn\n     \"\"\"\n+    if np.any(upper - lower < 0.):\n+        raise ValueError('upper >= lower is required')\n \n     phim1 = (np.sqrt(5) - 1) / 2\n \n@@ -349,16 +351,8 @@ def _golden_sect_DataFrame(params, lower, upper, func, atol=1e-8):\n     df['VL'] = lower\n \n     converged = False\n-    iterations = 0\n \n-    # handle all NaN case gracefully\n-    with warnings.catch_warnings():\n-        warnings.filterwarnings(action='ignore',\n-                                message='All-NaN slice encountered')\n-        iterlimit = 1 + np.nanmax(\n-            np.trunc(np.log(atol / (df['VH'] - df['VL'])) / np.log(phim1)))\n-\n-    while not converged and (iterations <= iterlimit):\n+    while not converged:\n \n         phi = phim1 * (df['VH'] - df['VL'])\n         df['V1'] = df['VL'] + phi\n@@ -373,22 +367,16 @@ def _golden_sect_DataFrame(params, lower, upper, func, atol=1e-8):\n \n         err = abs(df['V2'] - df['V1'])\n \n-        # works with single value because err is np.float64\n-        converged = (err[~np.isnan(err)] < atol).all()\n-        # err will be less than atol before iterations hit the limit\n-        # but just to be safe\n-        iterations += 1\n-\n-    if iterations > iterlimit:\n-        raise Exception(\"Iterations exceeded maximum. Check that func\",\n-                        \" is not NaN in (lower, upper)\")  # pragma: no cover\n+        # handle all NaN case gracefully\n+        with warnings.catch_warnings():\n+            warnings.filterwarnings(action='ignore',\n+                                    message='All-NaN slice encountered')\n+            converged = np.all(err[~np.isnan(err)] < atol)\n \n-    try:\n-        func_result = func(df, 'V1')\n-        x = np.where(np.isnan(func_result), np.nan, df['V1'])\n-    except KeyError:\n-        func_result = np.full_like(upper, np.nan)\n-        x = func_result.copy()\n+    # best estimate of location of maximum\n+    df['max'] = 0.5 * (df['V1'] + df['V2'])\n+    func_result = func(df, 'max')\n+    x = np.where(np.isnan(func_result), np.nan, df['max'])\n \n     return func_result, x\n \n", "test_command": "[\"pvlib/tests/test_tools.py::test__golden_sect_DataFrame_vector\"]", "test_commands": ["[\"pvlib/tests/test_tools.py::test__golden_sect_DataFrame_vector\"]", "[\"pvlib/tests/test_tools.py::test_build_kwargs[keys0-input_dict0-expected0]\", \"pvlib/tests/test_tools.py::test_build_kwargs[keys1-input_dict1-expected1]\", \"pvlib/tests/test_tools.py::test_build_kwargs[keys2-input_dict2-expected2]\", \"pvlib/tests/test_tools.py::test_build_kwargs[keys3-input_dict3-expected3]\", \"pvlib/tests/test_tools.py::test__golden_sect_DataFrame[params0-0.0-1.0-0.5-_obj_test_golden_sect]\", \"pvlib/tests/test_tools.py::test__golden_sect_DataFrame[params1-0.0-1.0-0.07230200263994839-_obj_test_golden_sect]\", \"pvlib/tests/test_tools.py::test__golden_sect_DataFrame[params2-0.0-100.0-89.14332727531685-_obj_test_golden_sect]\", \"pvlib/tests/test_tools.py::test__golden_sect_DataFrame_atol\", \"pvlib/tests/test_tools.py::test__golden_sect_DataFrame_nans\", \"pvlib/tests/test_tools.py::test_degrees_to_index_1\"]"], "files_to_edit": ["pvlib/tools.py"], "metadata": {"hints_text": "Confirmed. This appears to be an oversight in `pvlib.tools._golden_section_DataFrame` involving error messaging, likely introduced with #1089 .\r\n\r\nIn this code when processing the content of `data`, photocurrent is 0., hence the shunt resistance is infinite and v_oc is 0. That sets the range for the golden section search to be [0., 0.]. [iterlimit](https://github.com/pvlib/pvlib-python/blob/582b956c63c463e5178fbb7a88fa545fa5b1c257/pvlib/tools.py#L358) is then -infinity, which skips the loop (`iterations <= iterlimit`) but since `iterations > iterlimit` raises the \"Iterations exceeded...\" exception.\r\n", "created_at": "2022-12-07T21:12:08Z", "version": "0.8", "test_patch": "diff --git a/pvlib/tests/test_tools.py b/pvlib/tests/test_tools.py\n--- a/pvlib/tests/test_tools.py\n+++ b/pvlib/tests/test_tools.py\n@@ -45,6 +45,22 @@ def test__golden_sect_DataFrame_vector():\n     v, x = tools._golden_sect_DataFrame(params, lower, upper,\n                                         _obj_test_golden_sect)\n     assert np.allclose(x, expected, atol=1e-8)\n+    # some upper and lower bounds equal\n+    params = {'c': np.array([1., 2., 1.]), 'n': np.array([1., 1., 1.])}\n+    lower = np.array([0., 0.001, 1.])\n+    upper = np.array([1., 1.2, 1.])\n+    expected = np.array([0.5, 0.25, 1.0])  # x values for maxima\n+    v, x = tools._golden_sect_DataFrame(params, lower, upper,\n+                                        _obj_test_golden_sect)\n+    assert np.allclose(x, expected, atol=1e-8)\n+    # all upper and lower bounds equal, arrays of length 1\n+    params = {'c': np.array([1.]), 'n': np.array([1.])}\n+    lower = np.array([1.])\n+    upper = np.array([1.])\n+    expected = np.array([1.])  # x values for maxima\n+    v, x = tools._golden_sect_DataFrame(params, lower, upper,\n+                                        _obj_test_golden_sect)\n+    assert np.allclose(x, expected, atol=1e-8)\n \n \n def test__golden_sect_DataFrame_nans():\n", "environment_setup_commit": "ef8ad2fee9840a77d14b0dfd17fc489dd85c9b91"}}
{"problem_id": "pvlib__pvlib-python-1854", "repo_owner": "pvlib", "repo_name": "pvlib-python", "repo_url": "https://github.com/pvlib/pvlib-python", "base_commit": "27a3a07ebc84b11014d3753e4923902adf9a38c0", "problem": "PVSystem with single Array generates an error\n**Is your feature request related to a problem? Please describe.**\r\n\r\nWhen a PVSystem has a single Array, you can't assign just the Array instance when constructing the PVSystem.\r\n\r\n```\r\nmount = pvlib.pvsystem.FixedMount(surface_tilt=35, surface_azimuth=180)\r\narray = pvlib.pvsystem.Array(mount=mount)\r\npv = pvlib.pvsystem.PVSystem(arrays=array)\r\n\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-13-f5424e3db16a> in <module>\r\n      3 mount = pvlib.pvsystem.FixedMount(surface_tilt=35, surface_azimuth=180)\r\n      4 array = pvlib.pvsystem.Array(mount=mount)\r\n----> 5 pv = pvlib.pvsystem.PVSystem(arrays=array)\r\n\r\n~\\anaconda3\\lib\\site-packages\\pvlib\\pvsystem.py in __init__(self, arrays, surface_tilt, surface_azimuth, albedo, surface_type, module, module_type, module_parameters, temperature_model_parameters, modules_per_string, strings_per_inverter, inverter, inverter_parameters, racking_model, losses_parameters, name)\r\n    251                 array_losses_parameters,\r\n    252             ),)\r\n--> 253         elif len(arrays) == 0:\r\n    254             raise ValueError(\"PVSystem must have at least one Array. \"\r\n    255                              \"If you want to create a PVSystem instance \"\r\n\r\nTypeError: object of type 'Array' has no len()\r\n\r\n```\r\n\r\nNot a bug per se, since the PVSystem docstring requests that `arrays` be iterable. Still, a bit inconvenient to have to do this\r\n\r\n```\r\nmount = pvlib.pvsystem.FixedMount(surface_tilt=35, surface_azimuth=180)\r\narray = pvlib.pvsystem.Array(mount=mount)\r\npv = pvlib.pvsystem.PVSystem(arrays=[array])\r\n```\r\n\r\n**Describe the solution you'd like**\r\nHandle `arrays=array` where `array` is an instance of `Array`\r\n\r\n**Describe alternatives you've considered**\r\nStatus quo - either make the single Array into a list, or use the PVSystem kwargs.\r\n\n", "issue_title": "Fix issue in pvlib/pvlib-python", "issue_body": "PVSystem with single Array generates an error\n**Is your feature request related to a problem? Please describe.**\r\n\r\nWhen a PVSystem has a single Array, you can't assign just the Array instance when constructing the PVSystem.\r\n\r\n```\r\nmount = pvlib.pvsystem.FixedMount(surface_tilt=35, surface_azimuth=180)\r\narray = pvlib.pvsystem.Array(mount=mount)\r\npv = pvlib.pvsystem.PVSystem(arrays=array)\r\n\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-13-f5424e3db16a> in <module>\r\n      3 mount = pvlib.pvsystem.FixedMount(surface_tilt=35, surface_azimuth=180)\r\n      4 array = pvlib.pvsystem.Array(mount=mount)\r\n----> 5 pv = pvlib.pvsystem.PVSystem(arrays=array)\r\n\r\n~\\anaconda3\\lib\\site-packages\\pvlib\\pvsystem.py in __init__(self, arrays, surface_tilt, surface_azimuth, albedo, surface_type, module, module_type, module_parameters, temperature_model_parameters, modules_per_string, strings_per_inverter, inverter, inverter_parameters, racking_model, losses_parameters, name)\r\n    251                 array_losses_parameters,\r\n    252             ),)\r\n--> 253         elif len(arrays) == 0:\r\n    254             raise ValueError(\"PVSystem must have at least one Array. \"\r\n    255                              \"If you want to create a PVSystem instance \"\r\n\r\nTypeError: object of type 'Array' has no len()\r\n\r\n```\r\n\r\nNot a bug per se, since the PVSystem docstring requests that `arrays` be iterable. Still, a bit inconvenient to have to do this\r\n\r\n```\r\nmount = pvlib.pvsystem.FixedMount(surface_tilt=35, surface_azimuth=180)\r\narray = pvlib.pvsystem.Array(mount=mount)\r\npv = pvlib.pvsystem.PVSystem(arrays=[array])\r\n```\r\n\r\n**Describe the solution you'd like**\r\nHandle `arrays=array` where `array` is an instance of `Array`\r\n\r\n**Describe alternatives you've considered**\r\nStatus quo - either make the single Array into a list, or use the PVSystem kwargs.\r\n\n", "pr_diff": "diff --git a/pvlib/pvsystem.py b/pvlib/pvsystem.py\n--- a/pvlib/pvsystem.py\n+++ b/pvlib/pvsystem.py\n@@ -101,10 +101,11 @@ class PVSystem:\n \n     Parameters\n     ----------\n-    arrays : iterable of Array, optional\n-        List of arrays that are part of the system. If not specified\n-        a single array is created from the other parameters (e.g.\n-        `surface_tilt`, `surface_azimuth`). Must contain at least one Array,\n+    arrays : Array or iterable of Array, optional\n+        An Array or list of arrays that are part of the system. If not\n+        specified a single array is created from the other parameters (e.g.\n+        `surface_tilt`, `surface_azimuth`). If specified as a list, the list\n+        must contain at least one Array;\n         if length of arrays is 0 a ValueError is raised. If `arrays` is\n         specified the following PVSystem parameters are ignored:\n \n@@ -220,6 +221,8 @@ def __init__(self,\n                 strings_per_inverter,\n                 array_losses_parameters,\n             ),)\n+        elif isinstance(arrays, Array):\n+            self.arrays = (arrays,)\n         elif len(arrays) == 0:\n             raise ValueError(\"PVSystem must have at least one Array. \"\n                              \"If you want to create a PVSystem instance \"\n", "solution": "diff --git a/pvlib/pvsystem.py b/pvlib/pvsystem.py\n--- a/pvlib/pvsystem.py\n+++ b/pvlib/pvsystem.py\n@@ -101,10 +101,11 @@ class PVSystem:\n \n     Parameters\n     ----------\n-    arrays : iterable of Array, optional\n-        List of arrays that are part of the system. If not specified\n-        a single array is created from the other parameters (e.g.\n-        `surface_tilt`, `surface_azimuth`). Must contain at least one Array,\n+    arrays : Array or iterable of Array, optional\n+        An Array or list of arrays that are part of the system. If not\n+        specified a single array is created from the other parameters (e.g.\n+        `surface_tilt`, `surface_azimuth`). If specified as a list, the list\n+        must contain at least one Array;\n         if length of arrays is 0 a ValueError is raised. If `arrays` is\n         specified the following PVSystem parameters are ignored:\n \n@@ -220,6 +221,8 @@ def __init__(self,\n                 strings_per_inverter,\n                 array_losses_parameters,\n             ),)\n+        elif isinstance(arrays, Array):\n+            self.arrays = (arrays,)\n         elif len(arrays) == 0:\n             raise ValueError(\"PVSystem must have at least one Array. \"\n                              \"If you want to create a PVSystem instance \"\n", "test_command": "[\"pvlib/tests/test_pvsystem.py::test_PVSystem_single_array\"]", "test_commands": ["[\"pvlib/tests/test_pvsystem.py::test_PVSystem_single_array\"]", "[\"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam[ashrae-model_params0]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam[physical-model_params1]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam[martin_ruiz-model_params2]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_get_iam\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam_sapm\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam_interp\", \"pvlib/tests/test_pvsystem.py::test__normalize_sam_product_names\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam_invalid\", \"pvlib/tests/test_pvsystem.py::test_retrieve_sam_raise_no_parameters\", \"pvlib/tests/test_pvsystem.py::test_retrieve_sam_cecmod\", \"pvlib/tests/test_pvsystem.py::test_retrieve_sam_cecinverter\", \"pvlib/tests/test_pvsystem.py::test_sapm\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_sapm\", \"pvlib/tests/test_pvsystem.py::test_sapm_spectral_loss_deprecated\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_spectral_loss\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_sapm_spectral_loss\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_first_solar_spectral_loss[module_parameters0-multisi-None]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_first_solar_spectral_loss[module_parameters1-multisi-None]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_first_solar_spectral_loss[module_parameters2-None-coefficients2]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_first_solar_spectral_loss\", \"pvlib/tests/test_pvsystem.py::test_sapm_effective_irradiance[test_input0-1140.0510967821876]\", \"pvlib/tests/test_pvsystem.py::test_sapm_effective_irradiance[test_input1-expected1]\", \"pvlib/tests/test_pvsystem.py::test_sapm_effective_irradiance[test_input2-expected2]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_effective_irradiance\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_sapm_effective_irradiance\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_effective_irradiance_value_error[20-poa_diffuse0-aoi0]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_effective_irradiance_value_error[poa_direct1-poa_diffuse1-aoi1]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_effective_irradiance_value_error[poa_direct2-poa_diffuse2-20]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_celltemp_kwargs\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_sapm_celltemp_different_arrays\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvsyst_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_faiman_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_noct_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_noct_celltemp_error\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_functions[faiman]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_functions[pvsyst]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_functions[sapm]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_functions[fuentes]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_functions[noct_sam]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_temp[faiman]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_temp[pvsyst]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_temp[sapm]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_temp[fuentes]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_temp[noct_sam]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_wind[faiman]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_wind[pvsyst]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_wind[sapm]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_wind[fuentes]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_wind[noct_sam]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_cell_temperature_invalid\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_short[faiman]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_short[pvsyst]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_short[sapm]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_short[fuentes]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_short[noct_sam]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_long[faiman]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_long[pvsyst]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_long[sapm]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_long[fuentes]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_long[noct_sam]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_short[faiman]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_short[pvsyst]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_short[sapm]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_short[fuentes]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_short[noct_sam]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_long[faiman]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_long[pvsyst]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_long[sapm]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_long[fuentes]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_long[noct_sam]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_poa_length_mismatch[faiman]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_poa_length_mismatch[pvsyst]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_poa_length_mismatch[sapm]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_poa_length_mismatch[fuentes]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_poa_length_mismatch[noct_sam]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_fuentes_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_fuentes_module_height\", \"pvlib/tests/test_pvsystem.py::test_Array__infer_temperature_model_params\", \"pvlib/tests/test_pvsystem.py::test_Array__infer_cell_type\", \"pvlib/tests/test_pvsystem.py::test_calcparams_desoto_returns_correct_Python_type[numeric_type_funcs0]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_desoto_returns_correct_Python_type[numeric_type_funcs1]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_desoto_returns_correct_Python_type[numeric_type_funcs2]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_desoto_returns_correct_Python_type[numeric_type_funcs3]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_desoto_returns_correct_Python_type[numeric_type_funcs4]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_desoto_returns_correct_Python_type[numeric_type_funcs5]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_desoto_returns_correct_Python_type[numeric_type_funcs6]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_desoto_returns_correct_Python_type[numeric_type_funcs7]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_desoto_returns_correct_Python_type[numeric_type_funcs8]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_desoto_returns_correct_Python_type[numeric_type_funcs9]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_desoto_returns_correct_Python_type[numeric_type_funcs10]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_desoto_returns_correct_Python_type[numeric_type_funcs11]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_desoto_returns_correct_Python_type[numeric_type_funcs12]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_desoto_returns_correct_Python_type[numeric_type_funcs13]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_desoto_returns_correct_Python_type[numeric_type_funcs14]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_desoto_returns_correct_Python_type[numeric_type_funcs15]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_cec_returns_correct_Python_type[numeric_type_funcs0]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_cec_returns_correct_Python_type[numeric_type_funcs1]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_cec_returns_correct_Python_type[numeric_type_funcs2]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_cec_returns_correct_Python_type[numeric_type_funcs3]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_cec_returns_correct_Python_type[numeric_type_funcs4]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_cec_returns_correct_Python_type[numeric_type_funcs5]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_cec_returns_correct_Python_type[numeric_type_funcs6]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_cec_returns_correct_Python_type[numeric_type_funcs7]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_cec_returns_correct_Python_type[numeric_type_funcs8]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_cec_returns_correct_Python_type[numeric_type_funcs9]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_cec_returns_correct_Python_type[numeric_type_funcs10]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_cec_returns_correct_Python_type[numeric_type_funcs11]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_cec_returns_correct_Python_type[numeric_type_funcs12]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_cec_returns_correct_Python_type[numeric_type_funcs13]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_cec_returns_correct_Python_type[numeric_type_funcs14]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_cec_returns_correct_Python_type[numeric_type_funcs15]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_pvsyst_returns_correct_Python_type[numeric_type_funcs0]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_pvsyst_returns_correct_Python_type[numeric_type_funcs1]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_pvsyst_returns_correct_Python_type[numeric_type_funcs2]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_pvsyst_returns_correct_Python_type[numeric_type_funcs3]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_pvsyst_returns_correct_Python_type[numeric_type_funcs4]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_pvsyst_returns_correct_Python_type[numeric_type_funcs5]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_pvsyst_returns_correct_Python_type[numeric_type_funcs6]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_pvsyst_returns_correct_Python_type[numeric_type_funcs7]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_pvsyst_returns_correct_Python_type[numeric_type_funcs8]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_pvsyst_returns_correct_Python_type[numeric_type_funcs9]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_pvsyst_returns_correct_Python_type[numeric_type_funcs10]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_pvsyst_returns_correct_Python_type[numeric_type_funcs11]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_pvsyst_returns_correct_Python_type[numeric_type_funcs12]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_pvsyst_returns_correct_Python_type[numeric_type_funcs13]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_pvsyst_returns_correct_Python_type[numeric_type_funcs14]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_pvsyst_returns_correct_Python_type[numeric_type_funcs15]\", \"pvlib/tests/test_pvsystem.py::test_calcparams_desoto_all_scalars\", \"pvlib/tests/test_pvsystem.py::test_calcparams_cec_all_scalars\", \"pvlib/tests/test_pvsystem.py::test_calcparams_pvsyst_all_scalars\", \"pvlib/tests/test_pvsystem.py::test_calcparams_desoto\", \"pvlib/tests/test_pvsystem.py::test_calcparams_cec\", \"pvlib/tests/test_pvsystem.py::test_calcparams_cec_extra_params_propagation\", \"pvlib/tests/test_pvsystem.py::test_calcparams_pvsyst\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_calcparams_desoto\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_calcparams_pvsyst\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams[calcparams_pvsyst]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams[calcparams_desoto]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams[calcparams_cec]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams_value_error[calcparams_desoto-1-celltemp0]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams_value_error[calcparams_desoto-irrad1-1]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams_value_error[calcparams_cec-1-celltemp2]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams_value_error[calcparams_cec-irrad3-1]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams_value_error[calcparams_pvsyst-1-celltemp4]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams_value_error[calcparams_pvsyst-irrad5-1]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i0-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i0-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i0-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i1-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i1-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i1-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i2-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i2-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i2-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i3-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i3-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i3-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i4-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i4-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i4-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i5-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i5-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i5-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i6-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i6-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i6-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i7-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i7-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i7-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i8-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i8-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i8-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i9-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i9-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i9-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i10-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i10-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i10-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i0]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i1]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i2]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i3]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i4]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i5]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i6]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i7]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i8]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i9]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i10]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v0-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v0-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v0-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v1-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v1-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v1-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v2-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v2-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v2-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v3-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v3-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v3-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v4-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v4-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v4-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v5-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v5-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v5-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v6-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v6-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v6-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_i_from_v\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_size\", \"pvlib/tests/test_pvsystem.py::test_v_from_i_size\", \"pvlib/tests/test_pvsystem.py::test_mpp_floats\", \"pvlib/tests/test_pvsystem.py::test_mpp_recombination\", \"pvlib/tests/test_pvsystem.py::test_mpp_array\", \"pvlib/tests/test_pvsystem.py::test_mpp_series\", \"pvlib/tests/test_pvsystem.py::test_singlediode_series\", \"pvlib/tests/test_pvsystem.py::test_singlediode_array\", \"pvlib/tests/test_pvsystem.py::test_singlediode_floats\", \"pvlib/tests/test_pvsystem.py::test_singlediode_floats_ivcurve\", \"pvlib/tests/test_pvsystem.py::test_singlediode_series_ivcurve\", \"pvlib/tests/test_pvsystem.py::test_singlediode_ivcurvepnts_deprecation_warning[lambertw]\", \"pvlib/tests/test_pvsystem.py::test_singlediode_ivcurvepnts_deprecation_warning[brentq]\", \"pvlib/tests/test_pvsystem.py::test_singlediode_ivcurvepnts_deprecation_warning[newton]\", \"pvlib/tests/test_pvsystem.py::test_scale_voltage_current_power\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_scale_voltage_current_power\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_scale_voltage_current_power\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_sandia\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_sandia_multi\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_pvwatts\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_pvwatts_kwargs\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_pvwatts_multi\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_single_array_tuple_input[sandia]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_single_array_tuple_input[adr]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_single_array_tuple_input[pvwatts]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_adr\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_adr_multi\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_invalid\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_creation\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multiple_array_creation\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_aoi\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multiple_array_get_aoi\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_irradiance\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_irradiance_albedo\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_irradiance_model\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_get_irradiance\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_get_irradiance_multi_irrad\", \"pvlib/tests/test_pvsystem.py::test_Array_get_irradiance\", \"pvlib/tests/test_pvsystem.py::test_PVSystem___repr__\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array___repr__\", \"pvlib/tests/test_pvsystem.py::test_Array___repr__\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_dc_scalars\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_dc_arrays\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_dc_series\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_losses_default\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_losses_arrays\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_losses_series\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_dc\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_dc_kwargs\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multiple_array_pvwatts_dc\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multiple_array_pvwatts_dc_value_error\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_losses\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_num_arrays\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_at_least_one_array\", \"pvlib/tests/test_pvsystem.py::test_combine_loss_factors\", \"pvlib/tests/test_pvsystem.py::test_no_extra_kwargs\", \"pvlib/tests/test_pvsystem.py::test_AbstractMount_constructor\", \"pvlib/tests/test_pvsystem.py::test_FixedMount_constructor\", \"pvlib/tests/test_pvsystem.py::test_FixedMount_get_orientation\", \"pvlib/tests/test_pvsystem.py::test_SingleAxisTrackerMount_constructor\", \"pvlib/tests/test_pvsystem.py::test_SingleAxisTrackerMount_get_orientation\", \"pvlib/tests/test_pvsystem.py::test_dc_ohms_from_percent\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_dc_ohms_from_percent\", \"pvlib/tests/test_pvsystem.py::test_dc_ohmic_losses\", \"pvlib/tests/test_pvsystem.py::test_Array_dc_ohms_from_percent\", \"pvlib/tests/test_pvsystem.py::test_Array_temperature_missing_parameters[sapm-keys0]\", \"pvlib/tests/test_pvsystem.py::test_Array_temperature_missing_parameters[fuentes-keys1]\", \"pvlib/tests/test_pvsystem.py::test_Array_temperature_missing_parameters[noct_sam-keys2]\"]"], "files_to_edit": ["pvlib/pvsystem.py"], "metadata": {"hints_text": "", "created_at": "2023-09-13T17:25:47Z", "version": "0.9", "test_patch": "diff --git a/pvlib/tests/test_pvsystem.py b/pvlib/tests/test_pvsystem.py\n--- a/pvlib/tests/test_pvsystem.py\n+++ b/pvlib/tests/test_pvsystem.py\n@@ -1887,8 +1887,6 @@ def test_PVSystem_multiple_array_creation():\n     assert pv_system.arrays[0].module_parameters == {}\n     assert pv_system.arrays[1].module_parameters == {'pdc0': 1}\n     assert pv_system.arrays == (array_one, array_two)\n-    with pytest.raises(TypeError):\n-        pvsystem.PVSystem(arrays=array_one)\n \n \n def test_PVSystem_get_aoi():\n@@ -2362,6 +2360,14 @@ def test_PVSystem_at_least_one_array():\n         pvsystem.PVSystem(arrays=[])\n \n \n+def test_PVSystem_single_array():\n+    # GH 1831\n+    single_array = pvsystem.Array(pvsystem.FixedMount())\n+    system = pvsystem.PVSystem(arrays=single_array)\n+    assert isinstance(system.arrays, tuple)\n+    assert system.arrays[0] is single_array\n+\n+\n def test_combine_loss_factors():\n     test_index = pd.date_range(start='1990/01/01T12:00', periods=365, freq='D')\n     loss_1 = pd.Series(.10, index=test_index)\n", "environment_setup_commit": "6072e0982c3c0236f532ddfa48fbf461180d834e"}}
{"problem_id": "pvlib__pvlib-python-1154", "repo_owner": "pvlib", "repo_name": "pvlib-python", "repo_url": "https://github.com/pvlib/pvlib-python", "base_commit": "0b8f24c265d76320067a5ee908a57d475cd1bb24", "problem": "pvlib.irradiance.reindl() model generates NaNs when GHI = 0\n**Describe the bug**\r\nThe reindl function should give zero sky diffuse when GHI is zero. Instead it generates NaN or Inf values due to \"term3\" having a quotient that divides by GHI.  \r\n\r\n**Expected behavior**\r\nThe reindl function should result in zero sky diffuse when GHI is zero.\r\n\r\n\npvlib.irradiance.reindl() model generates NaNs when GHI = 0\n**Describe the bug**\r\nThe reindl function should give zero sky diffuse when GHI is zero. Instead it generates NaN or Inf values due to \"term3\" having a quotient that divides by GHI.  \r\n\r\n**Expected behavior**\r\nThe reindl function should result in zero sky diffuse when GHI is zero.\r\n\r\n\n", "issue_title": "Fix issue in pvlib/pvlib-python", "issue_body": "pvlib.irradiance.reindl() model generates NaNs when GHI = 0\n**Describe the bug**\r\nThe reindl function should give zero sky diffuse when GHI is zero. Instead it generates NaN or Inf values due to \"term3\" having a quotient that divides by GHI.  \r\n\r\n**Expected behavior**\r\nThe reindl function should result in zero sky diffuse when GHI is zero.\r\n\r\n\npvlib.irradiance.reindl() model generates NaNs when GHI = 0\n**Describe the bug**\r\nThe reindl function should give zero sky diffuse when GHI is zero. Instead it generates NaN or Inf values due to \"term3\" having a quotient that divides by GHI.  \r\n\r\n**Expected behavior**\r\nThe reindl function should result in zero sky diffuse when GHI is zero.\r\n\r\n\n", "pr_diff": "diff --git a/pvlib/irradiance.py b/pvlib/irradiance.py\n--- a/pvlib/irradiance.py\n+++ b/pvlib/irradiance.py\n@@ -886,8 +886,9 @@ def reindl(surface_tilt, surface_azimuth, dhi, dni, ghi, dni_extra,\n     # these are the () and [] sub-terms of the second term of eqn 8\n     term1 = 1 - AI\n     term2 = 0.5 * (1 + tools.cosd(surface_tilt))\n-    term3 = 1 + np.sqrt(HB / ghi) * (tools.sind(0.5 * surface_tilt) ** 3)\n-\n+    with np.errstate(invalid='ignore', divide='ignore'):\n+        hb_to_ghi = np.where(ghi == 0, 0, np.divide(HB, ghi))\n+    term3 = 1 + np.sqrt(hb_to_ghi) * (tools.sind(0.5 * surface_tilt)**3)\n     sky_diffuse = dhi * (AI * Rb + term1 * term2 * term3)\n     sky_diffuse = np.maximum(sky_diffuse, 0)\n \n", "solution": "diff --git a/pvlib/irradiance.py b/pvlib/irradiance.py\n--- a/pvlib/irradiance.py\n+++ b/pvlib/irradiance.py\n@@ -886,8 +886,9 @@ def reindl(surface_tilt, surface_azimuth, dhi, dni, ghi, dni_extra,\n     # these are the () and [] sub-terms of the second term of eqn 8\n     term1 = 1 - AI\n     term2 = 0.5 * (1 + tools.cosd(surface_tilt))\n-    term3 = 1 + np.sqrt(HB / ghi) * (tools.sind(0.5 * surface_tilt) ** 3)\n-\n+    with np.errstate(invalid='ignore', divide='ignore'):\n+        hb_to_ghi = np.where(ghi == 0, 0, np.divide(HB, ghi))\n+    term3 = 1 + np.sqrt(hb_to_ghi) * (tools.sind(0.5 * surface_tilt)**3)\n     sky_diffuse = dhi * (AI * Rb + term1 * term2 * term3)\n     sky_diffuse = np.maximum(sky_diffuse, 0)\n \n", "test_command": "[\"pvlib/tests/test_irradiance.py::test_reindl\"]", "test_commands": ["[\"pvlib/tests/test_irradiance.py::test_reindl\"]", "[\"pvlib/tests/test_irradiance.py::test_get_extra_radiation[asce-300-1383.636203]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[asce-300.0-1383.636203]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[asce-testval2-1383.636203]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[asce-testval3-1383.636203]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[asce-testval4-1383.636203]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[asce-testval5-expected5]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[asce-testval6-expected6]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[asce-testval7-expected7]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[asce-testval8-1383.636203]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[spencer-300-1383.636203]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[spencer-300.0-1383.636203]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[spencer-testval2-1383.636203]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[spencer-testval3-1383.636203]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[spencer-testval4-1383.636203]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[spencer-testval5-expected5]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[spencer-testval6-expected6]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[spencer-testval7-expected7]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[spencer-testval8-1383.636203]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[nrel-300-1383.636203]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[nrel-300.0-1383.636203]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[nrel-testval2-1383.636203]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[nrel-testval3-1383.636203]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[nrel-testval4-1383.636203]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[nrel-testval5-expected5]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[nrel-testval6-expected6]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[nrel-testval7-expected7]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[nrel-testval8-1383.636203]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[pyephem-300-1383.636203]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[pyephem-300.0-1383.636203]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[pyephem-testval2-1383.636203]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[pyephem-testval3-1383.636203]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[pyephem-testval4-1383.636203]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[pyephem-testval5-expected5]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[pyephem-testval6-expected6]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[pyephem-testval7-expected7]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation[pyephem-testval8-1383.636203]\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation_epoch_year\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation_nrel_numba\", \"pvlib/tests/test_irradiance.py::test_get_extra_radiation_invalid\", \"pvlib/tests/test_irradiance.py::test_grounddiffuse_simple_float\", \"pvlib/tests/test_irradiance.py::test_grounddiffuse_simple_series\", \"pvlib/tests/test_irradiance.py::test_grounddiffuse_albedo_0\", \"pvlib/tests/test_irradiance.py::test_grounddiffuse_albedo_invalid_surface\", \"pvlib/tests/test_irradiance.py::test_grounddiffuse_albedo_surface\", \"pvlib/tests/test_irradiance.py::test_isotropic_float\", \"pvlib/tests/test_irradiance.py::test_isotropic_series\", \"pvlib/tests/test_irradiance.py::test_klucher_series_float\", \"pvlib/tests/test_irradiance.py::test_klucher_series\", \"pvlib/tests/test_irradiance.py::test_haydavies\", \"pvlib/tests/test_irradiance.py::test_king\", \"pvlib/tests/test_irradiance.py::test_perez\", \"pvlib/tests/test_irradiance.py::test_perez_components\", \"pvlib/tests/test_irradiance.py::test_perez_arrays\", \"pvlib/tests/test_irradiance.py::test_perez_scalar\", \"pvlib/tests/test_irradiance.py::test_sky_diffuse_zenith_close_to_90[isotropic]\", \"pvlib/tests/test_irradiance.py::test_sky_diffuse_zenith_close_to_90[klucher]\", \"pvlib/tests/test_irradiance.py::test_sky_diffuse_zenith_close_to_90[haydavies]\", \"pvlib/tests/test_irradiance.py::test_sky_diffuse_zenith_close_to_90[reindl]\", \"pvlib/tests/test_irradiance.py::test_sky_diffuse_zenith_close_to_90[king]\", \"pvlib/tests/test_irradiance.py::test_sky_diffuse_zenith_close_to_90[perez]\", \"pvlib/tests/test_irradiance.py::test_get_sky_diffuse_invalid\", \"pvlib/tests/test_irradiance.py::test_campbell_norman\", \"pvlib/tests/test_irradiance.py::test_get_total_irradiance\", \"pvlib/tests/test_irradiance.py::test_get_total_irradiance_scalars[isotropic]\", \"pvlib/tests/test_irradiance.py::test_get_total_irradiance_scalars[klucher]\", \"pvlib/tests/test_irradiance.py::test_get_total_irradiance_scalars[haydavies]\", \"pvlib/tests/test_irradiance.py::test_get_total_irradiance_scalars[reindl]\", \"pvlib/tests/test_irradiance.py::test_get_total_irradiance_scalars[king]\", \"pvlib/tests/test_irradiance.py::test_get_total_irradiance_scalars[perez]\", \"pvlib/tests/test_irradiance.py::test_poa_components\", \"pvlib/tests/test_irradiance.py::test_disc_value[93193-expected0]\", \"pvlib/tests/test_irradiance.py::test_disc_value[None-expected1]\", \"pvlib/tests/test_irradiance.py::test_disc_value[101325-expected2]\", \"pvlib/tests/test_irradiance.py::test_disc_overirradiance\", \"pvlib/tests/test_irradiance.py::test_disc_min_cos_zenith_max_zenith\", \"pvlib/tests/test_irradiance.py::test_dirint_value\", \"pvlib/tests/test_irradiance.py::test_dirint_nans\", \"pvlib/tests/test_irradiance.py::test_dirint_tdew\", \"pvlib/tests/test_irradiance.py::test_dirint_no_delta_kt\", \"pvlib/tests/test_irradiance.py::test_dirint_coeffs\", \"pvlib/tests/test_irradiance.py::test_dirint_min_cos_zenith_max_zenith\", \"pvlib/tests/test_irradiance.py::test_gti_dirint\", \"pvlib/tests/test_irradiance.py::test_erbs\", \"pvlib/tests/test_irradiance.py::test_erbs_min_cos_zenith_max_zenith\", \"pvlib/tests/test_irradiance.py::test_erbs_all_scalar\", \"pvlib/tests/test_irradiance.py::test_dirindex\", \"pvlib/tests/test_irradiance.py::test_dirindex_min_cos_zenith_max_zenith\", \"pvlib/tests/test_irradiance.py::test_dni\", \"pvlib/tests/test_irradiance.py::test_aoi_and_aoi_projection[0-0-0-0-0-1]\", \"pvlib/tests/test_irradiance.py::test_aoi_and_aoi_projection[30-180-30-180-0-1]\", \"pvlib/tests/test_irradiance.py::test_aoi_and_aoi_projection[30-180-150-0-180--1]\", \"pvlib/tests/test_irradiance.py::test_aoi_and_aoi_projection[90-0-30-60-75.5224878-0.25]\", \"pvlib/tests/test_irradiance.py::test_aoi_and_aoi_projection[90-0-30-170-119.4987042--0.4924038]\", \"pvlib/tests/test_irradiance.py::test_kt_kt_prime_factor\", \"pvlib/tests/test_irradiance.py::test_clearsky_index\", \"pvlib/tests/test_irradiance.py::test_clearness_index\", \"pvlib/tests/test_irradiance.py::test_clearness_index_zenith_independent\"]"], "files_to_edit": ["pvlib/irradiance.py"], "metadata": {"hints_text": "Verified. Looks like an easy fix.\nVerified. Looks like an easy fix.", "created_at": "2021-01-29T20:53:24Z", "version": "0.8", "test_patch": "diff --git a/pvlib/tests/test_irradiance.py b/pvlib/tests/test_irradiance.py\n--- a/pvlib/tests/test_irradiance.py\n+++ b/pvlib/tests/test_irradiance.py\n@@ -203,7 +203,7 @@ def test_reindl(irrad_data, ephem_data, dni_et):\n         40, 180, irrad_data['dhi'], irrad_data['dni'], irrad_data['ghi'],\n         dni_et, ephem_data['apparent_zenith'], ephem_data['azimuth'])\n     # values from matlab 1.4 code\n-    assert_allclose(result, [np.nan, 27.9412, 104.1317, 34.1663], atol=1e-4)\n+    assert_allclose(result, [0., 27.9412, 104.1317, 34.1663], atol=1e-4)\n \n \n def test_king(irrad_data, ephem_data):\n", "environment_setup_commit": "ef8ad2fee9840a77d14b0dfd17fc489dd85c9b91"}}
{"problem_id": "pylint-dev__astroid-1978", "repo_owner": "pylint-dev", "repo_name": "astroid", "repo_url": "https://github.com/pylint-dev/astroid", "base_commit": "0c9ab0fe56703fa83c73e514a1020d398d23fa7f", "problem": "Deprecation warnings from numpy\n### Steps to reproduce\r\n\r\n1. Run pylint over the following test case:\r\n\r\n```\r\n\"\"\"Test case\"\"\"\r\n\r\nimport numpy as np\r\nvalue = np.random.seed(1234)\r\n```\r\n\r\n### Current behavior\r\n```\r\n/home/bje/source/nemo/myenv/lib/python3.10/site-packages/astroid/raw_building.py:470: FutureWarning: In the future `np.long` will be defined as the corresponding NumPy scalar.  (This may have returned Python scalars in past versions.\r\n  getattr(sys.modules[modname], name)\r\n/home/bje/source/nemo/myenv/lib/python3.10/site-packages/astroid/raw_building.py:470: FutureWarning: In the future `np.long` will be defined as the corresponding NumPy scalar.  (This may have returned Python scalars in past versions.\r\n  getattr(sys.modules[modname], name)\r\n```\r\n\r\n### Expected behavior\r\nThere should be no future warnings.\r\n\r\n### python -c \"from astroid import __pkginfo__; print(__pkginfo__.version)\" output\r\n2.12.13\n", "issue_title": "Fix issue in pylint-dev/astroid", "issue_body": "Deprecation warnings from numpy\n### Steps to reproduce\r\n\r\n1. Run pylint over the following test case:\r\n\r\n```\r\n\"\"\"Test case\"\"\"\r\n\r\nimport numpy as np\r\nvalue = np.random.seed(1234)\r\n```\r\n\r\n### Current behavior\r\n```\r\n/home/bje/source/nemo/myenv/lib/python3.10/site-packages/astroid/raw_building.py:470: FutureWarning: In the future `np.long` will be defined as the corresponding NumPy scalar.  (This may have returned Python scalars in past versions.\r\n  getattr(sys.modules[modname], name)\r\n/home/bje/source/nemo/myenv/lib/python3.10/site-packages/astroid/raw_building.py:470: FutureWarning: In the future `np.long` will be defined as the corresponding NumPy scalar.  (This may have returned Python scalars in past versions.\r\n  getattr(sys.modules[modname], name)\r\n```\r\n\r\n### Expected behavior\r\nThere should be no future warnings.\r\n\r\n### python -c \"from astroid import __pkginfo__; print(__pkginfo__.version)\" output\r\n2.12.13\n", "pr_diff": "diff --git a/astroid/raw_building.py b/astroid/raw_building.py\n--- a/astroid/raw_building.py\n+++ b/astroid/raw_building.py\n@@ -10,11 +10,14 @@\n \n import builtins\n import inspect\n+import io\n+import logging\n import os\n import sys\n import types\n import warnings\n from collections.abc import Iterable\n+from contextlib import redirect_stderr, redirect_stdout\n from typing import Any, Union\n \n from astroid import bases, nodes\n@@ -22,6 +25,9 @@\n from astroid.manager import AstroidManager\n from astroid.nodes import node_classes\n \n+logger = logging.getLogger(__name__)\n+\n+\n _FunctionTypes = Union[\n     types.FunctionType,\n     types.MethodType,\n@@ -471,7 +477,26 @@ def imported_member(self, node, member, name: str) -> bool:\n             # check if it sounds valid and then add an import node, else use a\n             # dummy node\n             try:\n-                getattr(sys.modules[modname], name)\n+                with redirect_stderr(io.StringIO()) as stderr, redirect_stdout(\n+                    io.StringIO()\n+                ) as stdout:\n+                    getattr(sys.modules[modname], name)\n+                    stderr_value = stderr.getvalue()\n+                    if stderr_value:\n+                        logger.error(\n+                            \"Captured stderr while getting %s from %s:\\n%s\",\n+                            name,\n+                            sys.modules[modname],\n+                            stderr_value,\n+                        )\n+                    stdout_value = stdout.getvalue()\n+                    if stdout_value:\n+                        logger.info(\n+                            \"Captured stdout while getting %s from %s:\\n%s\",\n+                            name,\n+                            sys.modules[modname],\n+                            stdout_value,\n+                        )\n             except (KeyError, AttributeError):\n                 attach_dummy_node(node, name, member)\n             else:\n", "solution": "diff --git a/astroid/raw_building.py b/astroid/raw_building.py\n--- a/astroid/raw_building.py\n+++ b/astroid/raw_building.py\n@@ -10,11 +10,14 @@\n \n import builtins\n import inspect\n+import io\n+import logging\n import os\n import sys\n import types\n import warnings\n from collections.abc import Iterable\n+from contextlib import redirect_stderr, redirect_stdout\n from typing import Any, Union\n \n from astroid import bases, nodes\n@@ -22,6 +25,9 @@\n from astroid.manager import AstroidManager\n from astroid.nodes import node_classes\n \n+logger = logging.getLogger(__name__)\n+\n+\n _FunctionTypes = Union[\n     types.FunctionType,\n     types.MethodType,\n@@ -471,7 +477,26 @@ def imported_member(self, node, member, name: str) -> bool:\n             # check if it sounds valid and then add an import node, else use a\n             # dummy node\n             try:\n-                getattr(sys.modules[modname], name)\n+                with redirect_stderr(io.StringIO()) as stderr, redirect_stdout(\n+                    io.StringIO()\n+                ) as stdout:\n+                    getattr(sys.modules[modname], name)\n+                    stderr_value = stderr.getvalue()\n+                    if stderr_value:\n+                        logger.error(\n+                            \"Captured stderr while getting %s from %s:\\n%s\",\n+                            name,\n+                            sys.modules[modname],\n+                            stderr_value,\n+                        )\n+                    stdout_value = stdout.getvalue()\n+                    if stdout_value:\n+                        logger.info(\n+                            \"Captured stdout while getting %s from %s:\\n%s\",\n+                            name,\n+                            sys.modules[modname],\n+                            stdout_value,\n+                        )\n             except (KeyError, AttributeError):\n                 attach_dummy_node(node, name, member)\n             else:\n", "test_command": "[\"tests/unittest_raw_building.py::test_build_module_getattr_catch_output\"]", "test_commands": ["[\"tests/unittest_raw_building.py::test_build_module_getattr_catch_output\"]", "[\"tests/unittest_raw_building.py::RawBuildingTC::test_attach_dummy_node\", \"tests/unittest_raw_building.py::RawBuildingTC::test_build_class\", \"tests/unittest_raw_building.py::RawBuildingTC::test_build_from_import\", \"tests/unittest_raw_building.py::RawBuildingTC::test_build_function\", \"tests/unittest_raw_building.py::RawBuildingTC::test_build_function_args\", \"tests/unittest_raw_building.py::RawBuildingTC::test_build_function_deepinspect_deprecation\", \"tests/unittest_raw_building.py::RawBuildingTC::test_build_function_defaults\", \"tests/unittest_raw_building.py::RawBuildingTC::test_build_function_kwonlyargs\", \"tests/unittest_raw_building.py::RawBuildingTC::test_build_function_posonlyargs\", \"tests/unittest_raw_building.py::RawBuildingTC::test_build_module\", \"tests/unittest_raw_building.py::RawBuildingTC::test_io_is__io\", \"tests/unittest_raw_building.py::RawBuildingTC::test_module_object_with_broken_getattr\"]"], "files_to_edit": ["astroid/raw_building.py"], "metadata": {"hints_text": "This seems very similar to https://github.com/PyCQA/astroid/pull/1514 that was fixed in 2.12.0.\nI'm running 2.12.13 (> 2.12.0), so the fix isn't working in this case?\nI don't know why #1514 did not fix this, I think we were capturing both stdout and stderr, so this will need some investigation. My guess would be that there's somewhere else to apply the same method to.\nHello, \r\nI see the same error with pylint on our tool [demcompare](https://github.com/CNES/demcompare). Pylint version:\r\n```\r\npylint --version\r\npylint 2.15.9\r\nastroid 2.12.13\r\nPython 3.8.10 (default, Nov 14 2022, 12:59:47) \r\n[GCC 9.4.0]\r\n```\r\nI confirm the weird astroid lower warning and I don't know how to bypass it with pylint checking. \r\n\r\n```\r\npylint demcompare \r\n/home/duboise/work/src/demcompare/venv/lib/python3.8/site-packages/astroid/raw_building.py:470: FutureWarning: In the future `np.long` will be defined as the corresponding NumPy scalar.  (This may have returned Python scalars in past versions.\r\n  getattr(sys.modules[modname], name)\r\n... (four times)\r\n```\r\n\r\nThanks in advance if there is a solution\r\nCordially\r\n\n> Thanks in advance if there is a solution\r\n\r\nwhile annoying the warning does not make pylint fail. Just ignore it. In a CI you can just check pylint return code. It will return 0 as expected\nI agree, even if annoying because it feels our code as a problem somewhere, the CI with pylint doesn't fail indeed. Thanks for the answer that confirm to not bother for now. \nThat might be fine in a CI environment, but for users, ultimately, ignoring warnings becomes difficult when there are too many such warnings. I would like to see this fixed.\nOh, it was not an argument in favour of not fixing it. It was just to point out that it is not a breaking problem. It is \"just\" a lot of quite annoying warnings. I am following the issue because it annoys me too. So I am in the same \"I hope they will fix it\" boat\n> I don't know why https://github.com/PyCQA/astroid/pull/1514 did not fix this, I think we were capturing both stdout and stderr, so this will need some investigation. My guess would be that there's somewhere else to apply the same method to.\r\n\r\nThat PR only addressed import-time. This `FutureWarning` is emitted by numpy's package-level `__getattr__` method, not during import.", "created_at": "2023-01-28T06:14:39Z", "version": "2.14", "test_patch": "diff --git a/tests/unittest_raw_building.py b/tests/unittest_raw_building.py\n--- a/tests/unittest_raw_building.py\n+++ b/tests/unittest_raw_building.py\n@@ -8,8 +8,15 @@\n # For details: https://github.com/PyCQA/astroid/blob/main/LICENSE\n # Copyright (c) https://github.com/PyCQA/astroid/blob/main/CONTRIBUTORS.txt\n \n+from __future__ import annotations\n+\n+import logging\n+import os\n+import sys\n import types\n import unittest\n+from typing import Any\n+from unittest import mock\n \n import _io\n import pytest\n@@ -117,5 +124,45 @@ def test_module_object_with_broken_getattr(self) -> None:\n         AstroidBuilder().inspect_build(fm_getattr, \"test\")\n \n \n+@pytest.mark.skipif(\n+    \"posix\" not in sys.builtin_module_names, reason=\"Platform doesn't support posix\"\n+)\n+def test_build_module_getattr_catch_output(\n+    capsys: pytest.CaptureFixture[str],\n+    caplog: pytest.LogCaptureFixture,\n+) -> None:\n+    \"\"\"Catch stdout and stderr in module __getattr__ calls when building a module.\n+\n+    Usually raised by DeprecationWarning or FutureWarning.\n+    \"\"\"\n+    caplog.set_level(logging.INFO)\n+    original_sys = sys.modules\n+    original_module = sys.modules[\"posix\"]\n+    expected_out = \"INFO (TEST): Welcome to posix!\"\n+    expected_err = \"WARNING (TEST): Monkey-patched version of posix - module getattr\"\n+\n+    class CustomGetattr:\n+        def __getattr__(self, name: str) -> Any:\n+            print(f\"{expected_out}\")\n+            print(expected_err, file=sys.stderr)\n+            return getattr(original_module, name)\n+\n+    def mocked_sys_modules_getitem(name: str) -> types.ModuleType | CustomGetattr:\n+        if name != \"posix\":\n+            return original_sys[name]\n+        return CustomGetattr()\n+\n+    with mock.patch(\"astroid.raw_building.sys.modules\") as sys_mock:\n+        sys_mock.__getitem__.side_effect = mocked_sys_modules_getitem\n+        builder = AstroidBuilder()\n+        builder.inspect_build(os)\n+\n+    out, err = capsys.readouterr()\n+    assert expected_out in caplog.text\n+    assert expected_err in caplog.text\n+    assert not out\n+    assert not err\n+\n+\n if __name__ == \"__main__\":\n     unittest.main()\n", "environment_setup_commit": "0c9ab0fe56703fa83c73e514a1020d398d23fa7f"}}
{"problem_id": "pylint-dev__astroid-1333", "repo_owner": "pylint-dev", "repo_name": "astroid", "repo_url": "https://github.com/pylint-dev/astroid", "base_commit": "d2a5b3c7b1e203fec3c7ca73c30eb1785d3d4d0a", "problem": "astroid 2.9.1 breaks pylint with missing __init__.py: F0010: error while code parsing: Unable to load file __init__.py\n### Steps to reproduce\r\n> Steps provided are for Windows 11, but initial problem found in Ubuntu 20.04\r\n\r\n> Update 2022-01-04: Corrected repro steps and added more environment details\r\n\r\n1. Set up simple repo with following structure (all files can be empty):\r\n```\r\nroot_dir/\r\n|--src/\r\n|----project/ # Notice the missing __init__.py\r\n|------file.py # It can be empty, but I added `import os` at the top\r\n|----__init__.py\r\n```\r\n2. Open a command prompt\r\n3. `cd root_dir`\r\n4. `python -m venv venv`\r\n5. `venv/Scripts/activate`\r\n6. `pip install pylint astroid==2.9.1` # I also repro'd on the latest, 2.9.2\r\n7. `pylint src/project` # Updated from `pylint src`\r\n8. Observe failure:\r\n```\r\nsrc\\project\\__init__.py:1:0: F0010: error while code parsing: Unable to load file src\\project\\__init__.py:\r\n```\r\n\r\n### Current behavior\r\nFails with `src\\project\\__init__.py:1:0: F0010: error while code parsing: Unable to load file src\\project\\__init__.py:`\r\n\r\n### Expected behavior\r\nDoes not fail with error.\r\n> If you replace step 6 with `pip install pylint astroid==2.9.0`, you get no failure with an empty output - since no files have content\r\n\r\n### `python -c \"from astroid import __pkginfo__; print(__pkginfo__.version)\"` output\r\n2.9.1\r\n\r\n`python 3.9.1`\r\n`pylint 2.12.2 `\r\n\r\n\r\n\r\nThis issue has been observed with astroid `2.9.1` and `2.9.2`\n", "issue_title": "Fix issue in pylint-dev/astroid", "issue_body": "astroid 2.9.1 breaks pylint with missing __init__.py: F0010: error while code parsing: Unable to load file __init__.py\n### Steps to reproduce\r\n> Steps provided are for Windows 11, but initial problem found in Ubuntu 20.04\r\n\r\n> Update 2022-01-04: Corrected repro steps and added more environment details\r\n\r\n1. Set up simple repo with following structure (all files can be empty):\r\n```\r\nroot_dir/\r\n|--src/\r\n|----project/ # Notice the missing __init__.py\r\n|------file.py # It can be empty, but I added `import os` at the top\r\n|----__init__.py\r\n```\r\n2. Open a command prompt\r\n3. `cd root_dir`\r\n4. `python -m venv venv`\r\n5. `venv/Scripts/activate`\r\n6. `pip install pylint astroid==2.9.1` # I also repro'd on the latest, 2.9.2\r\n7. `pylint src/project` # Updated from `pylint src`\r\n8. Observe failure:\r\n```\r\nsrc\\project\\__init__.py:1:0: F0010: error while code parsing: Unable to load file src\\project\\__init__.py:\r\n```\r\n\r\n### Current behavior\r\nFails with `src\\project\\__init__.py:1:0: F0010: error while code parsing: Unable to load file src\\project\\__init__.py:`\r\n\r\n### Expected behavior\r\nDoes not fail with error.\r\n> If you replace step 6 with `pip install pylint astroid==2.9.0`, you get no failure with an empty output - since no files have content\r\n\r\n### `python -c \"from astroid import __pkginfo__; print(__pkginfo__.version)\"` output\r\n2.9.1\r\n\r\n`python 3.9.1`\r\n`pylint 2.12.2 `\r\n\r\n\r\n\r\nThis issue has been observed with astroid `2.9.1` and `2.9.2`\n", "pr_diff": "diff --git a/astroid/modutils.py b/astroid/modutils.py\n--- a/astroid/modutils.py\n+++ b/astroid/modutils.py\n@@ -297,6 +297,9 @@ def _get_relative_base_path(filename, path_to_check):\n     if os.path.normcase(real_filename).startswith(path_to_check):\n         importable_path = real_filename\n \n+    # if \"var\" in path_to_check:\n+    #     breakpoint()\n+\n     if importable_path:\n         base_path = os.path.splitext(importable_path)[0]\n         relative_base_path = base_path[len(path_to_check) :]\n@@ -307,8 +310,11 @@ def _get_relative_base_path(filename, path_to_check):\n \n def modpath_from_file_with_callback(filename, path=None, is_package_cb=None):\n     filename = os.path.expanduser(_path_from_filename(filename))\n+    paths_to_check = sys.path.copy()\n+    if path:\n+        paths_to_check += path\n     for pathname in itertools.chain(\n-        path or [], map(_cache_normalize_path, sys.path), sys.path\n+        paths_to_check, map(_cache_normalize_path, paths_to_check)\n     ):\n         if not pathname:\n             continue\n", "solution": "diff --git a/astroid/modutils.py b/astroid/modutils.py\n--- a/astroid/modutils.py\n+++ b/astroid/modutils.py\n@@ -297,6 +297,9 @@ def _get_relative_base_path(filename, path_to_check):\n     if os.path.normcase(real_filename).startswith(path_to_check):\n         importable_path = real_filename\n \n+    # if \"var\" in path_to_check:\n+    #     breakpoint()\n+\n     if importable_path:\n         base_path = os.path.splitext(importable_path)[0]\n         relative_base_path = base_path[len(path_to_check) :]\n@@ -307,8 +310,11 @@ def _get_relative_base_path(filename, path_to_check):\n \n def modpath_from_file_with_callback(filename, path=None, is_package_cb=None):\n     filename = os.path.expanduser(_path_from_filename(filename))\n+    paths_to_check = sys.path.copy()\n+    if path:\n+        paths_to_check += path\n     for pathname in itertools.chain(\n-        path or [], map(_cache_normalize_path, sys.path), sys.path\n+        paths_to_check, map(_cache_normalize_path, paths_to_check)\n     ):\n         if not pathname:\n             continue\n", "test_command": "[\"tests/unittest_modutils.py::ModPathFromFileTest::test_load_packages_without_init\"]", "test_commands": ["[\"tests/unittest_modutils.py::ModPathFromFileTest::test_load_packages_without_init\"]", "[\"tests/unittest_modutils.py::ModuleFileTest::test_find_egg_module\", \"tests/unittest_modutils.py::ModuleFileTest::test_find_zipped_module\", \"tests/unittest_modutils.py::LoadModuleFromNameTest::test_known_values_load_module_from_name_1\", \"tests/unittest_modutils.py::LoadModuleFromNameTest::test_known_values_load_module_from_name_2\", \"tests/unittest_modutils.py::LoadModuleFromNameTest::test_raise_load_module_from_name_1\", \"tests/unittest_modutils.py::GetModulePartTest::test_get_module_part_exception\", \"tests/unittest_modutils.py::GetModulePartTest::test_known_values_get_builtin_module_part\", \"tests/unittest_modutils.py::GetModulePartTest::test_known_values_get_compiled_module_part\", \"tests/unittest_modutils.py::GetModulePartTest::test_known_values_get_module_part_1\", \"tests/unittest_modutils.py::GetModulePartTest::test_known_values_get_module_part_2\", \"tests/unittest_modutils.py::GetModulePartTest::test_known_values_get_module_part_3\", \"tests/unittest_modutils.py::ModPathFromFileTest::test_import_symlink_both_outside_of_path\", \"tests/unittest_modutils.py::ModPathFromFileTest::test_import_symlink_with_source_outside_of_path\", \"tests/unittest_modutils.py::ModPathFromFileTest::test_known_values_modpath_from_file_1\", \"tests/unittest_modutils.py::ModPathFromFileTest::test_load_from_module_symlink_on_symlinked_paths_in_syspath\", \"tests/unittest_modutils.py::ModPathFromFileTest::test_raise_modpath_from_file_exception\", \"tests/unittest_modutils.py::LoadModuleFromPathTest::test_do_not_load_twice\", \"tests/unittest_modutils.py::FileFromModPathTest::test_builtin\", \"tests/unittest_modutils.py::FileFromModPathTest::test_site_packages\", \"tests/unittest_modutils.py::FileFromModPathTest::test_std_lib\", \"tests/unittest_modutils.py::FileFromModPathTest::test_unexisting\", \"tests/unittest_modutils.py::FileFromModPathTest::test_unicode_in_package_init\", \"tests/unittest_modutils.py::GetSourceFileTest::test\", \"tests/unittest_modutils.py::GetSourceFileTest::test_raise\", \"tests/unittest_modutils.py::StandardLibModuleTest::test_4\", \"tests/unittest_modutils.py::StandardLibModuleTest::test_builtin\", \"tests/unittest_modutils.py::StandardLibModuleTest::test_builtins\", \"tests/unittest_modutils.py::StandardLibModuleTest::test_custom_path\", \"tests/unittest_modutils.py::StandardLibModuleTest::test_datetime\", \"tests/unittest_modutils.py::StandardLibModuleTest::test_failing_edge_cases\", \"tests/unittest_modutils.py::StandardLibModuleTest::test_nonstandard\", \"tests/unittest_modutils.py::StandardLibModuleTest::test_unknown\", \"tests/unittest_modutils.py::IsRelativeTest::test_deep_relative\", \"tests/unittest_modutils.py::IsRelativeTest::test_deep_relative2\", \"tests/unittest_modutils.py::IsRelativeTest::test_deep_relative3\", \"tests/unittest_modutils.py::IsRelativeTest::test_deep_relative4\", \"tests/unittest_modutils.py::IsRelativeTest::test_is_relative_bad_path\", \"tests/unittest_modutils.py::IsRelativeTest::test_known_values_is_relative_1\", \"tests/unittest_modutils.py::IsRelativeTest::test_known_values_is_relative_3\", \"tests/unittest_modutils.py::IsRelativeTest::test_known_values_is_relative_4\", \"tests/unittest_modutils.py::IsRelativeTest::test_known_values_is_relative_5\", \"tests/unittest_modutils.py::GetModuleFilesTest::test_get_all_files\", \"tests/unittest_modutils.py::GetModuleFilesTest::test_get_module_files_1\", \"tests/unittest_modutils.py::GetModuleFilesTest::test_load_module_set_attribute\", \"tests/unittest_modutils.py::ExtensionPackageWhitelistTest::test_is_module_name_part_of_extension_package_whitelist_success\", \"tests/unittest_modutils.py::ExtensionPackageWhitelistTest::test_is_module_name_part_of_extension_package_whitelist_true\"]"], "files_to_edit": ["astroid/modutils.py"], "metadata": {"hints_text": "I can't seem to reproduce this in my `virtualenv`. This might be specific to `venv`? Needs some further investigation.\n@interifter Which version of `pylint` are you using?\nRight, ``pip install pylint astroid==2.9.0``, will keep the local version if you already have one, so I thought it was ``2.12.2`` but that could be false. In fact it probably isn't 2.12.2. For the record, you're not supposed to set the version of ``astroid`` yourself, pylint does, and bad thing will happen if you try to set the version of an incompatible astroid. We might want to update the issue's template to have this information next.\nMy apologies... I updated the repro steps with a critical missed detail: `pylint src/project`, instead of `pylint src`\r\n\r\nBut I verified that either with, or without, `venv`, the issue is reproduced.\r\n\r\nAlso, I never have specified the `astroid` version, before. \r\n\r\nHowever, this isn't the first time the issue has been observed.\r\nBack in early 2019, a [similar issue](https://stackoverflow.com/questions/48024049/pylint-raises-error-if-directory-doesnt-contain-init-py-file) was observed with either `astroid 2.2.0` or `isort 4.3.5`, which led me to try pinning `astroid==2.9.0`, which worked.\n> @interifter Which version of `pylint` are you using?\r\n\r\n`2.12.2`\r\n\r\nFull env info:\r\n\r\n```\r\nPackage           Version\r\n----------------- -------\r\nastroid           2.9.2\r\ncolorama          0.4.4\r\nisort             5.10.1\r\nlazy-object-proxy 1.7.1\r\nmccabe            0.6.1\r\npip               20.2.3\r\nplatformdirs      2.4.1\r\npylint            2.12.2\r\nsetuptools        49.2.1\r\ntoml              0.10.2\r\ntyping-extensions 4.0.1\r\nwrapt             1.13.3\r\n```\r\n\nI confirm the bug and i'm able to reproduce it with `python 3.9.1`. \r\n```\r\n$> pip freeze\r\nastroid==2.9.2\r\nisort==5.10.1\r\nlazy-object-proxy==1.7.1\r\nmccabe==0.6.1\r\nplatformdirs==2.4.1\r\npylint==2.12.2\r\ntoml==0.10.2\r\ntyping-extensions==4.0.1\r\nwrapt==1.13.3\r\n```\nBisected and this is the faulty commit:\r\nhttps://github.com/PyCQA/astroid/commit/2ee20ccdf62450db611acc4a1a7e42f407ce8a14\nFix in #1333, no time to write tests yet so if somebody has any good ideas: please let me know!", "created_at": "2022-01-08T19:36:45Z", "version": "2.10", "test_patch": "diff --git a/tests/unittest_modutils.py b/tests/unittest_modutils.py\n--- a/tests/unittest_modutils.py\n+++ b/tests/unittest_modutils.py\n@@ -30,6 +30,7 @@\n import tempfile\n import unittest\n import xml\n+from pathlib import Path\n from xml import etree\n from xml.etree import ElementTree\n \n@@ -189,6 +190,30 @@ def test_load_from_module_symlink_on_symlinked_paths_in_syspath(self) -> None:\n         # this should be equivalent to: import secret\n         self.assertEqual(modutils.modpath_from_file(symlink_secret_path), [\"secret\"])\n \n+    def test_load_packages_without_init(self) -> None:\n+        \"\"\"Test that we correctly find packages with an __init__.py file.\n+\n+        Regression test for issue reported in:\n+        https://github.com/PyCQA/astroid/issues/1327\n+        \"\"\"\n+        tmp_dir = Path(tempfile.gettempdir())\n+        self.addCleanup(os.chdir, os.curdir)\n+        os.chdir(tmp_dir)\n+\n+        self.addCleanup(shutil.rmtree, tmp_dir / \"src\")\n+        os.mkdir(tmp_dir / \"src\")\n+        os.mkdir(tmp_dir / \"src\" / \"package\")\n+        with open(tmp_dir / \"src\" / \"__init__.py\", \"w\", encoding=\"utf-8\"):\n+            pass\n+        with open(tmp_dir / \"src\" / \"package\" / \"file.py\", \"w\", encoding=\"utf-8\"):\n+            pass\n+\n+        # this should be equivalent to: import secret\n+        self.assertEqual(\n+            modutils.modpath_from_file(str(Path(\"src\") / \"package\"), [\".\"]),\n+            [\"src\", \"package\"],\n+        )\n+\n \n class LoadModuleFromPathTest(resources.SysPathSetup, unittest.TestCase):\n     def test_do_not_load_twice(self) -> None:\n", "environment_setup_commit": "da745538c7236028a22cdf0405f6829fcf6886bc"}}
{"problem_id": "pylint-dev__astroid-1196", "repo_owner": "pylint-dev", "repo_name": "astroid", "repo_url": "https://github.com/pylint-dev/astroid", "base_commit": "39c2a9805970ca57093d32bbaf0e6a63e05041d8", "problem": "getitem does not infer the actual unpacked value\nWhen trying to call `Dict.getitem()` on a context where we have a dict unpacking of anything beside a real dict, astroid currently raises an `AttributeError: 'getitem'`, which has 2 problems:\r\n\r\n- The object might be a reference against something constant, this pattern is usually seen when we have different sets of dicts that extend each other, and all of their values are inferrable. \r\n- We can have something that is uninferable, but in that case instead of an `AttributeError` I think it makes sense to raise the usual `AstroidIndexError` which is supposed to be already handled by the downstream.\r\n\r\n\r\nHere is a short reproducer;\r\n\r\n```py\r\nfrom astroid import parse\r\n\r\n\r\nsource = \"\"\"\r\nX = {\r\n    'A': 'B'\r\n}\r\n\r\nY = {\r\n    **X\r\n}\r\n\r\nKEY = 'A'\r\n\"\"\"\r\n\r\ntree = parse(source)\r\n\r\nfirst_dict = tree.body[0].value\r\nsecond_dict = tree.body[1].value\r\nkey = tree.body[2].value\r\n\r\nprint(f'{first_dict.getitem(key).value = }')\r\nprint(f'{second_dict.getitem(key).value = }')\r\n\r\n\r\n```\r\n\r\nThe current output;\r\n\r\n```\r\n $ python t1.py                                                                                                 3ms\r\nfirst_dict.getitem(key).value = 'B'\r\nTraceback (most recent call last):\r\n  File \"/home/isidentical/projects/astroid/t1.py\", line 23, in <module>\r\n    print(f'{second_dict.getitem(key).value = }')\r\n  File \"/home/isidentical/projects/astroid/astroid/nodes/node_classes.py\", line 2254, in getitem\r\n    return value.getitem(index, context)\r\nAttributeError: 'Name' object has no attribute 'getitem'\r\n```\r\n\r\nExpeceted output;\r\n```\r\n $ python t1.py                                                                                                 4ms\r\nfirst_dict.getitem(key).value = 'B'\r\nsecond_dict.getitem(key).value = 'B'\r\n\r\n```\r\n\n", "issue_title": "Fix issue in pylint-dev/astroid", "issue_body": "getitem does not infer the actual unpacked value\nWhen trying to call `Dict.getitem()` on a context where we have a dict unpacking of anything beside a real dict, astroid currently raises an `AttributeError: 'getitem'`, which has 2 problems:\r\n\r\n- The object might be a reference against something constant, this pattern is usually seen when we have different sets of dicts that extend each other, and all of their values are inferrable. \r\n- We can have something that is uninferable, but in that case instead of an `AttributeError` I think it makes sense to raise the usual `AstroidIndexError` which is supposed to be already handled by the downstream.\r\n\r\n\r\nHere is a short reproducer;\r\n\r\n```py\r\nfrom astroid import parse\r\n\r\n\r\nsource = \"\"\"\r\nX = {\r\n    'A': 'B'\r\n}\r\n\r\nY = {\r\n    **X\r\n}\r\n\r\nKEY = 'A'\r\n\"\"\"\r\n\r\ntree = parse(source)\r\n\r\nfirst_dict = tree.body[0].value\r\nsecond_dict = tree.body[1].value\r\nkey = tree.body[2].value\r\n\r\nprint(f'{first_dict.getitem(key).value = }')\r\nprint(f'{second_dict.getitem(key).value = }')\r\n\r\n\r\n```\r\n\r\nThe current output;\r\n\r\n```\r\n $ python t1.py                                                                                                 3ms\r\nfirst_dict.getitem(key).value = 'B'\r\nTraceback (most recent call last):\r\n  File \"/home/isidentical/projects/astroid/t1.py\", line 23, in <module>\r\n    print(f'{second_dict.getitem(key).value = }')\r\n  File \"/home/isidentical/projects/astroid/astroid/nodes/node_classes.py\", line 2254, in getitem\r\n    return value.getitem(index, context)\r\nAttributeError: 'Name' object has no attribute 'getitem'\r\n```\r\n\r\nExpeceted output;\r\n```\r\n $ python t1.py                                                                                                 4ms\r\nfirst_dict.getitem(key).value = 'B'\r\nsecond_dict.getitem(key).value = 'B'\r\n\r\n```\r\n\n", "pr_diff": "diff --git a/astroid/nodes/node_classes.py b/astroid/nodes/node_classes.py\n--- a/astroid/nodes/node_classes.py\n+++ b/astroid/nodes/node_classes.py\n@@ -2346,24 +2346,33 @@ def itered(self):\n         \"\"\"\n         return [key for (key, _) in self.items]\n \n-    def getitem(self, index, context=None):\n+    def getitem(\n+        self, index: Const | Slice, context: InferenceContext | None = None\n+    ) -> NodeNG:\n         \"\"\"Get an item from this node.\n \n         :param index: The node to use as a subscript index.\n-        :type index: Const or Slice\n \n         :raises AstroidTypeError: When the given index cannot be used as a\n             subscript index, or if this node is not subscriptable.\n         :raises AstroidIndexError: If the given index does not exist in the\n             dictionary.\n         \"\"\"\n+        # pylint: disable-next=import-outside-toplevel; circular import\n+        from astroid.helpers import safe_infer\n+\n         for key, value in self.items:\n             # TODO(cpopa): no support for overriding yet, {1:2, **{1: 3}}.\n             if isinstance(key, DictUnpack):\n+                inferred_value = safe_infer(value, context)\n+                if not isinstance(inferred_value, Dict):\n+                    continue\n+\n                 try:\n-                    return value.getitem(index, context)\n+                    return inferred_value.getitem(index, context)\n                 except (AstroidTypeError, AstroidIndexError):\n                     continue\n+\n             for inferredkey in key.infer(context):\n                 if inferredkey is util.Uninferable:\n                     continue\n", "solution": "diff --git a/astroid/nodes/node_classes.py b/astroid/nodes/node_classes.py\n--- a/astroid/nodes/node_classes.py\n+++ b/astroid/nodes/node_classes.py\n@@ -2346,24 +2346,33 @@ def itered(self):\n         \"\"\"\n         return [key for (key, _) in self.items]\n \n-    def getitem(self, index, context=None):\n+    def getitem(\n+        self, index: Const | Slice, context: InferenceContext | None = None\n+    ) -> NodeNG:\n         \"\"\"Get an item from this node.\n \n         :param index: The node to use as a subscript index.\n-        :type index: Const or Slice\n \n         :raises AstroidTypeError: When the given index cannot be used as a\n             subscript index, or if this node is not subscriptable.\n         :raises AstroidIndexError: If the given index does not exist in the\n             dictionary.\n         \"\"\"\n+        # pylint: disable-next=import-outside-toplevel; circular import\n+        from astroid.helpers import safe_infer\n+\n         for key, value in self.items:\n             # TODO(cpopa): no support for overriding yet, {1:2, **{1: 3}}.\n             if isinstance(key, DictUnpack):\n+                inferred_value = safe_infer(value, context)\n+                if not isinstance(inferred_value, Dict):\n+                    continue\n+\n                 try:\n-                    return value.getitem(index, context)\n+                    return inferred_value.getitem(index, context)\n                 except (AstroidTypeError, AstroidIndexError):\n                     continue\n+\n             for inferredkey in key.infer(context):\n                 if inferredkey is util.Uninferable:\n                     continue\n", "test_command": "[\"tests/unittest_python3.py::Python3TC::test_unpacking_in_dict_getitem_uninferable\", \"tests/unittest_python3.py::Python3TC::test_unpacking_in_dict_getitem_with_ref\"]", "test_commands": ["[\"tests/unittest_python3.py::Python3TC::test_unpacking_in_dict_getitem_uninferable\", \"tests/unittest_python3.py::Python3TC::test_unpacking_in_dict_getitem_with_ref\"]", "[\"tests/unittest_python3.py::Python3TC::test_annotation_as_string\", \"tests/unittest_python3.py::Python3TC::test_annotation_support\", \"tests/unittest_python3.py::Python3TC::test_as_string\", \"tests/unittest_python3.py::Python3TC::test_async_comprehensions\", \"tests/unittest_python3.py::Python3TC::test_async_comprehensions_as_string\", \"tests/unittest_python3.py::Python3TC::test_async_comprehensions_outside_coroutine\", \"tests/unittest_python3.py::Python3TC::test_format_string\", \"tests/unittest_python3.py::Python3TC::test_kwonlyargs_annotations_supper\", \"tests/unittest_python3.py::Python3TC::test_metaclass_ancestors\", \"tests/unittest_python3.py::Python3TC::test_metaclass_error\", \"tests/unittest_python3.py::Python3TC::test_metaclass_imported\", \"tests/unittest_python3.py::Python3TC::test_metaclass_multiple_keywords\", \"tests/unittest_python3.py::Python3TC::test_metaclass_yes_leak\", \"tests/unittest_python3.py::Python3TC::test_nested_unpacking_in_dicts\", \"tests/unittest_python3.py::Python3TC::test_old_syntax_works\", \"tests/unittest_python3.py::Python3TC::test_parent_metaclass\", \"tests/unittest_python3.py::Python3TC::test_simple_metaclass\", \"tests/unittest_python3.py::Python3TC::test_starred_notation\", \"tests/unittest_python3.py::Python3TC::test_underscores_in_numeral_literal\", \"tests/unittest_python3.py::Python3TC::test_unpacking_in_dict_getitem\", \"tests/unittest_python3.py::Python3TC::test_unpacking_in_dicts\", \"tests/unittest_python3.py::Python3TC::test_yield_from\", \"tests/unittest_python3.py::Python3TC::test_yield_from_as_string\", \"tests/unittest_python3.py::Python3TC::test_yield_from_is_generator\"]"], "files_to_edit": ["astroid/nodes/node_classes.py"], "metadata": {"hints_text": "", "created_at": "2021-10-03T15:58:07Z", "version": "2.12", "test_patch": "diff --git a/tests/unittest_python3.py b/tests/unittest_python3.py\n--- a/tests/unittest_python3.py\n+++ b/tests/unittest_python3.py\n@@ -5,7 +5,9 @@\n import unittest\n from textwrap import dedent\n \n-from astroid import nodes\n+import pytest\n+\n+from astroid import exceptions, nodes\n from astroid.builder import AstroidBuilder, extract_node\n from astroid.test_utils import require_version\n \n@@ -285,6 +287,33 @@ def test_unpacking_in_dict_getitem(self) -> None:\n             self.assertIsInstance(value, nodes.Const)\n             self.assertEqual(value.value, expected)\n \n+    @staticmethod\n+    def test_unpacking_in_dict_getitem_with_ref() -> None:\n+        node = extract_node(\n+            \"\"\"\n+        a = {1: 2}\n+        {**a, 2: 3}  #@\n+        \"\"\"\n+        )\n+        assert isinstance(node, nodes.Dict)\n+\n+        for key, expected in ((1, 2), (2, 3)):\n+            value = node.getitem(nodes.Const(key))\n+            assert isinstance(value, nodes.Const)\n+            assert value.value == expected\n+\n+    @staticmethod\n+    def test_unpacking_in_dict_getitem_uninferable() -> None:\n+        node = extract_node(\"{**a, 2: 3}\")\n+        assert isinstance(node, nodes.Dict)\n+\n+        with pytest.raises(exceptions.AstroidIndexError):\n+            node.getitem(nodes.Const(1))\n+\n+        value = node.getitem(nodes.Const(2))\n+        assert isinstance(value, nodes.Const)\n+        assert value.value == 3\n+\n     def test_format_string(self) -> None:\n         code = \"f'{greetings} {person}'\"\n         node = extract_node(code)\n", "environment_setup_commit": "52f6d2d7722db383af035be929f18af5e9fe8cd5"}}
{"problem_id": "pylint-dev__astroid-1866", "repo_owner": "pylint-dev", "repo_name": "astroid", "repo_url": "https://github.com/pylint-dev/astroid", "base_commit": "6cf238d089cf4b6753c94cfc089b4a47487711e5", "problem": "\"TypeError: unsupported format string passed to NoneType.__format__\" while running type inference in version 2.12.x\n### Steps to reproduce\r\n\r\nI have no concise reproducer. Exception happens every time I run pylint on some internal code, with astroid 2.12.10 and 2.12.12 (debian bookworm). It does _not_ happen with earlier versions of astroid (not with version 2.9). The pylinted code itself is \"valid\", it runs in production here.\r\n\r\n### Current behavior\r\n\r\nWhen running pylint on some code, I get this exception:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3/dist-packages/pylint/utils/ast_walker.py\", line 90, in walk\r\n    callback(astroid)\r\n  File \"/usr/lib/python3/dist-packages/pylint/checkers/classes/special_methods_checker.py\", line 183, in visit_functiondef\r\n    inferred = _safe_infer_call_result(node, node)\r\n  File \"/usr/lib/python3/dist-packages/pylint/checkers/classes/special_methods_checker.py\", line 42, in _safe_infer_call_result\r\n    value = next(inferit)\r\n  File \"/usr/lib/python3/dist-packages/astroid/nodes/scoped_nodes/scoped_nodes.py\", line 1749, in infer_call_result\r\n    yield from returnnode.value.infer(context)\r\n  File \"/usr/lib/python3/dist-packages/astroid/nodes/node_ng.py\", line 159, in infer\r\n    results = list(self._explicit_inference(self, context, **kwargs))\r\n  File \"/usr/lib/python3/dist-packages/astroid/inference_tip.py\", line 45, in _inference_tip_cached\r\n    result = _cache[func, node] = list(func(*args, **kwargs))\r\n  File \"/usr/lib/python3/dist-packages/astroid/brain/brain_builtin_inference.py\", line 956, in _infer_str_format_call\r\n    formatted_string = format_template.format(*pos_values, **keyword_values)\r\nTypeError: unsupported format string passed to NoneType.__format__\r\n```\r\n\r\n### Expected behavior\r\n\r\nTypeError exception should not happen\r\n\r\n### `python -c \"from astroid import __pkginfo__; print(__pkginfo__.version)\"` output\r\n\r\n2.12.10,\r\n2.12.12\n", "issue_title": "Fix issue in pylint-dev/astroid", "issue_body": "\"TypeError: unsupported format string passed to NoneType.__format__\" while running type inference in version 2.12.x\n### Steps to reproduce\r\n\r\nI have no concise reproducer. Exception happens every time I run pylint on some internal code, with astroid 2.12.10 and 2.12.12 (debian bookworm). It does _not_ happen with earlier versions of astroid (not with version 2.9). The pylinted code itself is \"valid\", it runs in production here.\r\n\r\n### Current behavior\r\n\r\nWhen running pylint on some code, I get this exception:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3/dist-packages/pylint/utils/ast_walker.py\", line 90, in walk\r\n    callback(astroid)\r\n  File \"/usr/lib/python3/dist-packages/pylint/checkers/classes/special_methods_checker.py\", line 183, in visit_functiondef\r\n    inferred = _safe_infer_call_result(node, node)\r\n  File \"/usr/lib/python3/dist-packages/pylint/checkers/classes/special_methods_checker.py\", line 42, in _safe_infer_call_result\r\n    value = next(inferit)\r\n  File \"/usr/lib/python3/dist-packages/astroid/nodes/scoped_nodes/scoped_nodes.py\", line 1749, in infer_call_result\r\n    yield from returnnode.value.infer(context)\r\n  File \"/usr/lib/python3/dist-packages/astroid/nodes/node_ng.py\", line 159, in infer\r\n    results = list(self._explicit_inference(self, context, **kwargs))\r\n  File \"/usr/lib/python3/dist-packages/astroid/inference_tip.py\", line 45, in _inference_tip_cached\r\n    result = _cache[func, node] = list(func(*args, **kwargs))\r\n  File \"/usr/lib/python3/dist-packages/astroid/brain/brain_builtin_inference.py\", line 956, in _infer_str_format_call\r\n    formatted_string = format_template.format(*pos_values, **keyword_values)\r\nTypeError: unsupported format string passed to NoneType.__format__\r\n```\r\n\r\n### Expected behavior\r\n\r\nTypeError exception should not happen\r\n\r\n### `python -c \"from astroid import __pkginfo__; print(__pkginfo__.version)\"` output\r\n\r\n2.12.10,\r\n2.12.12\n", "pr_diff": "diff --git a/astroid/brain/brain_builtin_inference.py b/astroid/brain/brain_builtin_inference.py\n--- a/astroid/brain/brain_builtin_inference.py\n+++ b/astroid/brain/brain_builtin_inference.py\n@@ -954,8 +954,10 @@ def _infer_str_format_call(\n \n     try:\n         formatted_string = format_template.format(*pos_values, **keyword_values)\n-    except (IndexError, KeyError):\n-        # If there is an IndexError there are too few arguments to interpolate\n+    except (IndexError, KeyError, TypeError, ValueError):\n+        # IndexError: there are too few arguments to interpolate\n+        # TypeError: Unsupported format string\n+        # ValueError: Unknown format code\n         return iter([util.Uninferable])\n \n     return iter([nodes.const_factory(formatted_string)])\n", "solution": "diff --git a/astroid/brain/brain_builtin_inference.py b/astroid/brain/brain_builtin_inference.py\n--- a/astroid/brain/brain_builtin_inference.py\n+++ b/astroid/brain/brain_builtin_inference.py\n@@ -954,8 +954,10 @@ def _infer_str_format_call(\n \n     try:\n         formatted_string = format_template.format(*pos_values, **keyword_values)\n-    except (IndexError, KeyError):\n-        # If there is an IndexError there are too few arguments to interpolate\n+    except (IndexError, KeyError, TypeError, ValueError):\n+        # IndexError: there are too few arguments to interpolate\n+        # TypeError: Unsupported format string\n+        # ValueError: Unknown format code\n         return iter([util.Uninferable])\n \n     return iter([nodes.const_factory(formatted_string)])\n", "test_command": "[\"tests/unittest_brain_builtin.py::TestStringNodes::test_string_format_uninferable[\\\\n\"]", "test_commands": ["[\"tests/unittest_brain_builtin.py::TestStringNodes::test_string_format_uninferable[\\\\n\"]", "[\"tests/unittest_brain_builtin.py::BuiltinsTest::test_infer_property\", \"tests/unittest_brain_builtin.py::TestStringNodes::test_string_format[empty-indexes]\", \"tests/unittest_brain_builtin.py::TestStringNodes::test_string_format[numbered-indexes]\", \"tests/unittest_brain_builtin.py::TestStringNodes::test_string_format[named-indexes]\", \"tests/unittest_brain_builtin.py::TestStringNodes::test_string_format[numbered-indexes-from-positional]\", \"tests/unittest_brain_builtin.py::TestStringNodes::test_string_format[named-indexes-from-keyword]\", \"tests/unittest_brain_builtin.py::TestStringNodes::test_string_format[mixed-indexes-from-mixed]\", \"tests/unittest_brain_builtin.py::TestStringNodes::test_string_format[empty-indexes-on-variable]\", \"tests/unittest_brain_builtin.py::TestStringNodes::test_string_format_uninferable[\\\"I\", \"tests/unittest_brain_builtin.py::TestStringNodes::test_string_format_with_specs\"]"], "files_to_edit": ["astroid/brain/brain_builtin_inference.py"], "metadata": {"hints_text": "Hi @crosser, thanks for the report.\r\n\r\n> I have no concise reproducer. \r\n\r\nWe might be able to help you distill one.\r\n\r\n`pylint` produces a crash report, and shows the link in your terminal, like this:\r\n```shell\r\n************* Module a\r\na.py:1:0: F0002: a.py: Fatal error while checking 'a.py'. Please open an issue in our bug tracker so we address this. There is a pre-filled template that you can use in '/Users/.../Library/Caches/pylint/pylint-crash-2022-10-29-08-48-25.txt'. (astroid-error)\r\n```\r\nThe offending file is at the top of the crash report. If the code is too long, or contains sensitive information, you can use the knowledge that the crash happened in `_infer_str_format_call` to look for calls to `.format()` on strings. You should be able to then just provide us those calls--and enough surrounding code to rebuild the objects you provided to `format()`. \r\n\r\nDoing this would be a tremendous help!\n> `pylint` produces a crash report, and shows the link in your terminal, like this:\r\n\r\nNo, not really, it does not. I am attaching a (censored) stderr from running the test. The line in the source code that apparently triggers the problem is pretty innocuous:\r\n\r\n```\r\n    @property\r\n    def vnet_id(self):  # <---- this is the line 266 that is mentioned in the \"Exception on node\" message\r\n        if ...:\r\n```\r\nThere is very similar property definition right before this one, that does not trigger the problem.\r\n\r\n[pyerr.txt](https://github.com/PyCQA/astroid/files/9900190/pyerr.txt)\r\n\r\nPylint command was `python3 -m pylint --jobs=0 --rcfile=test/style/pylint.conf <project-dir>`\r\n\r\n```\r\n$ pylint --version\r\npylint 2.15.5\r\nastroid 2.12.12\r\nPython 3.10.8 (main, Oct 24 2022, 10:07:16) [GCC 12.2.0]\r\n```\r\n\r\nedit:\r\n> enough surrounding code to rebuild the objects you provided to format().\r\n\r\n_I_ did not provide any objects to `format()`, astroid did...\nThanks for providing the traceback.\r\n\r\n> No, not really, it does not. I am attaching a (censored) stderr from running the test. \r\n\r\nI see now that it's because you're invoking pylint from a unittest, so your test is managing the output.\r\n\r\n> The line in the source code that apparently triggers the problem is pretty innocuous:\r\n\r\nThe deeper failure is on the call in line 268, not the function def on line 266. Is there anything you can sanitize and tell us about line 268? Thanks again for providing the help.\n> I see now that it's because you're invoking pylint from a unittest, so your test is managing the output.\r\n\r\nWhen I run pylint by hand\r\n\r\n```\r\npylint --jobs=0 --rcfile=test/style/pylint.conf <module-name> | tee /tmp/pyerr.txt\r\n```\r\nthere is still no \"Fatal error while checking ...\" message in the output\r\n\r\n> > The line in the source code that apparently triggers the problem is pretty innocuous:\r\n> \r\n> The deeper failure is on the call in line 268, not the function def on line 266. Is there anything you can sanitize and tell us about line 268? Thanks again for providing the help.\r\n\r\nOh yes, there is a `something.format()` in that line! But the \"something\" is a literal string:\r\n```\r\n    @property\r\n    def vnet_id(self):\r\n        if self.backend == \"something\":\r\n            return \"{:04x}{:04x}n{:d}\".format(  # <---- this is line 268\r\n                self.<some-attr>, self.<another-attr>, self.<third-attr>\r\n            )\r\n        if self.backend == \"somethingelse\":\r\n            return \"h{:08}n{:d}\".format(self.<more-attr>, self.<and more>)\r\n        return None\r\n```\r\n\nThanks, that was very helpful. Here is a reproducer:\r\n```python\r\nx = \"{:c}\".format(None)\r\n```", "created_at": "2022-11-12T19:21:34Z", "version": "2.13", "test_patch": "diff --git a/tests/unittest_brain_builtin.py b/tests/unittest_brain_builtin.py\n--- a/tests/unittest_brain_builtin.py\n+++ b/tests/unittest_brain_builtin.py\n@@ -103,6 +103,12 @@ def test_string_format(self, format_string: str) -> None:\n             \"\"\"\n             \"My name is {fname}, I'm {age}\".format(fsname = \"Daniel\", age = 12)\n             \"\"\",\n+            \"\"\"\n+            \"My unicode character is {:c}\".format(None)\n+            \"\"\",\n+            \"\"\"\n+            \"My hex format is {:4x}\".format('1')\n+            \"\"\",\n         ],\n     )\n     def test_string_format_uninferable(self, format_string: str) -> None:\n", "environment_setup_commit": "fe058bff95745371df5796286d33677c21137847"}}
{"problem_id": "pylint-dev__astroid-1268", "repo_owner": "pylint-dev", "repo_name": "astroid", "repo_url": "https://github.com/pylint-dev/astroid", "base_commit": "ce5cbce5ba11cdc2f8139ade66feea1e181a7944", "problem": "'AsStringVisitor' object has no attribute 'visit_unknown'\n```python\r\n>>> import astroid\r\n>>> astroid.nodes.Unknown().as_string()\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/tusharsadhwani/code/marvin-python/venv/lib/python3.9/site-packages/astroid/nodes/node_ng.py\", line 609, in as_string\r\n    return AsStringVisitor()(self)\r\n  File \"/Users/tusharsadhwani/code/marvin-python/venv/lib/python3.9/site-packages/astroid/nodes/as_string.py\", line 56, in __call__\r\n    return node.accept(self).replace(DOC_NEWLINE, \"\\n\")\r\n  File \"/Users/tusharsadhwani/code/marvin-python/venv/lib/python3.9/site-packages/astroid/nodes/node_ng.py\", line 220, in accept\r\n    func = getattr(visitor, \"visit_\" + self.__class__.__name__.lower())\r\nAttributeError: 'AsStringVisitor' object has no attribute 'visit_unknown'\r\n>>> \r\n```\r\n### `python -c \"from astroid import __pkginfo__; print(__pkginfo__.version)\"` output\r\n\r\n2.8.6-dev0\n", "issue_title": "Fix issue in pylint-dev/astroid", "issue_body": "'AsStringVisitor' object has no attribute 'visit_unknown'\n```python\r\n>>> import astroid\r\n>>> astroid.nodes.Unknown().as_string()\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/tusharsadhwani/code/marvin-python/venv/lib/python3.9/site-packages/astroid/nodes/node_ng.py\", line 609, in as_string\r\n    return AsStringVisitor()(self)\r\n  File \"/Users/tusharsadhwani/code/marvin-python/venv/lib/python3.9/site-packages/astroid/nodes/as_string.py\", line 56, in __call__\r\n    return node.accept(self).replace(DOC_NEWLINE, \"\\n\")\r\n  File \"/Users/tusharsadhwani/code/marvin-python/venv/lib/python3.9/site-packages/astroid/nodes/node_ng.py\", line 220, in accept\r\n    func = getattr(visitor, \"visit_\" + self.__class__.__name__.lower())\r\nAttributeError: 'AsStringVisitor' object has no attribute 'visit_unknown'\r\n>>> \r\n```\r\n### `python -c \"from astroid import __pkginfo__; print(__pkginfo__.version)\"` output\r\n\r\n2.8.6-dev0\n", "pr_diff": "diff --git a/astroid/nodes/as_string.py b/astroid/nodes/as_string.py\n--- a/astroid/nodes/as_string.py\n+++ b/astroid/nodes/as_string.py\n@@ -36,6 +36,7 @@\n         MatchSingleton,\n         MatchStar,\n         MatchValue,\n+        Unknown,\n     )\n \n # pylint: disable=unused-argument\n@@ -643,6 +644,9 @@ def visit_property(self, node):\n     def visit_evaluatedobject(self, node):\n         return node.original.accept(self)\n \n+    def visit_unknown(self, node: \"Unknown\") -> str:\n+        return str(node)\n+\n \n def _import_string(names):\n     \"\"\"return a list of (name, asname) formatted as a string\"\"\"\n", "solution": "diff --git a/astroid/nodes/as_string.py b/astroid/nodes/as_string.py\n--- a/astroid/nodes/as_string.py\n+++ b/astroid/nodes/as_string.py\n@@ -36,6 +36,7 @@\n         MatchSingleton,\n         MatchStar,\n         MatchValue,\n+        Unknown,\n     )\n \n # pylint: disable=unused-argument\n@@ -643,6 +644,9 @@ def visit_property(self, node):\n     def visit_evaluatedobject(self, node):\n         return node.original.accept(self)\n \n+    def visit_unknown(self, node: \"Unknown\") -> str:\n+        return str(node)\n+\n \n def _import_string(names):\n     \"\"\"return a list of (name, asname) formatted as a string\"\"\"\n", "test_command": "[\"tests/unittest_nodes.py::AsStringTest::test_as_string_unknown\"]", "test_commands": ["[\"tests/unittest_nodes.py::AsStringTest::test_as_string_unknown\"]", "[\"tests/unittest_nodes.py::AsStringTest::test_3k_annotations_and_metaclass\", \"tests/unittest_nodes.py::AsStringTest::test_3k_as_string\", \"tests/unittest_nodes.py::AsStringTest::test_as_string\", \"tests/unittest_nodes.py::AsStringTest::test_as_string_for_list_containing_uninferable\", \"tests/unittest_nodes.py::AsStringTest::test_class_def\", \"tests/unittest_nodes.py::AsStringTest::test_ellipsis\", \"tests/unittest_nodes.py::AsStringTest::test_f_strings\", \"tests/unittest_nodes.py::AsStringTest::test_frozenset_as_string\", \"tests/unittest_nodes.py::AsStringTest::test_func_signature_issue_185\", \"tests/unittest_nodes.py::AsStringTest::test_int_attribute\", \"tests/unittest_nodes.py::AsStringTest::test_module2_as_string\", \"tests/unittest_nodes.py::AsStringTest::test_module_as_string\", \"tests/unittest_nodes.py::AsStringTest::test_operator_precedence\", \"tests/unittest_nodes.py::AsStringTest::test_slice_and_subscripts\", \"tests/unittest_nodes.py::AsStringTest::test_slices\", \"tests/unittest_nodes.py::AsStringTest::test_tuple_as_string\", \"tests/unittest_nodes.py::AsStringTest::test_varargs_kwargs_as_string\", \"tests/unittest_nodes.py::IfNodeTest::test_block_range\", \"tests/unittest_nodes.py::IfNodeTest::test_if_elif_else_node\", \"tests/unittest_nodes.py::IfNodeTest::test_if_sys_guard\", \"tests/unittest_nodes.py::IfNodeTest::test_if_typing_guard\", \"tests/unittest_nodes.py::TryExceptNodeTest::test_block_range\", \"tests/unittest_nodes.py::TryFinallyNodeTest::test_block_range\", \"tests/unittest_nodes.py::TryExceptFinallyNodeTest::test_block_range\", \"tests/unittest_nodes.py::ImportNodeTest::test_absolute_import\", \"tests/unittest_nodes.py::ImportNodeTest::test_as_string\", \"tests/unittest_nodes.py::ImportNodeTest::test_bad_import_inference\", \"tests/unittest_nodes.py::ImportNodeTest::test_conditional\", \"tests/unittest_nodes.py::ImportNodeTest::test_conditional_import\", \"tests/unittest_nodes.py::ImportNodeTest::test_from_self_resolve\", \"tests/unittest_nodes.py::ImportNodeTest::test_import_self_resolve\", \"tests/unittest_nodes.py::ImportNodeTest::test_more_absolute_import\", \"tests/unittest_nodes.py::ImportNodeTest::test_real_name\", \"tests/unittest_nodes.py::CmpNodeTest::test_as_string\", \"tests/unittest_nodes.py::ConstNodeTest::test_bool\", \"tests/unittest_nodes.py::ConstNodeTest::test_complex\", \"tests/unittest_nodes.py::ConstNodeTest::test_copy\", \"tests/unittest_nodes.py::ConstNodeTest::test_float\", \"tests/unittest_nodes.py::ConstNodeTest::test_int\", \"tests/unittest_nodes.py::ConstNodeTest::test_none\", \"tests/unittest_nodes.py::ConstNodeTest::test_str\", \"tests/unittest_nodes.py::ConstNodeTest::test_str_kind\", \"tests/unittest_nodes.py::ConstNodeTest::test_unicode\", \"tests/unittest_nodes.py::NameNodeTest::test_assign_to_true\", \"tests/unittest_nodes.py::TestNamedExprNode::test_frame\", \"tests/unittest_nodes.py::TestNamedExprNode::test_scope\", \"tests/unittest_nodes.py::AnnAssignNodeTest::test_as_string\", \"tests/unittest_nodes.py::AnnAssignNodeTest::test_complex\", \"tests/unittest_nodes.py::AnnAssignNodeTest::test_primitive\", \"tests/unittest_nodes.py::AnnAssignNodeTest::test_primitive_without_initial_value\", \"tests/unittest_nodes.py::ArgumentsNodeTC::test_kwoargs\", \"tests/unittest_nodes.py::ArgumentsNodeTC::test_positional_only\", \"tests/unittest_nodes.py::UnboundMethodNodeTest::test_no_super_getattr\", \"tests/unittest_nodes.py::BoundMethodNodeTest::test_is_property\", \"tests/unittest_nodes.py::AliasesTest::test_aliases\", \"tests/unittest_nodes.py::Python35AsyncTest::test_async_await_keywords\", \"tests/unittest_nodes.py::Python35AsyncTest::test_asyncfor_as_string\", \"tests/unittest_nodes.py::Python35AsyncTest::test_asyncwith_as_string\", \"tests/unittest_nodes.py::Python35AsyncTest::test_await_as_string\", \"tests/unittest_nodes.py::Python35AsyncTest::test_decorated_async_def_as_string\", \"tests/unittest_nodes.py::ContextTest::test_list_del\", \"tests/unittest_nodes.py::ContextTest::test_list_load\", \"tests/unittest_nodes.py::ContextTest::test_list_store\", \"tests/unittest_nodes.py::ContextTest::test_starred_load\", \"tests/unittest_nodes.py::ContextTest::test_starred_store\", \"tests/unittest_nodes.py::ContextTest::test_subscript_del\", \"tests/unittest_nodes.py::ContextTest::test_subscript_load\", \"tests/unittest_nodes.py::ContextTest::test_subscript_store\", \"tests/unittest_nodes.py::ContextTest::test_tuple_load\", \"tests/unittest_nodes.py::ContextTest::test_tuple_store\", \"tests/unittest_nodes.py::test_unknown\", \"tests/unittest_nodes.py::test_type_comments_with\", \"tests/unittest_nodes.py::test_type_comments_for\", \"tests/unittest_nodes.py::test_type_coments_assign\", \"tests/unittest_nodes.py::test_type_comments_invalid_expression\", \"tests/unittest_nodes.py::test_type_comments_invalid_function_comments\", \"tests/unittest_nodes.py::test_type_comments_function\", \"tests/unittest_nodes.py::test_type_comments_arguments\", \"tests/unittest_nodes.py::test_type_comments_posonly_arguments\", \"tests/unittest_nodes.py::test_correct_function_type_comment_parent\", \"tests/unittest_nodes.py::test_is_generator_for_yield_assignments\", \"tests/unittest_nodes.py::test_f_string_correct_line_numbering\", \"tests/unittest_nodes.py::test_assignment_expression\", \"tests/unittest_nodes.py::test_assignment_expression_in_functiondef\", \"tests/unittest_nodes.py::test_get_doc\", \"tests/unittest_nodes.py::test_parse_fstring_debug_mode\", \"tests/unittest_nodes.py::test_parse_type_comments_with_proper_parent\", \"tests/unittest_nodes.py::test_const_itered\", \"tests/unittest_nodes.py::test_is_generator_for_yield_in_while\", \"tests/unittest_nodes.py::test_is_generator_for_yield_in_if\", \"tests/unittest_nodes.py::test_is_generator_for_yield_in_aug_assign\"]"], "files_to_edit": ["astroid/nodes/as_string.py"], "metadata": {"hints_text": "Thank you for opening the issue.\nI don't believe `Unknown().as_string()` is ever called regularly. AFAIK it's only used during inference. What should the string representation of an `Unknown` node be? So not sure this needs to be addressed.\nProbably just `'Unknown'`.\nIt's mostly only a problem when we do something like this:\n\n```python\ninferred = infer(node)\nif inferred is not Uninferable:\n    if inferred.as_string().contains(some_value):\n        ...\n```\nSo for the most part, as long as it doesn't crash we're good.", "created_at": "2021-11-21T16:15:23Z", "version": "2.9", "test_patch": "diff --git a/tests/unittest_nodes.py b/tests/unittest_nodes.py\n--- a/tests/unittest_nodes.py\n+++ b/tests/unittest_nodes.py\n@@ -306,6 +306,11 @@ def test_f_strings(self):\n         ast = abuilder.string_build(code)\n         self.assertEqual(ast.as_string().strip(), code.strip())\n \n+    @staticmethod\n+    def test_as_string_unknown() -> None:\n+        assert nodes.Unknown().as_string() == \"Unknown.Unknown()\"\n+        assert nodes.Unknown(lineno=1, col_offset=0).as_string() == \"Unknown.Unknown()\"\n+\n \n class _NodeTest(unittest.TestCase):\n     \"\"\"test transformation of If Node\"\"\"\n", "environment_setup_commit": "0d1211558670cfefd95b39984b8d5f7f34837f32"}}
{"problem_id": "pyvista__pyvista-4315", "repo_owner": "pyvista", "repo_name": "pyvista", "repo_url": "https://github.com/pyvista/pyvista", "base_commit": "db6ee8dd4a747b8864caae36c5d05883976a3ae5", "problem": "Rectilinear grid does not allow Sequences as inputs\n### Describe the bug, what's wrong, and what you expected.\r\n\r\nRectilinear grid gives an error when `Sequence`s are passed in, but `ndarray` are ok.\r\n\r\n### Steps to reproduce the bug.\r\n\r\nThis doesn't work\r\n```python\r\nimport pyvista as pv\r\npv.RectilinearGrid([0, 1], [0, 1], [0, 1])\r\n```\r\n\r\nThis works\r\n```py\r\nimport pyvista as pv\r\nimport numpy as np\r\npv.RectilinearGrid(np.ndarray([0, 1]), np.ndarray([0, 1]), np.ndarray([0, 1]))\r\n```\r\n### System Information\r\n\r\n```shell\r\n--------------------------------------------------------------------------------\r\n  Date: Wed Apr 19 20:15:10 2023 UTC\r\n\r\n                OS : Linux\r\n            CPU(s) : 2\r\n           Machine : x86_64\r\n      Architecture : 64bit\r\n       Environment : IPython\r\n        GPU Vendor : Mesa/X.org\r\n      GPU Renderer : llvmpipe (LLVM 11.0.1, 256 bits)\r\n       GPU Version : 4.5 (Core Profile) Mesa 20.3.5\r\n\r\n  Python 3.11.2 (main, Mar 23 2023, 17:12:29) [GCC 10.2.1 20210110]\r\n\r\n           pyvista : 0.38.5\r\n               vtk : 9.2.6\r\n             numpy : 1.24.2\r\n           imageio : 2.27.0\r\n            scooby : 0.7.1\r\n             pooch : v1.7.0\r\n        matplotlib : 3.7.1\r\n           IPython : 8.12.0\r\n--------------------------------------------------------------------------------\r\n```\r\n\r\n\r\n### Screenshots\r\n\r\n_No response_\n", "issue_title": "Fix issue in pyvista/pyvista", "issue_body": "Rectilinear grid does not allow Sequences as inputs\n### Describe the bug, what's wrong, and what you expected.\r\n\r\nRectilinear grid gives an error when `Sequence`s are passed in, but `ndarray` are ok.\r\n\r\n### Steps to reproduce the bug.\r\n\r\nThis doesn't work\r\n```python\r\nimport pyvista as pv\r\npv.RectilinearGrid([0, 1], [0, 1], [0, 1])\r\n```\r\n\r\nThis works\r\n```py\r\nimport pyvista as pv\r\nimport numpy as np\r\npv.RectilinearGrid(np.ndarray([0, 1]), np.ndarray([0, 1]), np.ndarray([0, 1]))\r\n```\r\n### System Information\r\n\r\n```shell\r\n--------------------------------------------------------------------------------\r\n  Date: Wed Apr 19 20:15:10 2023 UTC\r\n\r\n                OS : Linux\r\n            CPU(s) : 2\r\n           Machine : x86_64\r\n      Architecture : 64bit\r\n       Environment : IPython\r\n        GPU Vendor : Mesa/X.org\r\n      GPU Renderer : llvmpipe (LLVM 11.0.1, 256 bits)\r\n       GPU Version : 4.5 (Core Profile) Mesa 20.3.5\r\n\r\n  Python 3.11.2 (main, Mar 23 2023, 17:12:29) [GCC 10.2.1 20210110]\r\n\r\n           pyvista : 0.38.5\r\n               vtk : 9.2.6\r\n             numpy : 1.24.2\r\n           imageio : 2.27.0\r\n            scooby : 0.7.1\r\n             pooch : v1.7.0\r\n        matplotlib : 3.7.1\r\n           IPython : 8.12.0\r\n--------------------------------------------------------------------------------\r\n```\r\n\r\n\r\n### Screenshots\r\n\r\n_No response_\n", "pr_diff": "diff --git a/pyvista/core/grid.py b/pyvista/core/grid.py\n--- a/pyvista/core/grid.py\n+++ b/pyvista/core/grid.py\n@@ -135,23 +135,30 @@ def __init__(self, *args, check_duplicates=False, deep=False, **kwargs):\n                     self.shallow_copy(args[0])\n             elif isinstance(args[0], (str, pathlib.Path)):\n                 self._from_file(args[0], **kwargs)\n-            elif isinstance(args[0], np.ndarray):\n-                self._from_arrays(args[0], None, None, check_duplicates)\n+            elif isinstance(args[0], (np.ndarray, Sequence)):\n+                self._from_arrays(np.asanyarray(args[0]), None, None, check_duplicates)\n             else:\n                 raise TypeError(f'Type ({type(args[0])}) not understood by `RectilinearGrid`')\n \n         elif len(args) == 3 or len(args) == 2:\n-            arg0_is_arr = isinstance(args[0], np.ndarray)\n-            arg1_is_arr = isinstance(args[1], np.ndarray)\n+            arg0_is_arr = isinstance(args[0], (np.ndarray, Sequence))\n+            arg1_is_arr = isinstance(args[1], (np.ndarray, Sequence))\n             if len(args) == 3:\n-                arg2_is_arr = isinstance(args[2], np.ndarray)\n+                arg2_is_arr = isinstance(args[2], (np.ndarray, Sequence))\n             else:\n                 arg2_is_arr = False\n \n             if all([arg0_is_arr, arg1_is_arr, arg2_is_arr]):\n-                self._from_arrays(args[0], args[1], args[2], check_duplicates)\n+                self._from_arrays(\n+                    np.asanyarray(args[0]),\n+                    np.asanyarray(args[1]),\n+                    np.asanyarray(args[2]),\n+                    check_duplicates,\n+                )\n             elif all([arg0_is_arr, arg1_is_arr]):\n-                self._from_arrays(args[0], args[1], None, check_duplicates)\n+                self._from_arrays(\n+                    np.asanyarray(args[0]), np.asanyarray(args[1]), None, check_duplicates\n+                )\n             else:\n                 raise TypeError(\"Arguments not understood by `RectilinearGrid`.\")\n \n", "solution": "diff --git a/pyvista/core/grid.py b/pyvista/core/grid.py\n--- a/pyvista/core/grid.py\n+++ b/pyvista/core/grid.py\n@@ -135,23 +135,30 @@ def __init__(self, *args, check_duplicates=False, deep=False, **kwargs):\n                     self.shallow_copy(args[0])\n             elif isinstance(args[0], (str, pathlib.Path)):\n                 self._from_file(args[0], **kwargs)\n-            elif isinstance(args[0], np.ndarray):\n-                self._from_arrays(args[0], None, None, check_duplicates)\n+            elif isinstance(args[0], (np.ndarray, Sequence)):\n+                self._from_arrays(np.asanyarray(args[0]), None, None, check_duplicates)\n             else:\n                 raise TypeError(f'Type ({type(args[0])}) not understood by `RectilinearGrid`')\n \n         elif len(args) == 3 or len(args) == 2:\n-            arg0_is_arr = isinstance(args[0], np.ndarray)\n-            arg1_is_arr = isinstance(args[1], np.ndarray)\n+            arg0_is_arr = isinstance(args[0], (np.ndarray, Sequence))\n+            arg1_is_arr = isinstance(args[1], (np.ndarray, Sequence))\n             if len(args) == 3:\n-                arg2_is_arr = isinstance(args[2], np.ndarray)\n+                arg2_is_arr = isinstance(args[2], (np.ndarray, Sequence))\n             else:\n                 arg2_is_arr = False\n \n             if all([arg0_is_arr, arg1_is_arr, arg2_is_arr]):\n-                self._from_arrays(args[0], args[1], args[2], check_duplicates)\n+                self._from_arrays(\n+                    np.asanyarray(args[0]),\n+                    np.asanyarray(args[1]),\n+                    np.asanyarray(args[2]),\n+                    check_duplicates,\n+                )\n             elif all([arg0_is_arr, arg1_is_arr]):\n-                self._from_arrays(args[0], args[1], None, check_duplicates)\n+                self._from_arrays(\n+                    np.asanyarray(args[0]), np.asanyarray(args[1]), None, check_duplicates\n+                )\n             else:\n                 raise TypeError(\"Arguments not understood by `RectilinearGrid`.\")\n \n", "test_command": "[\"tests/test_grid.py::test_create_rectilinear_grid_from_specs\"]", "test_commands": ["[\"tests/test_grid.py::test_create_rectilinear_grid_from_specs\"]", "[\"tests/test_grid.py::test_volume\", \"tests/test_grid.py::test_init_from_polydata\", \"tests/test_grid.py::test_init_from_structured\", \"tests/test_grid.py::test_init_from_unstructured\", \"tests/test_grid.py::test_init_from_numpy_arrays\", \"tests/test_grid.py::test_init_bad_input\", \"tests/test_grid.py::test_init_from_arrays[False]\", \"tests/test_grid.py::test_init_from_arrays[True]\", \"tests/test_grid.py::test_init_from_dict[False-False]\", \"tests/test_grid.py::test_init_from_dict[False-True]\", \"tests/test_grid.py::test_init_from_dict[True-False]\", \"tests/test_grid.py::test_init_from_dict[True-True]\", \"tests/test_grid.py::test_init_polyhedron\", \"tests/test_grid.py::test_cells_dict_hexbeam_file\", \"tests/test_grid.py::test_cells_dict_variable_length\", \"tests/test_grid.py::test_cells_dict_empty_grid\", \"tests/test_grid.py::test_cells_dict_alternating_cells\", \"tests/test_grid.py::test_destructor\", \"tests/test_grid.py::test_surface_indices\", \"tests/test_grid.py::test_extract_feature_edges\", \"tests/test_grid.py::test_triangulate_inplace\", \"tests/test_grid.py::test_save[.vtu-True]\", \"tests/test_grid.py::test_save[.vtu-False]\", \"tests/test_grid.py::test_save[.vtk-True]\", \"tests/test_grid.py::test_save[.vtk-False]\", \"tests/test_grid.py::test_pathlib_read_write\", \"tests/test_grid.py::test_init_bad_filename\", \"tests/test_grid.py::test_save_bad_extension\", \"tests/test_grid.py::test_linear_copy\", \"tests/test_grid.py::test_linear_copy_surf_elem\", \"tests/test_grid.py::test_extract_cells[True]\", \"tests/test_grid.py::test_extract_cells[False]\", \"tests/test_grid.py::test_merge\", \"tests/test_grid.py::test_merge_not_main\", \"tests/test_grid.py::test_merge_list\", \"tests/test_grid.py::test_merge_invalid\", \"tests/test_grid.py::test_init_structured_raise\", \"tests/test_grid.py::test_init_structured\", \"tests/test_grid.py::test_no_copy_polydata_init\", \"tests/test_grid.py::test_no_copy_polydata_points_setter\", \"tests/test_grid.py::test_no_copy_structured_mesh_init\", \"tests/test_grid.py::test_no_copy_structured_mesh_points_setter\", \"tests/test_grid.py::test_no_copy_pointset_init\", \"tests/test_grid.py::test_no_copy_pointset_points_setter\", \"tests/test_grid.py::test_no_copy_unstructured_grid_points_setter\", \"tests/test_grid.py::test_no_copy_rectilinear_grid\", \"tests/test_grid.py::test_grid_repr\", \"tests/test_grid.py::test_slice_structured\", \"tests/test_grid.py::test_invalid_init_structured\", \"tests/test_grid.py::test_save_structured[.vtk-True]\", \"tests/test_grid.py::test_save_structured[.vtk-False]\", \"tests/test_grid.py::test_save_structured[.vts-True]\", \"tests/test_grid.py::test_save_structured[.vts-False]\", \"tests/test_grid.py::test_load_structured_bad_filename\", \"tests/test_grid.py::test_instantiate_by_filename\", \"tests/test_grid.py::test_create_rectilinear_after_init\", \"tests/test_grid.py::test_create_rectilinear_grid_from_file\", \"tests/test_grid.py::test_read_rectilinear_grid_from_file\", \"tests/test_grid.py::test_read_rectilinear_grid_from_pathlib\", \"tests/test_grid.py::test_raise_rectilinear_grid_non_unique\", \"tests/test_grid.py::test_cast_rectilinear_grid\", \"tests/test_grid.py::test_create_uniform_grid_from_specs\", \"tests/test_grid.py::test_uniform_grid_invald_args\", \"tests/test_grid.py::test_uniform_setters\", \"tests/test_grid.py::test_create_uniform_grid_from_file\", \"tests/test_grid.py::test_read_uniform_grid_from_file\", \"tests/test_grid.py::test_read_uniform_grid_from_pathlib\", \"tests/test_grid.py::test_cast_uniform_to_structured\", \"tests/test_grid.py::test_cast_uniform_to_rectilinear\", \"tests/test_grid.py::test_uniform_grid_to_tetrahedra\", \"tests/test_grid.py::test_fft_and_rfft\", \"tests/test_grid.py::test_fft_low_pass\", \"tests/test_grid.py::test_fft_high_pass\", \"tests/test_grid.py::test_save_rectilinear[.vtk-True]\", \"tests/test_grid.py::test_save_rectilinear[.vtk-False]\", \"tests/test_grid.py::test_save_rectilinear[.vtr-True]\", \"tests/test_grid.py::test_save_rectilinear[.vtr-False]\", \"tests/test_grid.py::test_save_uniform[.vtk-True]\", \"tests/test_grid.py::test_save_uniform[.vtk-False]\", \"tests/test_grid.py::test_save_uniform[.vti-True]\", \"tests/test_grid.py::test_save_uniform[.vti-False]\", \"tests/test_grid.py::test_grid_points\", \"tests/test_grid.py::test_grid_extract_selection_points\", \"tests/test_grid.py::test_gaussian_smooth\", \"tests/test_grid.py::test_remove_cells[ind0]\", \"tests/test_grid.py::test_remove_cells[ind1]\", \"tests/test_grid.py::test_remove_cells[ind2]\", \"tests/test_grid.py::test_remove_cells_not_inplace[ind0]\", \"tests/test_grid.py::test_remove_cells_not_inplace[ind1]\", \"tests/test_grid.py::test_remove_cells_not_inplace[ind2]\", \"tests/test_grid.py::test_remove_cells_invalid\", \"tests/test_grid.py::test_hide_cells[ind0]\", \"tests/test_grid.py::test_hide_cells[ind1]\", \"tests/test_grid.py::test_hide_cells[ind2]\", \"tests/test_grid.py::test_hide_points[ind0]\", \"tests/test_grid.py::test_hide_points[ind1]\", \"tests/test_grid.py::test_hide_points[ind2]\", \"tests/test_grid.py::test_set_extent\", \"tests/test_grid.py::test_UnstructuredGrid_cast_to_explicit_structured_grid\", \"tests/test_grid.py::test_ExplicitStructuredGrid_init\", \"tests/test_grid.py::test_ExplicitStructuredGrid_cast_to_unstructured_grid\", \"tests/test_grid.py::test_ExplicitStructuredGrid_save\", \"tests/test_grid.py::test_ExplicitStructuredGrid_hide_cells\", \"tests/test_grid.py::test_ExplicitStructuredGrid_show_cells\", \"tests/test_grid.py::test_ExplicitStructuredGrid_dimensions\", \"tests/test_grid.py::test_ExplicitStructuredGrid_visible_bounds\", \"tests/test_grid.py::test_ExplicitStructuredGrid_cell_id\", \"tests/test_grid.py::test_ExplicitStructuredGrid_cell_coords\", \"tests/test_grid.py::test_ExplicitStructuredGrid_neighbors\", \"tests/test_grid.py::test_ExplicitStructuredGrid_compute_connectivity\", \"tests/test_grid.py::test_ExplicitStructuredGrid_compute_connections\", \"tests/test_grid.py::test_ExplicitStructuredGrid_raise_init\", \"tests/test_grid.py::test_copy_no_copy_wrap_object\", \"tests/test_grid.py::test_copy_no_copy_wrap_object_vtk9\"]"], "files_to_edit": ["pyvista/core/grid.py"], "metadata": {"hints_text": "", "created_at": "2023-04-21T13:47:31Z", "version": "0.39", "test_patch": "diff --git a/tests/test_grid.py b/tests/test_grid.py\n--- a/tests/test_grid.py\n+++ b/tests/test_grid.py\n@@ -735,6 +735,21 @@ def test_create_rectilinear_grid_from_specs():\n     assert grid.n_cells == 9 * 3 * 19\n     assert grid.n_points == 10 * 4 * 20\n     assert grid.bounds == (-10.0, 8.0, -10.0, 5.0, -10.0, 9.0)\n+\n+    # with Sequence\n+    xrng = [0, 1]\n+    yrng = [0, 1, 2]\n+    zrng = [0, 1, 2, 3]\n+    grid = pyvista.RectilinearGrid(xrng)\n+    assert grid.n_cells == 1\n+    assert grid.n_points == 2\n+    grid = pyvista.RectilinearGrid(xrng, yrng)\n+    assert grid.n_cells == 2\n+    assert grid.n_points == 6\n+    grid = pyvista.RectilinearGrid(xrng, yrng, zrng)\n+    assert grid.n_cells == 6\n+    assert grid.n_points == 24\n+\n     # 2D example\n     cell_spacings = np.array([1.0, 1.0, 2.0, 2.0, 5.0, 10.0])\n     x_coordinates = np.cumsum(cell_spacings)\n", "environment_setup_commit": "4c2d1aed10b1600d520271beba8579c71433e808"}}
{"problem_id": "pydicom__pydicom-1694", "repo_owner": "pydicom", "repo_name": "pydicom", "repo_url": "https://github.com/pydicom/pydicom", "base_commit": "f8cf45b6c121e5a4bf4a43f71aba3bc64af3db9c", "problem": "Dataset.to_json_dict can still generate exceptions when suppress_invalid_tags=True\n**Describe the bug**\r\nI'm using `Dataset.to_json_dict(suppress_invalid_tags=True)` and can live with losing invalid tags.  Unfortunately, I can still trigger an exception with something like  `2.0` in an `IS` field.\r\n\r\n**Expected behavior**\r\nto_json_dict shouldn't throw an error about an invalid tag when `suppress_invalid_tags` is enabled.\r\n\r\nMy thought was simply to move the `data_element = self[key]` into the try/catch block that's right after it.\r\n\r\n**Steps To Reproduce**\r\n\r\nTraceback:\r\n```\r\n  File \"dicom.py\", line 143, in create_dict\r\n    json_ds = ds.to_json_dict(suppress_invalid_tags=True)\r\n  File \"/usr/lib/python3/dist-packages/pydicom/dataset.py\", line 2495, in to_json_dict\r\n    data_element = self[key]\r\n  File \"/usr/lib/python3/dist-packages/pydicom/dataset.py\", line 939, in __getitem__\r\n    self[tag] = DataElement_from_raw(elem, character_set, self)\r\n  File \"/usr/lib/python3/dist-packages/pydicom/dataelem.py\", line 859, in DataElement_from_raw\r\n    value = convert_value(vr, raw, encoding)\r\n  File \"/usr/lib/python3/dist-packages/pydicom/values.py\", line 771, in convert_value\r\n    return converter(byte_string, is_little_endian, num_format)\r\n  File \"/usr/lib/python3/dist-packages/pydicom/values.py\", line 348, in convert_IS_string\r\n    return MultiString(num_string, valtype=pydicom.valuerep.IS)\r\n  File \"/usr/lib/python3/dist-packages/pydicom/valuerep.py\", line 1213, in MultiString\r\n    return valtype(splitup[0])\r\n  File \"/usr/lib/python3/dist-packages/pydicom/valuerep.py\", line 1131, in __new__\r\n    raise TypeError(\"Could not convert value to integer without loss\")\r\nTypeError: Could not convert value to integer without loss\r\n```\r\n\r\n**Your environment**\r\npython 3.7, pydicom 2.3\r\n\r\n\n", "issue_title": "Fix issue in pydicom/pydicom", "issue_body": "Dataset.to_json_dict can still generate exceptions when suppress_invalid_tags=True\n**Describe the bug**\r\nI'm using `Dataset.to_json_dict(suppress_invalid_tags=True)` and can live with losing invalid tags.  Unfortunately, I can still trigger an exception with something like  `2.0` in an `IS` field.\r\n\r\n**Expected behavior**\r\nto_json_dict shouldn't throw an error about an invalid tag when `suppress_invalid_tags` is enabled.\r\n\r\nMy thought was simply to move the `data_element = self[key]` into the try/catch block that's right after it.\r\n\r\n**Steps To Reproduce**\r\n\r\nTraceback:\r\n```\r\n  File \"dicom.py\", line 143, in create_dict\r\n    json_ds = ds.to_json_dict(suppress_invalid_tags=True)\r\n  File \"/usr/lib/python3/dist-packages/pydicom/dataset.py\", line 2495, in to_json_dict\r\n    data_element = self[key]\r\n  File \"/usr/lib/python3/dist-packages/pydicom/dataset.py\", line 939, in __getitem__\r\n    self[tag] = DataElement_from_raw(elem, character_set, self)\r\n  File \"/usr/lib/python3/dist-packages/pydicom/dataelem.py\", line 859, in DataElement_from_raw\r\n    value = convert_value(vr, raw, encoding)\r\n  File \"/usr/lib/python3/dist-packages/pydicom/values.py\", line 771, in convert_value\r\n    return converter(byte_string, is_little_endian, num_format)\r\n  File \"/usr/lib/python3/dist-packages/pydicom/values.py\", line 348, in convert_IS_string\r\n    return MultiString(num_string, valtype=pydicom.valuerep.IS)\r\n  File \"/usr/lib/python3/dist-packages/pydicom/valuerep.py\", line 1213, in MultiString\r\n    return valtype(splitup[0])\r\n  File \"/usr/lib/python3/dist-packages/pydicom/valuerep.py\", line 1131, in __new__\r\n    raise TypeError(\"Could not convert value to integer without loss\")\r\nTypeError: Could not convert value to integer without loss\r\n```\r\n\r\n**Your environment**\r\npython 3.7, pydicom 2.3\r\n\r\n\n", "pr_diff": "diff --git a/pydicom/dataset.py b/pydicom/dataset.py\n--- a/pydicom/dataset.py\n+++ b/pydicom/dataset.py\n@@ -2492,8 +2492,8 @@ def to_json_dict(\n         json_dataset = {}\n         for key in self.keys():\n             json_key = '{:08X}'.format(key)\n-            data_element = self[key]\n             try:\n+                data_element = self[key]\n                 json_dataset[json_key] = data_element.to_json_dict(\n                     bulk_data_element_handler=bulk_data_element_handler,\n                     bulk_data_threshold=bulk_data_threshold\n", "solution": "diff --git a/pydicom/dataset.py b/pydicom/dataset.py\n--- a/pydicom/dataset.py\n+++ b/pydicom/dataset.py\n@@ -2492,8 +2492,8 @@ def to_json_dict(\n         json_dataset = {}\n         for key in self.keys():\n             json_key = '{:08X}'.format(key)\n-            data_element = self[key]\n             try:\n+                data_element = self[key]\n                 json_dataset[json_key] = data_element.to_json_dict(\n                     bulk_data_element_handler=bulk_data_element_handler,\n                     bulk_data_threshold=bulk_data_threshold\n", "test_command": "[\"pydicom/tests/test_json.py::TestDataSetToJson::test_suppress_invalid_tags_with_failed_dataelement\"]", "test_commands": ["[\"pydicom/tests/test_json.py::TestDataSetToJson::test_suppress_invalid_tags_with_failed_dataelement\"]", "[\"pydicom/tests/test_json.py::TestPersonName::test_json_pn_from_file\", \"pydicom/tests/test_json.py::TestPersonName::test_pn_components_to_json\", \"pydicom/tests/test_json.py::TestPersonName::test_pn_components_from_json\", \"pydicom/tests/test_json.py::TestPersonName::test_empty_value\", \"pydicom/tests/test_json.py::TestPersonName::test_multi_value_to_json\", \"pydicom/tests/test_json.py::TestPersonName::test_dataelem_from_json\", \"pydicom/tests/test_json.py::TestAT::test_to_json\", \"pydicom/tests/test_json.py::TestAT::test_from_json\", \"pydicom/tests/test_json.py::TestAT::test_invalid_value_in_json\", \"pydicom/tests/test_json.py::TestAT::test_invalid_tag_in_json\", \"pydicom/tests/test_json.py::TestDataSetToJson::test_json_from_dicom_file\", \"pydicom/tests/test_json.py::TestDataSetToJson::test_roundtrip\", \"pydicom/tests/test_json.py::TestDataSetToJson::test_dataset_dumphandler\", \"pydicom/tests/test_json.py::TestDataSetToJson::test_dataelement_dumphandler\", \"pydicom/tests/test_json.py::TestDataSetToJson::test_sort_order\", \"pydicom/tests/test_json.py::TestDataSetToJson::test_suppress_invalid_tags\", \"pydicom/tests/test_json.py::TestSequence::test_nested_sequences\", \"pydicom/tests/test_json.py::TestBinary::test_inline_binary\", \"pydicom/tests/test_json.py::TestBinary::test_invalid_inline_binary\", \"pydicom/tests/test_json.py::TestBinary::test_valid_bulkdata_uri\", \"pydicom/tests/test_json.py::TestBinary::test_invalid_bulkdata_uri\", \"pydicom/tests/test_json.py::TestBinary::test_bulk_data_reader_is_called\", \"pydicom/tests/test_json.py::TestBinary::test_bulk_data_reader_is_called_2\", \"pydicom/tests/test_json.py::TestBinary::test_bulk_data_reader_is_called_within_SQ\", \"pydicom/tests/test_json.py::TestNumeric::test_numeric_values\", \"pydicom/tests/test_json.py::TestNumeric::test_numeric_types\"]"], "files_to_edit": ["pydicom/dataset.py"], "metadata": {"hints_text": "", "created_at": "2022-09-20T18:52:53Z", "version": "2.3", "test_patch": "diff --git a/pydicom/tests/test_json.py b/pydicom/tests/test_json.py\n--- a/pydicom/tests/test_json.py\n+++ b/pydicom/tests/test_json.py\n@@ -7,7 +7,7 @@\n \n from pydicom import dcmread\n from pydicom.data import get_testdata_file\n-from pydicom.dataelem import DataElement\n+from pydicom.dataelem import DataElement, RawDataElement\n from pydicom.dataset import Dataset\n from pydicom.tag import Tag, BaseTag\n from pydicom.valuerep import PersonName\n@@ -284,7 +284,23 @@ def test_suppress_invalid_tags(self, _):\n \n         ds_json = ds.to_json_dict(suppress_invalid_tags=True)\n \n-        assert ds_json.get(\"00100010\") is None\n+        assert \"00100010\" not in ds_json\n+\n+    def test_suppress_invalid_tags_with_failed_dataelement(self):\n+        \"\"\"Test tags that raise exceptions don't if suppress_invalid_tags True.\n+        \"\"\"\n+        ds = Dataset()\n+        # we have to add a RawDataElement as creating a DataElement would\n+        # already raise an exception\n+        ds[0x00082128] = RawDataElement(\n+            Tag(0x00082128), 'IS', 4, b'5.25', 0, True, True)\n+\n+        with pytest.raises(TypeError):\n+            ds.to_json_dict()\n+\n+        ds_json = ds.to_json_dict(suppress_invalid_tags=True)\n+\n+        assert \"00082128\" not in ds_json\n \n \n class TestSequence:\n", "environment_setup_commit": "a8be738418dee0a2b93c241fbd5e0bc82f4b8680"}}
{"problem_id": "pydicom__pydicom-1413", "repo_owner": "pydicom", "repo_name": "pydicom", "repo_url": "https://github.com/pydicom/pydicom", "base_commit": "f909c76e31f759246cec3708dadd173c5d6e84b1", "problem": "Error : a bytes-like object is required, not 'MultiValue'\nHello,\r\n\r\nI am getting following error while updating the tag LongTrianglePointIndexList (0066,0040),\r\n**TypeError: a bytes-like object is required, not 'MultiValue'**\r\n\r\nI noticed that the error  gets produced only when the VR is given as \"OL\" , works fine with \"OB\", \"OF\" etc.\r\n\r\nsample code (assume 'lineSeq' is the dicom dataset sequence):\r\n```python\r\nimport pydicom\r\nimport array\r\ndata=list(range(1,10))\r\ndata=array.array('H', indexData).tostring()  # to convert to unsigned short\r\nlineSeq.add_new(0x00660040, 'OL', data)   \r\nds.save_as(\"mydicom\")\r\n```\r\noutcome: **TypeError: a bytes-like object is required, not 'MultiValue'**\r\n\r\nusing version - 2.0.0.0\r\n\r\nAny help is appreciated.\r\n\r\nThank you\n", "issue_title": "Fix issue in pydicom/pydicom", "issue_body": "Error : a bytes-like object is required, not 'MultiValue'\nHello,\r\n\r\nI am getting following error while updating the tag LongTrianglePointIndexList (0066,0040),\r\n**TypeError: a bytes-like object is required, not 'MultiValue'**\r\n\r\nI noticed that the error  gets produced only when the VR is given as \"OL\" , works fine with \"OB\", \"OF\" etc.\r\n\r\nsample code (assume 'lineSeq' is the dicom dataset sequence):\r\n```python\r\nimport pydicom\r\nimport array\r\ndata=list(range(1,10))\r\ndata=array.array('H', indexData).tostring()  # to convert to unsigned short\r\nlineSeq.add_new(0x00660040, 'OL', data)   \r\nds.save_as(\"mydicom\")\r\n```\r\noutcome: **TypeError: a bytes-like object is required, not 'MultiValue'**\r\n\r\nusing version - 2.0.0.0\r\n\r\nAny help is appreciated.\r\n\r\nThank you\n", "pr_diff": "diff --git a/pydicom/dataelem.py b/pydicom/dataelem.py\n--- a/pydicom/dataelem.py\n+++ b/pydicom/dataelem.py\n@@ -433,13 +433,24 @@ def value(self) -> Any:\n     @value.setter\n     def value(self, val: Any) -> None:\n         \"\"\"Convert (if necessary) and set the value of the element.\"\"\"\n+        # Ignore backslash characters in these VRs, based on:\n+        # * Which str VRs can have backslashes in Part 5, Section 6.2\n+        # * All byte VRs\n+        exclusions = [\n+            'LT', 'OB', 'OD', 'OF', 'OL', 'OV', 'OW', 'ST', 'UN', 'UT',\n+            'OB/OW', 'OW/OB', 'OB or OW', 'OW or OB',\n+            # Probably not needed\n+            'AT', 'FD', 'FL', 'SQ', 'SS', 'SL', 'UL',\n+        ]\n+\n         # Check if is a string with multiple values separated by '\\'\n         # If so, turn them into a list of separate strings\n         #  Last condition covers 'US or SS' etc\n-        if isinstance(val, (str, bytes)) and self.VR not in \\\n-                ['UT', 'ST', 'LT', 'FL', 'FD', 'AT', 'OB', 'OW', 'OF', 'SL',\n-                 'SQ', 'SS', 'UL', 'OB/OW', 'OW/OB', 'OB or OW',\n-                 'OW or OB', 'UN'] and 'US' not in self.VR:\n+        if (\n+            isinstance(val, (str, bytes))\n+            and self.VR not in exclusions\n+            and 'US' not in self.VR\n+        ):\n             try:\n                 if _backslash_str in val:\n                     val = cast(str, val).split(_backslash_str)\n", "solution": "diff --git a/pydicom/dataelem.py b/pydicom/dataelem.py\n--- a/pydicom/dataelem.py\n+++ b/pydicom/dataelem.py\n@@ -433,13 +433,24 @@ def value(self) -> Any:\n     @value.setter\n     def value(self, val: Any) -> None:\n         \"\"\"Convert (if necessary) and set the value of the element.\"\"\"\n+        # Ignore backslash characters in these VRs, based on:\n+        # * Which str VRs can have backslashes in Part 5, Section 6.2\n+        # * All byte VRs\n+        exclusions = [\n+            'LT', 'OB', 'OD', 'OF', 'OL', 'OV', 'OW', 'ST', 'UN', 'UT',\n+            'OB/OW', 'OW/OB', 'OB or OW', 'OW or OB',\n+            # Probably not needed\n+            'AT', 'FD', 'FL', 'SQ', 'SS', 'SL', 'UL',\n+        ]\n+\n         # Check if is a string with multiple values separated by '\\'\n         # If so, turn them into a list of separate strings\n         #  Last condition covers 'US or SS' etc\n-        if isinstance(val, (str, bytes)) and self.VR not in \\\n-                ['UT', 'ST', 'LT', 'FL', 'FD', 'AT', 'OB', 'OW', 'OF', 'SL',\n-                 'SQ', 'SS', 'UL', 'OB/OW', 'OW/OB', 'OB or OW',\n-                 'OW or OB', 'UN'] and 'US' not in self.VR:\n+        if (\n+            isinstance(val, (str, bytes))\n+            and self.VR not in exclusions\n+            and 'US' not in self.VR\n+        ):\n             try:\n                 if _backslash_str in val:\n                     val = cast(str, val).split(_backslash_str)\n", "test_command": "[\"pydicom/tests/test_valuerep.py::test_assigning_bytes[OD-bytes-vm017-vmN17-DoubleFloatPixelData]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[OL-bytes-vm019-vmN19-TrackPointIndexList]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[OV-bytes-vm020-vmN20-SelectorOVValue]\"]", "test_commands": ["[\"pydicom/tests/test_valuerep.py::test_assigning_bytes[OD-bytes-vm017-vmN17-DoubleFloatPixelData]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[OL-bytes-vm019-vmN19-TrackPointIndexList]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[OV-bytes-vm020-vmN20-SelectorOVValue]\"]", "[\"pydicom/tests/test_valuerep.py::TestTM::test_pickling\", \"pydicom/tests/test_valuerep.py::TestTM::test_pickling_tm_from_time\", \"pydicom/tests/test_valuerep.py::TestTM::test_str_and_repr\", \"pydicom/tests/test_valuerep.py::TestTM::test_new_empty_str\", \"pydicom/tests/test_valuerep.py::TestTM::test_new_str_conversion\", \"pydicom/tests/test_valuerep.py::TestTM::test_new_obj_conversion\", \"pydicom/tests/test_valuerep.py::TestTM::test_comparison\", \"pydicom/tests/test_valuerep.py::TestTM::test_time_behavior\", \"pydicom/tests/test_valuerep.py::TestDT::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDT::test_pickling_with_timezone\", \"pydicom/tests/test_valuerep.py::TestDT::test_pickling_dt_from_datetime\", \"pydicom/tests/test_valuerep.py::TestDT::test_pickling_dt_from_datetime_with_timezone\", \"pydicom/tests/test_valuerep.py::TestDT::test_new_empty_str\", \"pydicom/tests/test_valuerep.py::TestDT::test_new_obj_conversion\", \"pydicom/tests/test_valuerep.py::TestDT::test_new_str_conversion\", \"pydicom/tests/test_valuerep.py::TestDT::test_str_and_repr\", \"pydicom/tests/test_valuerep.py::TestDT::test_comparison\", \"pydicom/tests/test_valuerep.py::TestDT::test_datetime_behavior\", \"pydicom/tests/test_valuerep.py::TestDA::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDA::test_new_obj_conversion\", \"pydicom/tests/test_valuerep.py::TestDA::test_str_and_repr\", \"pydicom/tests/test_valuerep.py::TestDA::test_comparison\", \"pydicom/tests/test_valuerep.py::TestDA::test_date_behavior\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[1]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[3.14159265358979]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[-1234.456e78]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[1.234E-5]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[1.234E+5]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[+1]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[42\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[nan]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[-inf]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[3.141592653589793]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[1,000]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[1\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[127.0.0.1]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[1.e]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[1.0-1.0]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[0.0-0.0]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[-0.0--0.0]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[0.123-0.123]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[-0.321--0.321]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[1e-05-1e-05]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[3.141592653589793-3.14159265358979]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[-3.141592653589793--3.1415926535898]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[5.385940192876374e-07-5.3859401929e-07]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[-5.385940192876374e-07--5.385940193e-07]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[12342534378.125532-12342534378.1255]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[64070869985876.78-64070869985876.8]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[1.7976931348623157e+308-1.797693135e+308]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-101]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-100]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[100]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[101]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-16]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-15]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-14]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-13]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-12]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-11]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-10]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-9]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-8]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-7]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-6]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-5]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-4]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-3]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-2]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-1]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[0]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[1]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[2]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[3]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[4]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[5]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[6]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[7]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[8]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[9]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[10]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[11]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[12]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[13]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[14]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[15]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[16]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-101]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-100]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[100]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[101]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-16]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-15]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-14]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-13]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-12]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-11]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-10]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-9]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-8]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-7]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-6]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-5]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-4]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-3]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-2]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-1]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[0]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[1]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[2]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[3]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[4]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[5]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[6]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[7]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[8]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[9]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[10]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[11]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[12]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[13]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[14]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[15]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[16]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_invalid[nan0]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_invalid[nan1]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_invalid[-inf]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_invalid[inf]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_wrong_type\", \"pydicom/tests/test_valuerep.py::TestDS::test_empty_value\", \"pydicom/tests/test_valuerep.py::TestDS::test_float_values\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_new_empty\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_str_value\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_str\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_repr\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_DSfloat\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_DSdecimal\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_auto_format[True]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_auto_format[False]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_auto_format_from_invalid_DS\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_auto_format_invalid_string[True]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_auto_format_invalid_string[False]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_auto_format_valid_string[True]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_auto_format_valid_string[False]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_length\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_DSfloat_auto_format\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[nan0]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[-nan]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[inf0]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[-inf0]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[nan1]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[nan2]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[-inf1]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[inf1]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_comparison_operators\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_hash\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_float_value\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_new_empty\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_str_value\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_DSfloat\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_DSdecimal\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_repr\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_auto_format[True]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_auto_format[False]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_auto_format_from_invalid_DS\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_auto_format_invalid_string[True]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_auto_format_invalid_string[False]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[NaN]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[-NaN]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[Infinity]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[-Infinity]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[val4]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[val5]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[val6]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[val7]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_auto_format_valid_string[True]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_auto_format_valid_string[False]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_DSdecimal_auto_format\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_comparison_operators\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_hash\", \"pydicom/tests/test_valuerep.py::TestIS::test_empty_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_str_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_valid_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_invalid_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_pickling\", \"pydicom/tests/test_valuerep.py::TestIS::test_longint\", \"pydicom/tests/test_valuerep.py::TestIS::test_overflow\", \"pydicom/tests/test_valuerep.py::TestIS::test_str\", \"pydicom/tests/test_valuerep.py::TestIS::test_repr\", \"pydicom/tests/test_valuerep.py::TestIS::test_comparison_operators\", \"pydicom/tests/test_valuerep.py::TestIS::test_hash\", \"pydicom/tests/test_valuerep.py::TestBadValueRead::test_read_bad_value_in_VR_default\", \"pydicom/tests/test_valuerep.py::TestBadValueRead::test_read_bad_value_in_VR_enforce_valid_value\", \"pydicom/tests/test_valuerep.py::TestDecimalString::test_DS_decimal_set\", \"pydicom/tests/test_valuerep.py::TestDecimalString::test_valid_decimal_strings\", \"pydicom/tests/test_valuerep.py::TestDecimalString::test_invalid_decimal_strings\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_last_first\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_copy\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_three_component\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_formatting\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_kr\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_bytes\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_bytes_comp_delimiter\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_bytes_caret_delimiter\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_unicode\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_not_equal\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_encoding_carried\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_hash\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_next\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_iterator\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_contains\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_length\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components_kr_from_bytes\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components_kr_from_unicode\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components_jp_from_bytes\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components_jp_from_unicode\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components_veterinary\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components_with_separator\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components_with_separator_from_bytes\", \"pydicom/tests/test_valuerep.py::TestDateTime::test_date\", \"pydicom/tests/test_valuerep.py::TestDateTime::test_date_time\", \"pydicom/tests/test_valuerep.py::TestDateTime::test_time\", \"pydicom/tests/test_valuerep.py::test_person_name_unicode_warns\", \"pydicom/tests/test_valuerep.py::test_set_value[AE-str-vm00-vmN0-Receiver]\", \"pydicom/tests/test_valuerep.py::test_set_value[AS-str-vm01-vmN1-PatientAge]\", \"pydicom/tests/test_valuerep.py::test_set_value[AT-int-vm02-vmN2-OffendingElement]\", \"pydicom/tests/test_valuerep.py::test_set_value[CS-str-vm03-vmN3-QualityControlSubject]\", \"pydicom/tests/test_valuerep.py::test_set_value[DA-str-vm04-vmN4-PatientBirthDate]\", \"pydicom/tests/test_valuerep.py::test_set_value[DS-str-vm05-vmN5-PatientWeight]\", \"pydicom/tests/test_valuerep.py::test_set_value[DS-int-vm06-vmN6-PatientWeight]\", \"pydicom/tests/test_valuerep.py::test_set_value[DS-float-vm07-vmN7-PatientWeight]\", \"pydicom/tests/test_valuerep.py::test_set_value[DT-str-vm08-vmN8-AcquisitionDateTime]\", \"pydicom/tests/test_valuerep.py::test_set_value[FD-float-vm09-vmN9-RealWorldValueLUTData]\", \"pydicom/tests/test_valuerep.py::test_set_value[FL-float-vm010-vmN10-VectorAccuracy]\", \"pydicom/tests/test_valuerep.py::test_set_value[IS-str-vm011-vmN11-BeamNumber]\", \"pydicom/tests/test_valuerep.py::test_set_value[IS-int-vm012-vmN12-BeamNumber]\", \"pydicom/tests/test_valuerep.py::test_set_value[IS-float-vm013-vmN13-BeamNumber]\", \"pydicom/tests/test_valuerep.py::test_set_value[LO-str-vm014-vmN14-DataSetSubtype]\", \"pydicom/tests/test_valuerep.py::test_set_value[LT-str-vm015-vmN15-ExtendedCodeMeaning]\", \"pydicom/tests/test_valuerep.py::test_set_value[OB-bytes-vm016-vmN16-FillPattern]\", \"pydicom/tests/test_valuerep.py::test_set_value[OD-bytes-vm017-vmN17-DoubleFloatPixelData]\", \"pydicom/tests/test_valuerep.py::test_set_value[OF-bytes-vm018-vmN18-UValueData]\", \"pydicom/tests/test_valuerep.py::test_set_value[OL-bytes-vm019-vmN19-TrackPointIndexList]\", \"pydicom/tests/test_valuerep.py::test_set_value[OV-bytes-vm020-vmN20-SelectorOVValue]\", \"pydicom/tests/test_valuerep.py::test_set_value[OW-bytes-vm021-vmN21-TrianglePointIndexList]\", \"pydicom/tests/test_valuerep.py::test_set_value[PN-str-vm022-vmN22-PatientName]\", \"pydicom/tests/test_valuerep.py::test_set_value[SH-str-vm023-vmN23-CodeValue]\", \"pydicom/tests/test_valuerep.py::test_set_value[SL-int-vm024-vmN24-RationalNumeratorValue]\", \"pydicom/tests/test_valuerep.py::test_set_value[SQ-list-vm025-vmN25-BeamSequence]\", \"pydicom/tests/test_valuerep.py::test_set_value[SS-int-vm026-vmN26-SelectorSSValue]\", \"pydicom/tests/test_valuerep.py::test_set_value[ST-str-vm027-vmN27-InstitutionAddress]\", \"pydicom/tests/test_valuerep.py::test_set_value[SV-int-vm028-vmN28-SelectorSVValue]\", \"pydicom/tests/test_valuerep.py::test_set_value[TM-str-vm029-vmN29-StudyTime]\", \"pydicom/tests/test_valuerep.py::test_set_value[UC-str-vm030-vmN30-LongCodeValue]\", \"pydicom/tests/test_valuerep.py::test_set_value[UI-str-vm031-vmN31-SOPClassUID]\", \"pydicom/tests/test_valuerep.py::test_set_value[UL-int-vm032-vmN32-SimpleFrameList]\", \"pydicom/tests/test_valuerep.py::test_set_value[UN-bytes-vm033-vmN33-SelectorUNValue]\", \"pydicom/tests/test_valuerep.py::test_set_value[UR-str-vm034-vmN34-CodingSchemeURL]\", \"pydicom/tests/test_valuerep.py::test_set_value[US-int-vm035-vmN35-SourceAcquisitionBeamNumber]\", \"pydicom/tests/test_valuerep.py::test_set_value[UT-str-vm036-vmN36-StrainAdditionalInformation]\", \"pydicom/tests/test_valuerep.py::test_set_value[UV-int-vm037-vmN37-SelectorUVValue]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[AE-str-vm00-vmN0-Receiver]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[AS-str-vm01-vmN1-PatientAge]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[AT-int-vm02-vmN2-OffendingElement]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[CS-str-vm03-vmN3-QualityControlSubject]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[DA-str-vm04-vmN4-PatientBirthDate]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[DS-str-vm05-vmN5-PatientWeight]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[DS-int-vm06-vmN6-PatientWeight]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[DS-float-vm07-vmN7-PatientWeight]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[DT-str-vm08-vmN8-AcquisitionDateTime]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[FD-float-vm09-vmN9-RealWorldValueLUTData]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[FL-float-vm010-vmN10-VectorAccuracy]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[IS-str-vm011-vmN11-BeamNumber]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[IS-int-vm012-vmN12-BeamNumber]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[IS-float-vm013-vmN13-BeamNumber]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[LO-str-vm014-vmN14-DataSetSubtype]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[LT-str-vm015-vmN15-ExtendedCodeMeaning]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[OB-bytes-vm016-vmN16-FillPattern]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[OF-bytes-vm018-vmN18-UValueData]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[OW-bytes-vm021-vmN21-TrianglePointIndexList]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[PN-str-vm022-vmN22-PatientName]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[SH-str-vm023-vmN23-CodeValue]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[SL-int-vm024-vmN24-RationalNumeratorValue]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[SQ-list-vm025-vmN25-BeamSequence]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[SS-int-vm026-vmN26-SelectorSSValue]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[ST-str-vm027-vmN27-InstitutionAddress]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[SV-int-vm028-vmN28-SelectorSVValue]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[TM-str-vm029-vmN29-StudyTime]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[UC-str-vm030-vmN30-LongCodeValue]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[UI-str-vm031-vmN31-SOPClassUID]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[UL-int-vm032-vmN32-SimpleFrameList]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[UN-bytes-vm033-vmN33-SelectorUNValue]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[UR-str-vm034-vmN34-CodingSchemeURL]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[US-int-vm035-vmN35-SourceAcquisitionBeamNumber]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[UT-str-vm036-vmN36-StrainAdditionalInformation]\", \"pydicom/tests/test_valuerep.py::test_assigning_bytes[UV-int-vm037-vmN37-SelectorUVValue]\"]"], "files_to_edit": ["pydicom/dataelem.py"], "metadata": {"hints_text": "Also tried following code to get the byte string, but same error.\r\n1. data=array.array('L', indexData).tostring()  # to convert to long -> same error\r\n2. data=array.array('Q', indexData).tostring()  # to convert to long long -> same error\r\n\r\n\nO* VRs should be `bytes`. Use `array.tobytes()` instead of `tostring()`?\r\n\r\nAlso, in the future if have an issue it's much more helpful if you post the full traceback rather than the error since we can look at it to figure out where in the code the exception is occurring.\r\n\r\nIt would also help if you posted the version of Python you're using. \r\n\r\nThis works fine for me with Python 3.9 and pydicom 2.1.2:\r\n```python\r\nfrom pydicom import Dataset\r\nimport array\r\n\r\narr = array.array('H', range(10))\r\nds = Dataset()\r\nds.is_little_endian = True\r\nds.is_implicit_VR = False\r\nds.LongTrianglePointIndexList = arr.tobytes()\r\nprint(ds[\"LongTrianglePointIndexList\"].VR)  # 'OL'\r\nds.save_as('temp.dcm')\r\n```\r\nThis also works fine:\r\n```python\r\nds = Dataset()\r\nds.add_new(0x00660040, 'OL', arr.tobytes())\r\n```\nThank you for the answer.\r\nUnfortunately the error still persists with above code.\r\nPlease find the attached detailed error.\r\n[error.txt](https://github.com/pydicom/pydicom/files/6661451/error.txt)\r\n\r\nOne more information is that the 'ds' is actually read from a file in the disk (ds=pydicom.read_file(filename)). \r\nand this byte array is stored under the following sequence\r\nds[0x0066,0x0002][0][0x0066,0x0013][0][0x0066,0x0028][0][0x0066,0x0040] = arr.tobytes()\r\n\r\npydicom - 2.0.0.0\r\npython - 3.6.4\r\n\r\nThank you.\nCould you post a minimal code sample that reproduces the issue please?\r\n\r\nIf you're using something like this:\r\n`ds[0x0066,0x0002][0][0x0066,0x0013][0][0x0066,0x0028][0][0x0066,0x0040] = arr.tobytes()`\r\n\r\nThen you're missing the `.value` assignment:\r\n`ds[0x0066,0x0002][0][0x0066,0x0013][0][0x0066,0x0028][0][0x0066,0x0040].value = arr.tobytes()`\nHello,\r\nabove code line I just mentioned to give an idea where the actual data is stored (tree level).\r\n\r\nPlease find the actual code used below,\r\n```python\r\nimport pydicom\r\nfrom pydicom.sequence import Sequence\r\nfrom pydicom.dataelem import DataElement\r\nfrom pydicom.dataset import Dataset\r\n\r\nds = pydicom.read_file(filename)\r\nsurfaceSeq= ds[0x0066,0x0002]\r\n\r\n#// read existing sequence items in the dataset\r\nseqlist=[]\r\nfor n in surfaceSeq:\r\n    seqlist.append(n)\r\n\r\nnewDs = Dataset()\r\n \r\nsurfaceMeshPrimitiveSq = Dataset()\r\nlineSeq = Dataset()\r\nindexData = list(range(1,100))\r\nindexData = array.array('H', indexData)\r\nindexData = indexData.tobytes()\r\nlineSeq.add_new(0x00660040, 'OL', indexData) \r\nsurfaceMeshPrimitiveSq.add_new(0x00660028, 'SQ', [lineSeq])\r\nnewDs.add_new(0x00660013, 'SQ', [surfaceMeshPrimitiveSq])\r\n\r\n#add the new sequnce item to the list\r\nseqlist.append(newDs)\r\nds[0x0066,0x0002] = DataElement(0x00660002,\"SQ\",seqlist)\r\nds.save_as(filename)\r\n```\nOK, I can reproduce with:\r\n```python\r\n\r\nimport array\r\n\r\nfrom pydicom import Dataset\r\nfrom pydicom.uid import ExplicitVRLittleEndian\r\n\r\nds = Dataset()\r\nds.file_meta = Dataset()\r\nds.file_meta.TransferSyntaxUID = ExplicitVRLittleEndian\r\n\r\nb = array.array('H', range(100)).tobytes()\r\n\r\nds.LongPrimitivePointIndexList = b\r\nds.save_as('1421.dcm')\r\n```\r\nAnd `print(ds)` gives:\r\n```\r\n(0066, 0040) Long Primitive Point Index List     OL: [b'\\x00\\x00\\x01\\x00\\x02\\x00\\x03\\x00\\x04\\x00\\x05\\x00\\x06\\x00\\x07\\x00\\x08\\x00\\t\\x00\\n\\x00\\x0b\\x00\\x0c\\x00\\r\\x00\\x0e\\x00\\x0f\\x00\\x10\\x00\\x11\\x00\\x12\\x00\\x13\\x00\\x14\\x00\\x15\\x00\\x16\\x00\\x17\\x00\\x18\\x00\\x19\\x00\\x1a\\x00\\x1b\\x00\\x1c\\x00\\x1d\\x00\\x1e\\x00\\x1f\\x00 \\x00!\\x00\"\\x00#\\x00$\\x00%\\x00&\\x00\\'\\x00(\\x00)\\x00*\\x00+\\x00,\\x00-\\x00.\\x00/\\x000\\x001\\x002\\x003\\x004\\x005\\x006\\x007\\x008\\x009\\x00:\\x00;\\x00<\\x00=\\x00>\\x00?\\x00@\\x00A\\x00B\\x00C\\x00D\\x00E\\x00F\\x00G\\x00H\\x00I\\x00J\\x00K\\x00L\\x00M\\x00N\\x00O\\x00P\\x00Q\\x00R\\x00S\\x00T\\x00U\\x00V\\x00W\\x00X\\x00Y\\x00Z\\x00[\\x00', b'\\x00]\\x00^\\x00_\\x00`\\x00a\\x00b\\x00c\\x00']\r\n```\r\nI think this is because the byte value is hitting the hex for the backslash character during assignment. Ouch, that's kinda nasty.", "created_at": "2021-06-16T09:47:08Z", "version": "2.1", "test_patch": "diff --git a/pydicom/tests/test_valuerep.py b/pydicom/tests/test_valuerep.py\n--- a/pydicom/tests/test_valuerep.py\n+++ b/pydicom/tests/test_valuerep.py\n@@ -1546,3 +1546,16 @@ def test_set_value(vr, pytype, vm0, vmN, keyword):\n     elem = ds[keyword]\n     assert elem.value == list(vmN)\n     assert list(vmN) == elem.value\n+\n+\n+@pytest.mark.parametrize(\"vr, pytype, vm0, vmN, keyword\", VALUE_REFERENCE)\n+def test_assigning_bytes(vr, pytype, vm0, vmN, keyword):\n+    \"\"\"Test that byte VRs are excluded from the backslash check.\"\"\"\n+    if pytype == bytes:\n+        ds = Dataset()\n+        value = b\"\\x00\\x01\" + b\"\\\\\" + b\"\\x02\\x03\"\n+        setattr(ds, keyword, value)\n+        elem = ds[keyword]\n+        assert elem.VR == vr\n+        assert elem.value == value\n+        assert elem.VM == 1\n", "environment_setup_commit": "506ecea8f378dc687d5c504788fc78810a190b7a"}}
{"problem_id": "pydicom__pydicom-901", "repo_owner": "pydicom", "repo_name": "pydicom", "repo_url": "https://github.com/pydicom/pydicom", "base_commit": "3746878d8edf1cbda6fbcf35eec69f9ba79301ca", "problem": "pydicom should not define handler, formatter and log level.\nThe `config` module (imported when pydicom is imported) defines a handler and set the log level for the pydicom logger. This should not be the case IMO. It should be the responsibility of the client code of pydicom to configure the logging module to its convenience. Otherwise one end up having multiple logs record as soon as pydicom is imported:\r\n\r\nExample:\r\n```\r\nCould not import pillow\r\n2018-03-25 15:27:29,744 :: DEBUG :: pydicom \r\n  Could not import pillow\r\nCould not import jpeg_ls\r\n2018-03-25 15:27:29,745 :: DEBUG :: pydicom \r\n  Could not import jpeg_ls\r\nCould not import gdcm\r\n2018-03-25 15:27:29,745 :: DEBUG :: pydicom \r\n  Could not import gdcm\r\n``` \r\nOr am I missing something?\n", "issue_title": "Fix issue in pydicom/pydicom", "issue_body": "pydicom should not define handler, formatter and log level.\nThe `config` module (imported when pydicom is imported) defines a handler and set the log level for the pydicom logger. This should not be the case IMO. It should be the responsibility of the client code of pydicom to configure the logging module to its convenience. Otherwise one end up having multiple logs record as soon as pydicom is imported:\r\n\r\nExample:\r\n```\r\nCould not import pillow\r\n2018-03-25 15:27:29,744 :: DEBUG :: pydicom \r\n  Could not import pillow\r\nCould not import jpeg_ls\r\n2018-03-25 15:27:29,745 :: DEBUG :: pydicom \r\n  Could not import jpeg_ls\r\nCould not import gdcm\r\n2018-03-25 15:27:29,745 :: DEBUG :: pydicom \r\n  Could not import gdcm\r\n``` \r\nOr am I missing something?\n", "pr_diff": "diff --git a/pydicom/config.py b/pydicom/config.py\n--- a/pydicom/config.py\n+++ b/pydicom/config.py\n@@ -62,10 +62,7 @@ def DS_decimal(use_Decimal_boolean=True):\n \n # Logging system and debug function to change logging level\n logger = logging.getLogger('pydicom')\n-handler = logging.StreamHandler()\n-formatter = logging.Formatter(\"%(message)s\")\n-handler.setFormatter(formatter)\n-logger.addHandler(handler)\n+logger.addHandler(logging.NullHandler())\n \n \n import pydicom.pixel_data_handlers.numpy_handler as np_handler  # noqa\n@@ -110,16 +107,29 @@ def get_pixeldata(ds):\n \"\"\"\n \n \n-def debug(debug_on=True):\n-    \"\"\"Turn debugging of DICOM file reading and writing on or off.\n+def debug(debug_on=True, default_handler=True):\n+    \"\"\"Turn on/off debugging of DICOM file reading and writing.\n+\n     When debugging is on, file location and details about the\n     elements read at that location are logged to the 'pydicom'\n     logger using python's logging module.\n \n-    :param debug_on: True (default) to turn on debugging,\n-    False to turn off.\n+    Parameters\n+    ----------\n+    debug_on : bool, optional\n+        If True (default) then turn on debugging, False to turn off.\n+    default_handler : bool, optional\n+        If True (default) then use ``logging.StreamHandler()`` as the handler\n+        for log messages.\n     \"\"\"\n     global logger, debugging\n+\n+    if default_handler:\n+        handler = logging.StreamHandler()\n+        formatter = logging.Formatter(\"%(message)s\")\n+        handler.setFormatter(formatter)\n+        logger.addHandler(handler)\n+\n     if debug_on:\n         logger.setLevel(logging.DEBUG)\n         debugging = True\n@@ -129,4 +139,4 @@ def debug(debug_on=True):\n \n \n # force level=WARNING, in case logging default is set differently (issue 103)\n-debug(False)\n+debug(False, False)\n", "solution": "diff --git a/pydicom/config.py b/pydicom/config.py\n--- a/pydicom/config.py\n+++ b/pydicom/config.py\n@@ -62,10 +62,7 @@ def DS_decimal(use_Decimal_boolean=True):\n \n # Logging system and debug function to change logging level\n logger = logging.getLogger('pydicom')\n-handler = logging.StreamHandler()\n-formatter = logging.Formatter(\"%(message)s\")\n-handler.setFormatter(formatter)\n-logger.addHandler(handler)\n+logger.addHandler(logging.NullHandler())\n \n \n import pydicom.pixel_data_handlers.numpy_handler as np_handler  # noqa\n@@ -110,16 +107,29 @@ def get_pixeldata(ds):\n \"\"\"\n \n \n-def debug(debug_on=True):\n-    \"\"\"Turn debugging of DICOM file reading and writing on or off.\n+def debug(debug_on=True, default_handler=True):\n+    \"\"\"Turn on/off debugging of DICOM file reading and writing.\n+\n     When debugging is on, file location and details about the\n     elements read at that location are logged to the 'pydicom'\n     logger using python's logging module.\n \n-    :param debug_on: True (default) to turn on debugging,\n-    False to turn off.\n+    Parameters\n+    ----------\n+    debug_on : bool, optional\n+        If True (default) then turn on debugging, False to turn off.\n+    default_handler : bool, optional\n+        If True (default) then use ``logging.StreamHandler()`` as the handler\n+        for log messages.\n     \"\"\"\n     global logger, debugging\n+\n+    if default_handler:\n+        handler = logging.StreamHandler()\n+        formatter = logging.Formatter(\"%(message)s\")\n+        handler.setFormatter(formatter)\n+        logger.addHandler(handler)\n+\n     if debug_on:\n         logger.setLevel(logging.DEBUG)\n         debugging = True\n@@ -129,4 +139,4 @@ def debug(debug_on=True):\n \n \n # force level=WARNING, in case logging default is set differently (issue 103)\n-debug(False)\n+debug(False, False)\n", "test_command": "[\"pydicom/tests/test_config.py::TestDebug::test_default\", \"pydicom/tests/test_config.py::TestDebug::test_debug_on_handler_null\", \"pydicom/tests/test_config.py::TestDebug::test_debug_off_handler_null\", \"pydicom/tests/test_config.py::TestDebug::test_debug_on_handler_stream\", \"pydicom/tests/test_config.py::TestDebug::test_debug_off_handler_stream\"]", "test_commands": ["[\"pydicom/tests/test_config.py::TestDebug::test_default\", \"pydicom/tests/test_config.py::TestDebug::test_debug_on_handler_null\", \"pydicom/tests/test_config.py::TestDebug::test_debug_off_handler_null\", \"pydicom/tests/test_config.py::TestDebug::test_debug_on_handler_stream\", \"pydicom/tests/test_config.py::TestDebug::test_debug_off_handler_stream\"]", "[]"], "files_to_edit": ["pydicom/config.py"], "metadata": {"hints_text": "In addition, I don't understand what the purpose of the `config.debug` function since the default behavor of the logging module in absence of configuartion seems to already be the one you want.\r\n\r\nFrom https://docs.python.org/3/howto/logging.html#configuring-logging-for-a-library:\r\n\r\n> If the using application does not use logging, and library code makes logging calls, then (as described in the previous section) events of severity WARNING and greater will be printed to sys.stderr. This is regarded as the best default behaviour.\r\n\r\nand\r\n\r\n>**It is strongly advised that you do not add any handlers other than NullHandler to your library\u2019s loggers.** This is because the configuration of handlers is the prerogative of the application developer who uses your library. The application developer knows their target audience and what handlers are most appropriate for their application: if you add handlers \u2018under the hood\u2019, you might well interfere with their ability to carry out unit tests and deliver logs which suit their requirements. \r\n\nI think you make good points here.  I support changing the logging to comply with python's suggested behavior.\r\n\r\n> In addition, I don't understand what the purpose of the config.debug function\r\n\r\nOne reason is that the core loop in pydicom (data_element_generator in filereader.py) is extremely optimized for speed - it checks the `debugging` flag set by config.debug, to avoid composing messages and doing function calls to logger when not needed.", "created_at": "2019-07-27T00:18:11Z", "version": "1.3", "test_patch": "diff --git a/pydicom/tests/test_config.py b/pydicom/tests/test_config.py\nnew file mode 100644\n--- /dev/null\n+++ b/pydicom/tests/test_config.py\n@@ -0,0 +1,107 @@\n+# Copyright 2008-2019 pydicom authors. See LICENSE file for details.\n+\"\"\"Unit tests for the pydicom.config module.\"\"\"\n+\n+import logging\n+import sys\n+\n+import pytest\n+\n+from pydicom import dcmread\n+from pydicom.config import debug\n+from pydicom.data import get_testdata_files\n+\n+\n+DS_PATH = get_testdata_files(\"CT_small.dcm\")[0]\n+PYTEST = [int(x) for x in pytest.__version__.split('.')]\n+\n+\n+@pytest.mark.skipif(PYTEST[:2] < [3, 4], reason='no caplog')\n+class TestDebug(object):\n+    \"\"\"Tests for config.debug().\"\"\"\n+    def setup(self):\n+        self.logger = logging.getLogger('pydicom')\n+\n+    def teardown(self):\n+        # Reset to just NullHandler\n+        self.logger.handlers = [self.logger.handlers[0]]\n+\n+    def test_default(self, caplog):\n+        \"\"\"Test that the default logging handler is a NullHandler.\"\"\"\n+        assert 1 == len(self.logger.handlers)\n+        assert isinstance(self.logger.handlers[0], logging.NullHandler)\n+\n+        with caplog.at_level(logging.DEBUG, logger='pydicom'):\n+            ds = dcmread(DS_PATH)\n+\n+            assert \"Call to dcmread()\" not in caplog.text\n+            assert \"Reading File Meta Information preamble...\" in caplog.text\n+            assert \"Reading File Meta Information prefix...\" in caplog.text\n+            assert \"00000080: 'DICM' prefix found\" in caplog.text\n+\n+    def test_debug_on_handler_null(self, caplog):\n+        \"\"\"Test debug(True, False).\"\"\"\n+        debug(True, False)\n+        assert 1 == len(self.logger.handlers)\n+        assert isinstance(self.logger.handlers[0], logging.NullHandler)\n+\n+        with caplog.at_level(logging.DEBUG, logger='pydicom'):\n+            ds = dcmread(DS_PATH)\n+\n+            assert \"Call to dcmread()\" in caplog.text\n+            assert \"Reading File Meta Information preamble...\" in caplog.text\n+            assert \"Reading File Meta Information prefix...\" in caplog.text\n+            assert \"00000080: 'DICM' prefix found\" in caplog.text\n+            msg = (\n+                \"00009848: fc ff fc ff 4f 42 00 00 7e 00 00 00    \"\n+                \"(fffc, fffc) OB Length: 126\"\n+            )\n+            assert msg in caplog.text\n+\n+    def test_debug_off_handler_null(self, caplog):\n+        \"\"\"Test debug(False, False).\"\"\"\n+        debug(False, False)\n+        assert 1 == len(self.logger.handlers)\n+        assert isinstance(self.logger.handlers[0], logging.NullHandler)\n+\n+        with caplog.at_level(logging.DEBUG, logger='pydicom'):\n+            ds = dcmread(DS_PATH)\n+\n+            assert \"Call to dcmread()\" not in caplog.text\n+            assert \"Reading File Meta Information preamble...\" in caplog.text\n+            assert \"Reading File Meta Information prefix...\" in caplog.text\n+            assert \"00000080: 'DICM' prefix found\" in caplog.text\n+\n+    def test_debug_on_handler_stream(self, caplog):\n+        \"\"\"Test debug(True, True).\"\"\"\n+        debug(True, True)\n+        assert 2 == len(self.logger.handlers)\n+        assert isinstance(self.logger.handlers[0], logging.NullHandler)\n+        assert isinstance(self.logger.handlers[1], logging.StreamHandler)\n+\n+        with caplog.at_level(logging.DEBUG, logger='pydicom'):\n+            ds = dcmread(DS_PATH)\n+\n+            assert \"Call to dcmread()\" in caplog.text\n+            assert \"Reading File Meta Information preamble...\" in caplog.text\n+            assert \"Reading File Meta Information prefix...\" in caplog.text\n+            assert \"00000080: 'DICM' prefix found\" in caplog.text\n+            msg = (\n+                \"00009848: fc ff fc ff 4f 42 00 00 7e 00 00 00    \"\n+                \"(fffc, fffc) OB Length: 126\"\n+            )\n+            assert msg in caplog.text\n+\n+    def test_debug_off_handler_stream(self, caplog):\n+        \"\"\"Test debug(False, True).\"\"\"\n+        debug(False, True)\n+        assert 2 == len(self.logger.handlers)\n+        assert isinstance(self.logger.handlers[0], logging.NullHandler)\n+        assert isinstance(self.logger.handlers[1], logging.StreamHandler)\n+\n+        with caplog.at_level(logging.DEBUG, logger='pydicom'):\n+            ds = dcmread(DS_PATH)\n+\n+            assert \"Call to dcmread()\" not in caplog.text\n+            assert \"Reading File Meta Information preamble...\" in caplog.text\n+            assert \"Reading File Meta Information prefix...\" in caplog.text\n+            assert \"00000080: 'DICM' prefix found\" in caplog.text\n", "environment_setup_commit": "7241f5d9db0de589b230bb84212fbb643a7c86c3"}}
{"problem_id": "pydicom__pydicom-1139", "repo_owner": "pydicom", "repo_name": "pydicom", "repo_url": "https://github.com/pydicom/pydicom", "base_commit": "b9fb05c177b685bf683f7f57b2d57374eb7d882d", "problem": "Make PersonName3 iterable\n```python\r\nfrom pydicom import Dataset\r\n\r\nds = Dataset()\r\nds.PatientName = 'SomeName'\r\n\r\n'S' in ds.PatientName\r\n```\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nTypeError: argument of type 'PersonName3' is not iterable\r\n```\r\n\r\nI'm not really sure if this is intentional or if PN elements should support `str` methods. And yes I know I can `str(ds.PatientName)` but it's a bit silly, especially when I keep having to write exceptions to my element iterators just for PN elements.\n", "issue_title": "Fix issue in pydicom/pydicom", "issue_body": "Make PersonName3 iterable\n```python\r\nfrom pydicom import Dataset\r\n\r\nds = Dataset()\r\nds.PatientName = 'SomeName'\r\n\r\n'S' in ds.PatientName\r\n```\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nTypeError: argument of type 'PersonName3' is not iterable\r\n```\r\n\r\nI'm not really sure if this is intentional or if PN elements should support `str` methods. And yes I know I can `str(ds.PatientName)` but it's a bit silly, especially when I keep having to write exceptions to my element iterators just for PN elements.\n", "pr_diff": "diff --git a/pydicom/valuerep.py b/pydicom/valuerep.py\n--- a/pydicom/valuerep.py\n+++ b/pydicom/valuerep.py\n@@ -1,6 +1,5 @@\n # Copyright 2008-2018 pydicom authors. See LICENSE file for details.\n \"\"\"Special classes for DICOM value representations (VR)\"\"\"\n-from copy import deepcopy\n from decimal import Decimal\n import re\n \n@@ -750,6 +749,25 @@ def __ne__(self, other):\n     def __str__(self):\n         return '='.join(self.components).__str__()\n \n+    def __next__(self):\n+        # Get next character or stop iteration\n+        if self._i < self._rep_len:\n+            c = self._str_rep[self._i]\n+            self._i += 1\n+            return c\n+        else:\n+            raise StopIteration\n+\n+    def __iter__(self):\n+        # Get string rep. and length, initialize index counter\n+        self._str_rep = self.__str__()\n+        self._rep_len = len(self._str_rep)\n+        self._i = 0\n+        return self\n+\n+    def __contains__(self, x):\n+        return x in self.__str__()\n+\n     def __repr__(self):\n         return '='.join(self.components).__repr__()\n \n", "solution": "diff --git a/pydicom/valuerep.py b/pydicom/valuerep.py\n--- a/pydicom/valuerep.py\n+++ b/pydicom/valuerep.py\n@@ -1,6 +1,5 @@\n # Copyright 2008-2018 pydicom authors. See LICENSE file for details.\n \"\"\"Special classes for DICOM value representations (VR)\"\"\"\n-from copy import deepcopy\n from decimal import Decimal\n import re\n \n@@ -750,6 +749,25 @@ def __ne__(self, other):\n     def __str__(self):\n         return '='.join(self.components).__str__()\n \n+    def __next__(self):\n+        # Get next character or stop iteration\n+        if self._i < self._rep_len:\n+            c = self._str_rep[self._i]\n+            self._i += 1\n+            return c\n+        else:\n+            raise StopIteration\n+\n+    def __iter__(self):\n+        # Get string rep. and length, initialize index counter\n+        self._str_rep = self.__str__()\n+        self._rep_len = len(self._str_rep)\n+        self._i = 0\n+        return self\n+\n+    def __contains__(self, x):\n+        return x in self.__str__()\n+\n     def __repr__(self):\n         return '='.join(self.components).__repr__()\n \n", "test_command": "[\"pydicom/tests/test_valuerep.py::TestPersonName::test_next\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_iterator\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_contains\"]", "test_commands": ["[\"pydicom/tests/test_valuerep.py::TestPersonName::test_next\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_iterator\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_contains\"]", "[\"pydicom/tests/test_valuerep.py::TestTM::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDT::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDA::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDS::test_empty_value\", \"pydicom/tests/test_valuerep.py::TestDS::test_float_values\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_str\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_repr\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_float_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_empty_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_valid_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_invalid_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_pickling\", \"pydicom/tests/test_valuerep.py::TestIS::test_longint\", \"pydicom/tests/test_valuerep.py::TestIS::test_overflow\", \"pydicom/tests/test_valuerep.py::TestIS::test_str\", \"pydicom/tests/test_valuerep.py::TestIS::test_repr\", \"pydicom/tests/test_valuerep.py::TestBadValueRead::test_read_bad_value_in_VR_default\", \"pydicom/tests/test_valuerep.py::TestBadValueRead::test_read_bad_value_in_VR_enforce_valid_value\", \"pydicom/tests/test_valuerep.py::TestDecimalString::test_DS_decimal_set\", \"pydicom/tests/test_valuerep.py::TestDecimalString::test_valid_decimal_strings\", \"pydicom/tests/test_valuerep.py::TestDecimalString::test_invalid_decimal_strings\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_last_first\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_copy\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_three_component\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_formatting\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_kr\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_bytes\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_bytes_comp_delimiter\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_bytes_caret_delimiter\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_unicode\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_not_equal\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_encoding_carried\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_hash\", \"pydicom/tests/test_valuerep.py::TestDateTime::test_date\", \"pydicom/tests/test_valuerep.py::TestDateTime::test_date_time\", \"pydicom/tests/test_valuerep.py::TestDateTime::test_time\"]"], "files_to_edit": ["pydicom/valuerep.py"], "metadata": {"hints_text": "I think it is reasonable to support at least some `str` methods (definitely `__contains__` for the example above), but there are many that don't make a lot of sense in this context though - e.g. `join`, `ljust`, `maketrans`, `splitlines` just to name a few, but I suppose each would either never be actually used or would have no effect.\r\n\r\nI have a vague memory that one or more of the `PersonName` classes was at one time subclassed from `str`, or at least that it was discussed... does anyone remember?  Maybe it would be easier now with only Python 3 supported.\n`PersonName` was derived from `str` or `unicode` in Python 2, but that caused a number of problems, which is why you switched to `PersonName3` in Python 3, I think. I agree though that it makes sense to implement `str` methods, either by implementing some of them, or generically by adding `__getattr__` that converts it to `str` and applies the attribute to that string. ", "created_at": "2020-06-26T11:47:17Z", "version": "2.0", "test_patch": "diff --git a/pydicom/tests/test_valuerep.py b/pydicom/tests/test_valuerep.py\n--- a/pydicom/tests/test_valuerep.py\n+++ b/pydicom/tests/test_valuerep.py\n@@ -427,6 +427,62 @@ def test_hash(self):\n         )\n         assert hash(pn1) == hash(pn2)\n \n+    def test_next(self):\n+        \"\"\"Test that the next function works on it's own\"\"\"\n+        # Test getting the first character\n+        pn1 = PersonName(\"John^Doe^^Dr\", encodings=default_encoding)\n+        pn1_itr = iter(pn1)\n+        assert next(pn1_itr) == \"J\"\n+\n+        # Test getting multiple characters\n+        pn2 = PersonName(\n+            \"Yamada^Tarou=\u5c71\u7530^\u592a\u90ce=\u3084\u307e\u3060^\u305f\u308d\u3046\", [default_encoding, \"iso2022_jp\"]\n+        )\n+        pn2_itr = iter(pn2)\n+        assert next(pn2_itr) == \"Y\"\n+        assert next(pn2_itr) == \"a\"\n+\n+        # Test getting all characters\n+        pn3 = PersonName(\"SomeName\")\n+        pn3_itr = iter(pn3)\n+        assert next(pn3_itr) == \"S\"\n+        assert next(pn3_itr) == \"o\"\n+        assert next(pn3_itr) == \"m\"\n+        assert next(pn3_itr) == \"e\"\n+        assert next(pn3_itr) == \"N\"\n+        assert next(pn3_itr) == \"a\"\n+        assert next(pn3_itr) == \"m\"\n+        assert next(pn3_itr) == \"e\"\n+\n+        # Attempting to get next characeter should stop the iteration\n+        # I.e. next can only start once\n+        with pytest.raises(StopIteration):\n+            next(pn3_itr)\n+\n+        # Test that next() doesn't work without instantiating an iterator\n+        pn4 = PersonName(\"SomeName\")\n+        with pytest.raises(AttributeError):\n+            next(pn4)\n+\n+    def test_iterator(self):\n+        \"\"\"Test that iterators can be corretly constructed\"\"\"\n+        name_str = \"John^Doe^^Dr\"\n+        pn1 = PersonName(name_str)\n+        \n+        for i, c in enumerate(pn1):\n+            assert name_str[i] == c\n+\n+        # Ensure that multiple iterators can be created on the same variable\n+        for i, c in enumerate(pn1):\n+            assert name_str[i] == c\n+\n+    def test_contains(self):\n+        \"\"\"Test that characters can be check if they are within the name\"\"\"\n+        pn1 = PersonName(\"John^Doe\")\n+        assert (\"J\" in pn1) == True\n+        assert (\"o\" in pn1) == True\n+        assert (\"x\" in pn1) == False\n+\n \n class TestDateTime:\n     \"\"\"Unit tests for DA, DT, TM conversion to datetime objects\"\"\"\n", "environment_setup_commit": "9d69811e539774f296c2f289839147e741251716"}}
{"problem_id": "pydicom__pydicom-1256", "repo_owner": "pydicom", "repo_name": "pydicom", "repo_url": "https://github.com/pydicom/pydicom", "base_commit": "49a3da4a3d9c24d7e8427a25048a1c7d5c4f7724", "problem": "from_json does not correctly convert BulkDataURI's in SQ data elements\n**Describe the bug**\r\nWhen a DICOM object contains large data elements in SQ elements and is converted to JSON, those elements are correctly turned into BulkDataURI's. However, when the JSON is converted back to DICOM using from_json, the BulkDataURI's in SQ data elements are not converted back and warnings are thrown.\r\n\r\n**Expected behavior**\r\nThe BulkDataURI's in SQ data elements get converted back correctly.\r\n\r\n**Steps To Reproduce**\r\nTake the `waveform_ecg.dcm` in the test data, convert it to JSON, and then convert the JSON to DICOM\r\n\r\n**Your environment**\r\nmodule       | version\r\n------       | -------\r\nplatform     | macOS-10.15.7-x86_64-i386-64bit\r\nPython       | 3.8.2 (v3.8.2:7b3ab5921f, Feb 24 2020, 17:52:18)  [Clang 6.0 (clang-600.0.57)]\r\npydicom      | 2.1.0\r\ngdcm         | _module not found_\r\njpeg_ls      | _module not found_\r\nnumpy        | _module not found_\r\nPIL          | _module not found_\r\n\r\nThe problem is in `jsonrep.py` at line 227. I plan on submitting a pull-request today for this.\n", "issue_title": "Fix issue in pydicom/pydicom", "issue_body": "from_json does not correctly convert BulkDataURI's in SQ data elements\n**Describe the bug**\r\nWhen a DICOM object contains large data elements in SQ elements and is converted to JSON, those elements are correctly turned into BulkDataURI's. However, when the JSON is converted back to DICOM using from_json, the BulkDataURI's in SQ data elements are not converted back and warnings are thrown.\r\n\r\n**Expected behavior**\r\nThe BulkDataURI's in SQ data elements get converted back correctly.\r\n\r\n**Steps To Reproduce**\r\nTake the `waveform_ecg.dcm` in the test data, convert it to JSON, and then convert the JSON to DICOM\r\n\r\n**Your environment**\r\nmodule       | version\r\n------       | -------\r\nplatform     | macOS-10.15.7-x86_64-i386-64bit\r\nPython       | 3.8.2 (v3.8.2:7b3ab5921f, Feb 24 2020, 17:52:18)  [Clang 6.0 (clang-600.0.57)]\r\npydicom      | 2.1.0\r\ngdcm         | _module not found_\r\njpeg_ls      | _module not found_\r\nnumpy        | _module not found_\r\nPIL          | _module not found_\r\n\r\nThe problem is in `jsonrep.py` at line 227. I plan on submitting a pull-request today for this.\n", "pr_diff": "diff --git a/pydicom/jsonrep.py b/pydicom/jsonrep.py\n--- a/pydicom/jsonrep.py\n+++ b/pydicom/jsonrep.py\n@@ -226,7 +226,8 @@ def get_sequence_item(self, value):\n                     value_key = unique_value_keys[0]\n                     elem = DataElement.from_json(\n                         self.dataset_class, key, vr,\n-                        val[value_key], value_key\n+                        val[value_key], value_key,\n+                        self.bulk_data_element_handler\n                     )\n                 ds.add(elem)\n         return ds\n", "solution": "diff --git a/pydicom/jsonrep.py b/pydicom/jsonrep.py\n--- a/pydicom/jsonrep.py\n+++ b/pydicom/jsonrep.py\n@@ -226,7 +226,8 @@ def get_sequence_item(self, value):\n                     value_key = unique_value_keys[0]\n                     elem = DataElement.from_json(\n                         self.dataset_class, key, vr,\n-                        val[value_key], value_key\n+                        val[value_key], value_key,\n+                        self.bulk_data_element_handler\n                     )\n                 ds.add(elem)\n         return ds\n", "test_command": "[\"pydicom/tests/test_json.py::TestBinary::test_bulk_data_reader_is_called_within_SQ\"]", "test_commands": ["[\"pydicom/tests/test_json.py::TestBinary::test_bulk_data_reader_is_called_within_SQ\"]", "[\"pydicom/tests/test_json.py::TestPersonName::test_json_pn_from_file\", \"pydicom/tests/test_json.py::TestPersonName::test_pn_components_to_json\", \"pydicom/tests/test_json.py::TestPersonName::test_pn_components_from_json\", \"pydicom/tests/test_json.py::TestPersonName::test_empty_value\", \"pydicom/tests/test_json.py::TestPersonName::test_multi_value_to_json\", \"pydicom/tests/test_json.py::TestPersonName::test_dataelem_from_json\", \"pydicom/tests/test_json.py::TestAT::test_to_json\", \"pydicom/tests/test_json.py::TestAT::test_from_json\", \"pydicom/tests/test_json.py::TestAT::test_invalid_value_in_json\", \"pydicom/tests/test_json.py::TestAT::test_invalid_tag_in_json\", \"pydicom/tests/test_json.py::TestDataSetToJson::test_json_from_dicom_file\", \"pydicom/tests/test_json.py::TestDataSetToJson::test_roundtrip\", \"pydicom/tests/test_json.py::TestDataSetToJson::test_dataset_dumphandler\", \"pydicom/tests/test_json.py::TestDataSetToJson::test_dataelement_dumphandler\", \"pydicom/tests/test_json.py::TestDataSetToJson::test_sort_order\", \"pydicom/tests/test_json.py::TestSequence::test_nested_sequences\", \"pydicom/tests/test_json.py::TestBinary::test_inline_binary\", \"pydicom/tests/test_json.py::TestBinary::test_invalid_inline_binary\", \"pydicom/tests/test_json.py::TestBinary::test_valid_bulkdata_uri\", \"pydicom/tests/test_json.py::TestBinary::test_invalid_bulkdata_uri\", \"pydicom/tests/test_json.py::TestBinary::test_bulk_data_reader_is_called\", \"pydicom/tests/test_json.py::TestBinary::test_bulk_data_reader_is_called_2\"]"], "files_to_edit": ["pydicom/jsonrep.py"], "metadata": {"hints_text": "", "created_at": "2020-11-04T21:13:33Z", "version": "2.1", "test_patch": "diff --git a/pydicom/tests/test_json.py b/pydicom/tests/test_json.py\n--- a/pydicom/tests/test_json.py\n+++ b/pydicom/tests/test_json.py\n@@ -354,3 +354,25 @@ def bulk_data_reader(tag, vr, value):\n         ds = Dataset().from_json(json.dumps(json_data), bulk_data_reader)\n \n         assert b'xyzzy' == ds[0x00091002].value\n+\n+    def test_bulk_data_reader_is_called_within_SQ(self):\n+        def bulk_data_reader(_):\n+            return b'xyzzy'\n+\n+        json_data = {\n+            \"003a0200\": {\n+                \"vr\": \"SQ\", \n+                \"Value\": [\n+                    {\n+                        \"54001010\": {\n+                            \"vr\": \"OW\",\n+                            \"BulkDataURI\": \"https://a.dummy.url\"\n+                        }\n+                    }\n+                ]\n+            }\n+        }\n+\n+        ds = Dataset().from_json(json.dumps(json_data), bulk_data_reader)\n+\n+        assert b'xyzzy' == ds[0x003a0200].value[0][0x54001010].value\n", "environment_setup_commit": "506ecea8f378dc687d5c504788fc78810a190b7a"}}
