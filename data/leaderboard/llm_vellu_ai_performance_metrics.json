[
  {
    "model": "GPT- 4.5",
    "throughput": "48 t/s",
    "latency": "1.25s"
  },
  {
    "model": "Claude 3.7 Sonnet [R]",
    "throughput": "/",
    "latency": "/"
  },
  {
    "model": "Grok-2",
    "throughput": "N/A",
    "latency": "N/A"
  },
  {
    "model": "DeepSeek-R1",
    "throughput": "58 t/s",
    "latency": "40s"
  },
  {
    "model": "OpenAI o1-mini",
    "throughput": "196 t/s",
    "latency": "11.43s"
  },
  {
    "model": "Qwen2.5-32b Instruct",
    "throughput": "61 t/s",
    "latency": "1.34s"
  },
  {
    "model": "DeepSeek V3 O324",
    "throughput": "47 t/s",
    "latency": "1.47 s"
  },
  {
    "model": "OpenAI o1",
    "throughput": "/",
    "latency": "/"
  },
  {
    "model": "Gemini 2.0 Flash",
    "throughput": "169 t/s",
    "latency": "0.48s"
  },
  {
    "model": "Llama 3.3 70b",
    "throughput": "250 t/s via Groq",
    "latency": "n/a"
  },
  {
    "model": "Nova Micro",
    "throughput": "n/a",
    "latency": "0.3s"
  },
  {
    "model": "Nova Lite",
    "throughput": "150 t/s",
    "latency": "0.4s"
  },
  {
    "model": "Nova Pro",
    "throughput": "97 t/s",
    "latency": "0.4s"
  },
  {
    "model": "Claude 3.5 Haiku",
    "throughput": "60 t/s",
    "latency": "0.77s"
  },
  {
    "model": "Llama 3.1 405b",
    "throughput": "163 t/s via SambaNova",
    "latency": "0.59s"
  },
  {
    "model": "Llama 3.1 70b",
    "throughput": "2,100 t/s (Cerebras)",
    "latency": "0.38s"
  },
  {
    "model": "Llama 3.1 8b",
    "throughput": "~1800 t/s (Cerebras)",
    "latency": "0.32s"
  },
  {
    "model": "Gemini 1.5 Flash",
    "throughput": "166 t/s",
    "latency": "1.06S"
  },
  {
    "model": "Gemini 1.5 Pro",
    "throughput": "61 t/s",
    "latency": "1.12s"
  },
  {
    "model": "GPT-3.5 Turbo",
    "throughput": "84 t/s",
    "latency": "0.37s"
  },
  {
    "model": "GPT-4o mini",
    "throughput": "97 t/s",
    "latency": "0.56s"
  },
  {
    "model": "GPT-Turbo",
    "throughput": "28 t/s",
    "latency": "0.6s"
  },
  {
    "model": "GPT-4o",
    "throughput": "79 t/s",
    "latency": "0.48s"
  },
  {
    "model": "Claude 3 Haiku",
    "throughput": "133 t/s",
    "latency": "0.55s"
  },
  {
    "model": "Claude 3.5 Sonnet",
    "throughput": "78 t/s",
    "latency": "1.22s"
  },
  {
    "model": "Claude 3 Opus",
    "throughput": "25 t/s",
    "latency": "1.99s"
  },
  {
    "model": "GPT-4",
    "throughput": "125 t/s",
    "latency": "0.59s"
  },
  {
    "model": "GPT- 4.5",
    "throughput": "48 t/s",
    "latency": "1.25s"
  },
  {
    "model": "Claude 3.7 Sonnet [R]",
    "throughput": "/",
    "latency": "/"
  },
  {
    "model": "Grok-2",
    "throughput": "N/A",
    "latency": "N/A"
  },
  {
    "model": "DeepSeek-R1",
    "throughput": "58 t/s",
    "latency": "40s"
  },
  {
    "model": "OpenAI o1-mini",
    "throughput": "196 t/s",
    "latency": "11.43s"
  },
  {
    "model": "Qwen2.5-32b Instruct",
    "throughput": "61 t/s",
    "latency": "1.34s"
  },
  {
    "model": "DeepSeek V3 O324",
    "throughput": "47 t/s",
    "latency": "1.47 s"
  },
  {
    "model": "OpenAI o1",
    "throughput": "/",
    "latency": "/"
  },
  {
    "model": "Gemini 2.0 Flash",
    "throughput": "169 t/s",
    "latency": "0.48s"
  },
  {
    "model": "Llama 3.3 70b",
    "throughput": "250 t/s via Groq",
    "latency": "n/a"
  },
  {
    "model": "Nova Micro",
    "throughput": "n/a",
    "latency": "0.3s"
  },
  {
    "model": "Nova Lite",
    "throughput": "150 t/s",
    "latency": "0.4s"
  },
  {
    "model": "Nova Pro",
    "throughput": "97 t/s",
    "latency": "0.4s"
  },
  {
    "model": "Claude 3.5 Haiku",
    "throughput": "60 t/s",
    "latency": "0.77s"
  },
  {
    "model": "Llama 3.1 405b",
    "throughput": "163 t/s via SambaNova",
    "latency": "0.59s"
  },
  {
    "model": "Llama 3.1 70b",
    "throughput": "2,100 t/s (Cerebras)",
    "latency": "0.38s"
  },
  {
    "model": "Llama 3.1 8b",
    "throughput": "~1800 t/s (Cerebras)",
    "latency": "0.32s"
  },
  {
    "model": "Gemini 1.5 Flash",
    "throughput": "166 t/s",
    "latency": "1.06S"
  },
  {
    "model": "Gemini 1.5 Pro",
    "throughput": "61 t/s",
    "latency": "1.12s"
  },
  {
    "model": "GPT-3.5 Turbo",
    "throughput": "84 t/s",
    "latency": "0.37s"
  },
  {
    "model": "GPT-4o mini",
    "throughput": "97 t/s",
    "latency": "0.56s"
  },
  {
    "model": "GPT-Turbo",
    "throughput": "28 t/s",
    "latency": "0.6s"
  },
  {
    "model": "GPT-4o",
    "throughput": "79 t/s",
    "latency": "0.48s"
  },
  {
    "model": "Claude 3 Haiku",
    "throughput": "133 t/s",
    "latency": "0.55s"
  },
  {
    "model": "Claude 3.5 Sonnet",
    "throughput": "78 t/s",
    "latency": "1.22s"
  },
  {
    "model": "Claude 3 Opus",
    "throughput": "25 t/s",
    "latency": "1.99s"
  },
  {
    "model": "GPT-4",
    "throughput": "125 t/s",
    "latency": "0.59s"
  }
]